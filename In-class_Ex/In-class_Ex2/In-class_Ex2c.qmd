---
title: "In-Class Exercise 2C: Emerging Hot Spot Analysis"
subtitle: "Using sfdep package" 
author: "Goh Si Hui"
date: 2023/11/25
date-format: long
date-modified: "last-modified"
format: html 
execute: 
  echo: true
  eval: true
  warning: false
editor: visual 
---

## Overview

Emerging Hot Spot Analysis (EHSA) is a spatio-temporal analysis method for revealing and describing how hot spot and cold spot areas evolve over time. The analysis consist of four main steps:

-   Building a space-time cube,

-   Calculating Getis-Ord local Gi\* statistic for each bin by using an FDR correction,

-   Evaluating these hot and cold spot trends by using Mann-Kendall trend test,

-   Categorising each study area location by referring to the resultant trend z-score and p-value for each location with data, and with the hot spot z-score and p-value for each bin.

## Getting Started

We will first load the necessary packages using the following code chunk:

-   **tmap**: for thematic mapping
-   **sf**: for geospatial data handling (e.g. importing and exporting for spatial data and geoprocessing)
-   **tidyverse**: a family of R packages for non-spatial data handling
-   **knitr**: to generate static html tables
-   **sfdep**: to calculate spatial weights and matrices, space time cube and hot spot analysis
-   **plotly**: to make the graphs interactive

```{r}
pacman::p_load(tmap, sf, tidyverse, sfdep, knitr, plotly)
```

## Preparing the Geospatial Data

### Importing the data

```{r}
hunan <- st_read(dsn = "data/geospatial", layer="Hunan")
```

From the above outcome, we know that `hunan`data is simple feature (sf) data frame with 88 features (each representing 1 geographical entity), and each feature is a polygon.It uses the WGS84 projection.

## Preparing the Aspatial Data

### Importing the data

```{r}
GDPPC <- read.csv("data/aspatial/Hunan_GDPPC.csv")
```

Let us take a look at the GDPPC data.

```{r}

kable(head(GDPPC))

```

## Creating a Time Series Cube

Checking that the Year column is a numeric data type. 

```{r}
str(GDPPC)

```
We can convert Year to numeric using the following code. 

```{r}

GDPPC[1] <- lapply(GDPPC[1], as.numeric)
```

Checking that the Year column is a numeric data type. 

```{r}
str(GDPPC)

```

We use `spacetime()` of sfdep to create a space time cube.

```{r}
GDPPC_st <- spacetime(GDPPC, hunan,
                 .loc_col = "County",
                 .time_col = "Year")
```

We can use `is_spacetime_cube()` of **sfedep** package to verify if GDPPC_st is indeed a space time cube object.

```{r}
is_spacetime_cube(GDPPC_st)
```

The TRUE return confirms that GDPPC_st object is indeed an space time cube.

```{r}
GDPPC_st
```

## Computing Gi*

First we will compute an inverse distance weight matrix.

```{r}
GDPPC_nb <- GDPPC_st %>%
  activate("geometry") %>% 
  mutate(nb = include_self(st_contiguity(geometry)),
         wt = st_inverse_distance(nb, geometry, scale = 1,
                                  alpha=1),
         .before = 1) %>%
  set_nbs("nb") %>% 
  set_wts("wt")
```

::: callout-note
-   activate() of dplyr package is used to activate the geometry context
-   mutate() of dplyr package is used to create 2 columns nb and wt.
-   Then we will activate the data context again and copy over the nb and wt columns to each time-slice using set_nbs() and set_wts().
    -   Note that row order is very important so do not rearrange the observations after using set_nbs() or set_wts().
:::

The following output shows that this dataset now has neighbours and weighrs for each time-slice

```{r}
head(GDPPC_nb)

```

We can now use these new columns to calculate the local Gi\* for each location. We can do this by grouping Year and using `local_gstar_perm()` of **sfdep** package. After which, we use `unnest()` to unnest gi_star column of the newly created gi_stars data frame.

Erroreous code:


gi_stars <- GDPPC_nb %>%
  group_by(Year) %>% 
  mutate(gi_star = local_gstar_perm(GDPPC, nb, wt)) %>% 
  tidyr::unnest(gi_star)


## Mann-Kendall Test

## Arrange to show significant emerging hot/cold spots

## Performing Emerging Hotspot Analysis


