---
title: "In-class Exercise 3: Calibrating Spatial Interaction Models"
author: "Goh Si Hui"
date: 2023/12/02
date-format: long
date-modified: "last-modified"
format: html 
execute: 
  echo: true
  eval: true
  warning: false
editor: visual 
---

## Overview

In this in-class exercise, we will learn how to calibrate Spatial Interaction Models (SIM) to determine factors affecting the public bus passenger flows during the morning peak in Singapore.

::: callout-note
Calibration is the process of adjusting parameters in the model to try and get the estimates to agree with the observed data as much as possible. Adjusting the parameters is the sort of iterative process that computers are particularly good at and the goodness-of-fit statistics can be used to indicate when the optimum solution is found. Historically this process required a researcher with the requisite programming skills to write a computer algorithm to iteratively adjust each parameter, check the goodness-of-fit, and then start all over again until the goodness-of-fit statistic was maximised/minimised. (Adam Dennett, 2018)
:::

## Getting Started

### Packages

We import the relevant packages using the following code chunk.

```{r}
pacman::p_load(tmap, sf, sp, DT, performance, reshape2, ggpubr, tidyverse) 
```

-   **sf**: provides simple features access for R

-   **sp**: Classes and Methods for spatial data

-   **tmap**: generates thematic maps

-   **dt**: creates dynamic tables

-   **performance**: assesses model quality, which are not directly provided by R's 'base' or 'stats' packages

-   **reshape2**: transforms data between wide and long formats.

-   **ggpubr**: creates the multiple plots into one

-   **tidyverse**: handles aspatial data

### Importing Data

This exercise is a continuation of Hands-on Exercise 3 and the following data will be used:

-   od_data.rds - weekday morning peak passenger flows at planning subzone level

-   mpsz.rds - URA Master Plan 2019 Planning Subzone boundary in simple feature tibble data frame format.

-   pop.csv - an attribute data downloaded from Singstat.

::: callout-note
RDS (R Data Serialization) files are a common format for saving R objects in RStudio, and they allow you to preserve the state of an object between R sessions. Saving your R object as an RDS file in R can be useful for sharing your work with others, replicating your analysis, or simply storing your work for later use.
:::

## Computing Distance Matrix

In this section, you will learn how to compute a distance matrix by using URA Master Plan 2019 Planning Subzone boundary in which you saved as an rds file called `mpsz`.In spatial interaction, a distance matrix is a table that shows the distance between pairs of locations.

We will fiture import mpsz.rds into R using the folloiwng code chunk.

```{r}
#| code-fold: true
#| code-summary: "Show the code"

mpsz <- read_rds("data/rds/mpsz.rds")
mpsz
```

::: callout-Note
Note that mpsz is a sf tibble dataframe object class.
:::

### Converting from sf data table to Spatial Polygons DataFrame

There are at least two ways to compute the required distance matrix. One is based on **sf** and the other is based on **sp**. We will be using function from the **sp** package because past experience had shown that computing distance matrix using **sf** package's function took relatively longer time than **sp**, especially when the data set is large.

We will use `as.Spatial()` to convert `mpsz` from a sf tibble data frame to SpatialPolygonsDataFrame of sp object.

```{r}
mpsz_sp <- as(mpsz, "Spatial")
mpsz_sp
```

::: callout-Note
From the above output, we see that mpsz is no longer a tibble dataframe but a list.
:::

### Computing the Distance Matrix

We will use `spDist()` of **sp** package to compute the Euclidean distance between the centroids of the planning subzones. We need to calculate the distance between 2 centroids of a pair of spatial polygons because a pair of spatial polygons represent the origin and destination of movement and a centroid is an absration of the attributes of a zone at a point. Hence, by measuring the distance between 2 centroids of a pair of spatial polygons, it represents the movement occurring between an origin location and a destination location.

```{r}
dist <- spDists(mpsz_sp, 
                longlat = FALSE)
```

In the above code chunk, `longlat=` is FALSE because there is already a projection and the geometry is not in longtitude and latitude.

::: callout-Note
Notice that: - the output `dist` is a matrix object class of R. - the diagonals (representing intra-distances) are zeroes. - the column headers and row headers are not labeled with the planning subzone codes.
:::

We use the following code chunk to display the top 10 column and rows of the matrix because it is very large.

```{r}
head(dist, n=c(10, 10))
```

### Labelling the column and row headers of a distance matrix

We will perform the following steps to label the column and row headers of the distance matrix with planning subzone codes.

First, we will create a list sorted according to the distance matrix by planning subzone code.

```{r}
sz_names <- mpsz$SUBZONE_C
```

Next, we will the attach SUBZONE_C to row and column for distance matrix matching ahead.

```{r}
colnames(dist) <- paste0(sz_names)
rownames(dist) <- paste0(sz_names)
```

### Pivoting Distance Value by Subzone_C

Next, we will pivot the distance matrix into a long table using the row and column subzone codes shown in the following code chunk.

```{r}
distPair <- melt(dist) %>%
  rename(dist = value)
head(distPair, 10)
```

::: callout-Note
-   `melt` is from **reshape2** package. It takes the dist matrix and convert it to a long table.
-   The within zone distance is 0.
:::

### Updating intra-zonal distances

In this section, we are going to append a constant value to replace the intra-zonal distance of 0.

First, we will select and find out the minimum value of the distance by using `summary()`.

```{r}
distPair %>%
  filter(dist > 0) %>%
  summary()
```

From the above output, we note that the minimum distance us 173.80. Hence we will derive a number smaller than 173.80 divided by 2 to get the minimum distance from the centriod to the boundary of the zone. We divided the minimum distance observed by 2 because the interzonal distance is between 2 zones.

In this case, we will use a constant distance value of 50m and add it into the intra-zones distance.

```{r}
distPair$dist <- ifelse(distPair$dist == 0,
                        50, distPair$dist)
```

We check the result using the following code.

```{r}
distPair %>%
  summary()
```

We also rename the origin and destination fields using the following code chunk

```{r}
distPair <- distPair %>%
  rename(orig = Var1,
         dest = Var2)

```

Lastly, we will save the dataframe into an rds for future use.

```{r}
write_rds(distPair, "data/rds/disPair.rds")
```

## Preparing Flow Data

We first import the `od_data` into R environment.

```{r}
od_data <- read_rds("data/rds/od_data.rds")
```

Then, we compute the total passenger trip between and within planning subzones sing the following code chunk. The ouput is `flow_data`.

```{r}
flow_data <- od_data %>%
  group_by(ORIGIN_SZ, DESTIN_SZ) %>% 
  summarize(TRIPS = sum(MORNING_PEAK)) 
```

```{r}
head(flow_data, 10)
```

### Separating intra-flow from passenger volume df

We use the following code chunk to add 3 new fields into the `flow_data` dataframe.

```{r}
flow_data$FlowNoIntra <- ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 
  0, flow_data$TRIPS)
flow_data$offset <- ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 
  0.000001, 1)
```

### Combining passenger volume data with distance value

Before we can join flow_data and distPair, wethe convert data value type of ORIGIN_SZ and DESTIN_SZ fields of flow_data dataframe into factor data type.

```{r}
flow_data$ORIGIN_SZ <- as.factor(flow_data$ORIGIN_SZ)
flow_data$DESTIN_SZ <- as.factor(flow_data$DESTIN_SZ)

```

Then we will use `left_join()` of **dplyr** to join `flow_data` and `disPair`. The output is `flow_data1`.

```{r}
flow_data1 <- flow_data %>%
  left_join (distPair,
             by = c("ORIGIN_SZ" = "orig",
                    "DESTIN_SZ" = "dest"))
```

## Preparing Origin and Destination Attributes

### Importing population data

```{r}
#| code-fold: true
#| code-summary: "Show the code"
pop <- read_csv("data/aspatial/pop.csv")
pop
```

### Geospatial data wrangling

```{r}
pop <- pop %>%
  left_join(mpsz, 
            by = c("PA" = "PLN_AREA_N",
                   "SZ" = "SUBZONE_N")) %>%
  select(1:6) %>%
  rename(SZ_NAME = SZ, 
         SZ = SUBZONE_C)
```

### Preparing Origin Attribute

```{r}
flow_data1 <- flow_data1 %>%
  left_join(pop,
            by = c(ORIGIN_SZ = "SZ")) %>%
  rename(ORIGIN_AGE7_12 = AGE7_12,
         ORIGIN_AGE13_24 = AGE13_24,
         ORIGIN_AGE25_64 = AGE25_64) %>%
  select(-c(PA, SZ_NAME))

```

### Preparing Destination Attribute

```{r}
flow_data1 <- flow_data1 %>%
  left_join(pop,
            by = c(DESTIN_SZ = "SZ")) %>%
  rename(DESTIN_AGE7_12 = AGE7_12,
         DESTIN_AGE13_24 = AGE13_24,
         DESTIN_AGE25_64 = AGE25_64) %>%
  select(-c(PA, SZ_NAME))

```

We will save the output in rds file format using the following code chunk.

```{r}
write_rds(flow_data1, "data/rds/SIM_data")
```

## Calibrating Spatial Interaction Models

In this section, we wll learn how to calibrate Spatial Interaction Models using Poisson Regression Method.

### Importing the Modelling Data

We use the following code chunk to import the modelling data.

```{r}
SIM_data <- read_rds("data/rds/SIM_data.rds")
```

### Visualising the dependent variable

First, we plot the distribution of the dependent variable (i.e. TRIPS) with a histogram using the following code chunk.

```{r}
ggplot(data = SIM_data,
       aes(x = TRIPS)) +
  geom_histogram()

```

Notice that the distribution is highly skewed and not resemble bell shape or also known as normal distribution.

Next, let us visualise the relation between the dependent variable and one of the key independent variable in Spatial Interaction Model, namely distance.

```{r}
ggplot(data = SIM_data,
       aes(x = dist,
           y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

```

From the above chart, it seems that their relationship is not linear.

On the other hand, if we plot the scatter plot by using the log transformed version of both variables, we can see that their relationship resembles more of a linear relationship.

```{r}
ggplot(data = SIM_data,
       aes(x = log(dist),
           y = log(TRIPS))) +
  geom_point() + 
  geom_smooth(method = lm)
```

### Checking for variables with zero values

Since Poisson Regression is based on log and log 0 is undefined, it is important to ensure that there is no 0 values in the explanatory variables. We use `summary()` of Base R to compute the summary statistics of all variables in SIM_data dataframe.

```{r}
summary(SIM_data)
```

The output above shows that the following variables have 0 in their values: - ORIGIN_AGE7_12 - ORIGIN_AGE13_24 - ORIGIN_AGE25_64 - DESTIN_AGE7_12 - DESTIN_AGE13_24 - DESTIN_AGE25_64

We will use the following code chunk to replace 0 values to 0.99.

```{r}
SIM_data$DESTIN_AGE7_12 <- ifelse(
  SIM_data$DESTIN_AGE7_12 == 0,
  0.99, SIM_data$DESTIN_AGE7_12)
SIM_data$DESTIN_AGE13_24 <- ifelse(
  SIM_data$DESTIN_AGE13_24 == 0,
  0.99, SIM_data$DESTIN_AGE13_24)
SIM_data$DESTIN_AGE25_64 <- ifelse(
  SIM_data$DESTIN_AGE25_64 == 0,
  0.99, SIM_data$DESTIN_AGE25_64)
SIM_data$ORIGIN_AGE7_12 <- ifelse(
  SIM_data$ORIGIN_AGE7_12 == 0,
  0.99, SIM_data$ORIGIN_AGE7_12)
SIM_data$ORIGIN_AGE13_24 <- ifelse(
  SIM_data$ORIGIN_AGE13_24 == 0,
  0.99, SIM_data$ORIGIN_AGE13_24)
SIM_data$ORIGIN_AGE25_64 <- ifelse(
  SIM_data$ORIGIN_AGE25_64 == 0,
  0.99, SIM_data$ORIGIN_AGE25_64)
```

We check the summary of `SIM_data` again.

```{r}
summary(SIM_data)
```

Notice that all the minimum values have been changed from 0 to 0.99.

### Unconstrained Spatial Interaction Model

In this section, we will learn how to calibrate an unconstrained spatial interaction model using `glm()` of Base Stats. The explanatory variables are (i) origin population by different age cohort, (ii) destination population by different age cohort and (iii) distance between origin and destination in km (i.e. `dist`).

The general formula of Unconstrained Spatial Interaction Model is as follow.

$$
\lambda{i}{j}= exp(k + \mu\ln V{i} + \alpha\ln W{j} - \beta \ln d{i}{j})
$$

We use the following code chunk to calibrate the model.

```{r}
uncSIM <- glm(formula = TRIPS ~ 
                log(ORIGIN_AGE25_64) + 
                log(DESTIN_AGE25_64) +
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
uncSIM

```

::: callout-Note
Note that we the code chunk above uses addition even though the general formula involves a "-" sign.
:::

### R squared Function

To measure how much variation of the trips can be accounted by the model, we write the following function to calcuate the R squared value.

```{r}
CalcRSquared <- function(observed,estimated){
  r <- cor(observed,estimated)
  R2 <- r^2
  R2
}

```

We will compute the R sqaured of the unconstained SIM using the following code chunk.

```{r}
CalcRSquared(uncSIM$data$TRIPS, uncSIM$fitted.values)

```

```{r}
r2_mcfadden(uncSIM)
```

### Origin (Production) constrained SIM

In this section, we will fit an origin constrained SIM.

The general formula of Origin Constrained Spatial Interaction Model

$$
\lambda{i}{j}= exp(k + \mu{i} + \alpha\ln W{j} - \beta \ln d{i}{j})
$$

::: panel-tabset
## Codes

```{r}

orcSIM <- glm(formula = TRIPS ~ 
                 ORIGIN_SZ +
                 log(DESTIN_AGE25_64) +
                 log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)

```

## Output

```{r}

summary(orcSIM)

```
:::

We can examine how the constraints hold for destinations this time using the following code.

```{r}
CalcRSquared(orcSIM$data$TRIPS, orcSIM$fitted.values)

```

### Destination Constrained

In this section, we will fit a destination constrained SIM.

The general formula of Destination Constrained Spatial Interaction Model

$$
\lambda{i}{j}= exp(k + \mu\ln V{i} + \alpha{i} - \beta \ln d{i}{j})
$$

::: panel-tabset
### Codes

```{r}

decSIM <- glm(formula = TRIPS ~ 
                DESTIN_SZ + 
                log(ORIGIN_AGE25_64) + 
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)

```

### Output

```{r}
summary(decSIM)
```
:::

We can examine how the constraints hold for destinations using the following code.

```{r}
CalcRSquared(decSIM$data$TRIPS, decSIM$fitted.values)
```

### Doubly Constrained

In this section, we will fit a doubly constrained SIM.

The general formula of Doubly Constrained Spatial Interaction Model

$$
\lambda{i}{j}= exp(k + \mu{i} + \alpha{i} - \beta \ln d{i}{j})
$$

::: panel-tabset
## Codes

```{r}

dbcSIM <- glm(formula = TRIPS ~ 
                ORIGIN_SZ + 
                DESTIN_SZ + 
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)

```

## Output

```{r}

summary(dbcSIM)

```
:::

We can examine how the constraints hold for destinations using the following code.

```{r}
CalcRSquared(dbcSIM$data$TRIPS, dbcSIM$fitted.values)

```

We note that there is a relatively higher improvement in the R squared value.

### Model Comparison

We will learn how to use `compare_performance()` of **performance** package in this section.

First, we create a list called `model_list` using the following code chunk.

```{r}
model_list <- list(unconstrained=uncSIM,
                   originConstrained=orcSIM,
                   destinationConstrained=decSIM,
                   doublyConstrained=dbcSIM)

```

Then, we will compute the Root Mean Squared Error (RMSE) of all the models in the `model_list` using the following code chunk.

```{r}
compare_performance(model_list,
                    metrics = "RMSE")

```

The output above reveals that doubly constrained SIM is the best model among all the four SIMs because it has the smallest RMSE value of 1487.111.

### Visualing Fitted

In this section, we will learn how to visual the observed values and the fitted values.

First, we will extract the fitted values from each model using the following code chunk.

```{r}
df <- as.data.frame(uncSIM$fitted.values) %>%
  round(digits = 0)

```

Next, we will join the values to `SIM_data` dataframe.

```{r}
SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(uncTRIPS = "uncSIM$fitted.values")

```

Repeat the same steps for Origin Constrained SIM (i.e. orcSIM)

```{r}
df <- as.data.frame(orcSIM$fitted.values) %>%
  round(digits = 0)

```

```{r}
SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(orcTRIPS = "orcSIM$fitted.values")

```

Repeat the same steps for Destination Constrained SIM (i.e. decSIM)

```{r}
df <- as.data.frame(decSIM$fitted.values) %>%
  round(digits = 0)

```

```{r}
SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(decTRIPS = "decSIM$fitted.values")

```

Repeat the same steps for Doubly Constrained SIM (i.e. dbcSIM)

```{r}
df <- as.data.frame(dbcSIM$fitted.values) %>%
  round(digits = 0)
```

```{r}
SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(dbcTRIPS = "dbcSIM$fitted.values")
```

We will now plot the charts showing the observed and fitted values for each SIM.

```{r}
unc_p <- ggplot(data = SIM_data,
                aes(x = uncTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

orc_p <- ggplot(data = SIM_data,
                aes(x = orcTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

dec_p <- ggplot(data = SIM_data,
                aes(x = decTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

dbc_p <- ggplot(data = SIM_data,
                aes(x = dbcTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

ggarrange(unc_p, orc_p, dec_p, dbc_p,
          ncol = 2,
          nrow = 2)
```
