---
title: "Take-Home Exercise 1: Geospatial Analytics for Public Good"
author: "Goh Si Hui"
date: 2023/11/26
date-format: long
date-modified: "last-modified"
format: html 
execute: 
  echo: true
  eval: true
  warning: false
editor: visual 
---

## Overview

### Introduction

As city-wide urban infrastructures such as buses, taxis, public utilities and roads become digital, data can be collected and used as a framework for tracking movement patterns through space and time. These massive movement data collected are likely to contain structure and patterns that provide useful information about characteristics of the measured phenomena. The identification, analysis and comparison of such patterns will provide greater insights on human movement and behaviours within a city. These understandings will potentially contribute to a better urban management and useful information for urban transport services providers both from the private and public sector to formulate informed decision to gain competitive advantage.

### Objectives

Exploratory Spatial Data Analysis (ESDA) hold tremendous potential to address complex problems facing society. In this takeihome exercise, I will be applying appropriate Local Indicators of Spatial Association (LISA) to undercover the spatial and spatio-temporal mobility patterns of public bus passengers in Singapore.

### Packages used

For this exercise, we will be using the following packages:

-   **sf** - to import and handle geospatial data

-   **tidyverse** - to handle and wrangle attribute data

-   **knitr** - to generate tables for matrices

-   **sfdep** - to compute spatial weights, global and local spatial autocorrelation statistics

-   **tmap** - to prepare and plot cartographic quality choropleth maps

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
pacman::p_load(sf, sfdep, tmap, tidyverse, knitr, patchwork)
```

## Data Preparation

For the purpose of this take-home exercise, we will be using two datasets:

-   `Passenger Volume by Origin Destination Bus Stops` - this is an aspatial dataset in csv file format. It contains information on the number of passenger trips by weekdays and weekends from origin destination bus stops. I used the October 2023 dataset downloaded from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) on 18 Nov 2023 for the purpose of this exercise.

::: callout-note
`Passenger Volume by Origin Destination Bus Stops` dataset is updated monthly at LTA Datamall. Using the [API](https://datamall.lta.gov.sg/content/dam/datamall/datasets/LTA_DataMall_API_User_Guide.pdf) provided by LTA Datamall, we can download up to the latest 3 months data.
:::

-   `Bus Stop Location` - this is a geospatial dataset in shapefile format. It provides information from all the bus stops currently serviced by buses, including the bus stop code and location coordinates.I downloaded the `Bus Stop Location` dataset that was updated on July 2023 from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) on 18 Nov 2023 for the purpose of this exercise.

::: callout-note
`Bus Stop Location` dataset is updated quarterly at LTA Datamall.
:::

### Importing the Data into R Environment

Firstly, we import the aspatial data `Passenger Volume by Origin Destination Bus Stops` dataset using `read_csv()` of **readr** package, which is part of the **tidyverse** family of packages. We use `st_read()` from **sf** package to import the geospatial data `Bus Stop Location`.

::: panel-tabset
## Aspatial Data

```{r}
odbus_oct <- read_csv("data/aspatial/origin_destination_bus_202310.csv")
```

## Geospatial Data

```{r}
busstop <- st_read(dsn = "data/geospatial",layer = "BusStop")
```
:::

### Data Wrangling of Aspatial Data

We first examine the imported aspatial data `odbus_oct` using `glimpse()`.

::: panel-tabset
## Snapshot of Data

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
head(odbus_oct)
```

## About the Variables

-   YEAR_MONTH - The year and month which the data was collected. `2023-10` means that the data was collected on October 2023.
-   DAY_TYPE - Tells us the type of the day which the trip occurred. If DAY_TYPE is Weekday, it means that the trip occurred on a Weekday (i.e., any day from Monday to Friday).
-   TIME_PER_HOUR - The time which the passenger tap in.
-   PT_TYPE - Type of Public Transport. For example, in our case, it should be bus.
-   ORIGIN_PT_CODE - Bus stop code for origin bus stop.
-   DESTINATION_PT_CODE - Bus stop code for destination bus stop.
-   TOTAL_TRIPS - Total number of trips generated by origin bus stop.
:::

A quick check of `odbus_oct` tibble data frame using `glimpse()` shows that the values in `ORIGIN_PT_CODE` and `DESTINATON_PT_CODE` are in **character** data type. Since these two columns contain the origin bus stop codes and destination bus stop codes and they actually take on a limited number of different values (unlike strings), we convert `ORIGIN_PT_CODE` and `DESTINATION_PT_CODE` into **factor** data type using `as.factor()`.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
odbus_oct$ORIGIN_PT_CODE <- as.factor(odbus_oct$ORIGIN_PT_CODE)
odbus_oct$DESTINATION_PT_CODE <- as.factor(odbus_oct$DESTINATION_PT_CODE) 
```

Let us check the `odbus_oct` data frame again.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
glimpse(odbus_oct)
```

Using `unique()` function, we can find the unique values in a column. Let us first check the `YEAR_MONTH`, `DAY_TYPE`, `TIME_PER_HOUR` and `PT_TYPE` to ensure the data contains bus trips made in October 2023, and there are no other unexpected values for `DAY_TYPE` and TIME_PER_HOUR.

::: panel-tabset
## YEAR_MONTH

```{r}
unique(odbus_oct$YEAR_MONTH)
```

## DAY_TYPE

```{r}
unique(odbus_oct$DAY_TYPE)
```

## TIME_PER_HOUR

```{r}
unique(odbus_oct$TIME_PER_HOUR)

#To count the number hours listed
length(unique(odbus_oct$TIME_PER_HOUR))

```

## PT_TYPE

```{r}
unique(odbus_oct$PT_TYPE)
```
:::

From the above output, we know that the data only contains **bus** trips made in **October 2023**. The DAY_TYPES have 2 categories: **WEEKDAYS** and **WEEKENDS/HOLIDAY**. TIME_PER_HOUR have 23 categories because there is no value of "3" in TIME_PER_HOUR variable.

Next, we find out there are 5073 bus stops in the dataset using the following code chunk.

```{r}
length(unique(odbus_oct$ORIGIN_PT_CODE))
```

We also check for duplicate records in the dataset and found that there are no duplicate records since the `duplicate` data frame has no rows.

::: panel-tabset
## Codes

```{r}
duplicate <- odbus_oct %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
```

## Output

```{r}
duplicate
```
:::

We also check if there are any missing values and observations with 0 total trips in the dataset because this would affect our subsequent steps, especially when we are going to conduct Local Spatial Autocorrelation Analysis.

::: panel-tabset
## Check for Missing Values

```{r}
odbus_oct %>% 
  map(is.na) %>%
  map(sum)

```

## Check for TOTAL_TRIPS with 0 value

```{r}
summary(odbus_oct$TOTAL_TRIPS)
```
:::

From the above output, we know that there are no missing values and no observations with 0 trips.

We visualise the dataset to get more understanding of the trips and the Day Type.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"

total_trips <- odbus_oct %>% 
  group_by(DAY_TYPE) %>%
  summarise(TOTAL = sum(TOTAL_TRIPS))
  
g_total_trips <- ggplot(total_trips) + 
  geom_col(aes(x=DAY_TYPE, y=TOTAL)) + 
  ggtitle('Total Passenger Trips in Oct 2023') 

weekday_trips <- odbus_oct %>% 
  filter(DAY_TYPE == "WEEKDAY") %>%
  group_by(TIME_PER_HOUR) %>%
  summarise(TOTAL = sum(TOTAL_TRIPS)) 
  
g_weekday_trips <- ggplot(weekday_trips) + 
  geom_col(aes(x=TIME_PER_HOUR, y=TOTAL)) + 
  ggtitle('Weekday Passenger Trips')

weekend_trips <- odbus_oct %>% 
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  group_by(TIME_PER_HOUR) %>%
  summarise(TOTAL = sum(TOTAL_TRIPS))
  
g_weekend_trips <- ggplot(weekend_trips) + 
  geom_col(aes(x=TIME_PER_HOUR, y=TOTAL)) + 
  ggtitle('Weekend Passenger Trips')

g_total_trips / (g_weekday_trips | g_weekend_trips)

```

From the above, we gather that weekday generate more passenger trips as compared to Weekends/Holidays. We also note that on weekdays, the passenger peaks at 7am - 8am and 6pm - 7pm. While weekends/ holidays generally has less trips than weekdays but its peaks are less distinctive, indicating that the flow of passengers are generally more constant.

#### Extracting Data for this exercise

For the purpose of this exercise, we are going to focus on the passenger trips generated by origin bus stops during the following Peak Hour Periods:

-   Weekday Morning Peak - 9am to 9am

-   Weekday Afternoon Peak - 5pm to 8pm

-   Weekend/holiday Morning Peak - 11am to 2pm

-   Weekend/holiday Evening Peak - 4pm to 7pm

We will use `group_by()`, `summarise()` and `sum()` to derive the passenger trips generated by origin bus stops during the abovementioned peak periods.

::: panel-tabset
### Total Passenger Trips

```{r}
origin_TOTAL <- odbus_oct %>% 
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TOTAL = sum(TOTAL_TRIPS)) 

glimpse(origin_TOTAL)
```

### Weekday Morning Peak Hour

```{r}
origin_WDMP <- odbus_oct %>% 
  filter(DAY_TYPE == "WEEKDAY") %>% 
  filter(TIME_PER_HOUR >= 6 &
           TIME_PER_HOUR <= 9) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(WDMP = sum(TOTAL_TRIPS))

glimpse(origin_WDMP)
```

### Weekday Afternoon Peak Hour

```{r}
origin_WDAP <- odbus_oct %>% 
  filter(DAY_TYPE == "WEEKDAY") %>% 
  filter(TIME_PER_HOUR >= 17 &
           TIME_PER_HOUR <= 20) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(WDAP = sum(TOTAL_TRIPS))

glimpse(origin_WDAP)
```

### Weekend Morning Peak Hour

```{r}
origin_WEMP <- odbus_oct %>% 
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>% 
  filter(TIME_PER_HOUR >= 11 &
           TIME_PER_HOUR <= 14) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(WEMP = sum(TOTAL_TRIPS))

glimpse(origin_WEMP)
```

### Weekend Evening Peak Hour

```{r}
origin_WEEP <- odbus_oct %>% 
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>% 
  filter(TIME_PER_HOUR >= 16 &
           TIME_PER_HOUR <= 19) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(WEEP = sum(TOTAL_TRIPS))

glimpse(origin_WEEP) 
```
:::

Notice that as compared to the number of origin bus stops in `origin_TOTAL`, there are less origin bus stops in origin_WDMP, origin_WDAP, origin_WEMP and origin_WEEP. This could be due to some bus stops with no trips generated at origin bus stops during the peak periods which we are interested in.

Nonetheless, this is something we should take note in our subsequent step when we join these dataframes together. To ensure all 5073 bus stops are not dropped due to 0 trips generated during peak hour, `origin_TOTAL` should be on the left hand side of the left join.

::: panel-tabset
### Join with Weekday Morning Peak

```{r}
#| code-fold: true
#| code-summary: "Show the Code"

origin_TRIPS <- left_join(origin_TOTAL, origin_WDMP)
glimpse(origin_TRIPS)
```

### Join with Weekday Afternoon Peak

```{r}
origin_TRIPS <- left_join(origin_TRIPS, origin_WDAP)
glimpse(origin_TRIPS)

```

### Join with Weekend Morning Peak

```{r}
origin_TRIPS <- left_join(origin_TRIPS, origin_WEMP)
glimpse(origin_TRIPS)

```

### Join with Weekend Evening Peak

```{r}
origin_TRIPS <- left_join(origin_TRIPS, origin_WEEP)
glimpse(origin_TRIPS)
```
:::

After joining these tables, we check for missing values in the final dataframe `origin_TRIPS` and observed that there are missing values in WDMP, WDAP, WEMP and WEEP columns, which is probably due to there were no trips generated at origin bus stops during these peak hour periods.

::: panel-tabset
### Check for Columns with Missing Values

```{r}
origin_TRIPS %>% 
  map(is.na) %>%
  map(sum)

```

### Filter out rows with missing values

```{r}
origin_TRIPS[rowSums(is.na(origin_TRIPS)) > 0, ] 
```
:::

We use the following code chunk to fill all the missing values with 0 for easier handling in subsequent steps.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"

origin_TRIPS <- origin_TRIPS %>% 
  replace(is.na(.), 0) 

```

### Data Wrangling of Geospatial Data

Let us take a look at the geospatial data imported.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
head(busstop) 

```

From the above output, we know that the `busstop` is a simple feature data frame. It consists of 5161 features, which are point geometry type.We note that it has 3 fields and the projected CRS is SVY21.

::: {.callout-caution collapse="false"}
This dataset has 5161 busstops while our aspatial dataset has 5073 busstops. This should be something to take note in our subsequent steps.
:::

First, let us check the coordinate system using the following code.

```{r}

#| code-fold: true
#| code-summary: "Show the Code"
st_crs(busstop)

```

Although `busstop` data frame is projected in svy21, at the end of the output, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.Hence, we need to assign the correct ESPG code to `busstop` data frame using the `st_set_crs()` of **sf** package.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
busstop3414 <- st_set_crs(busstop, 3414)
st_crs(busstop3414)
```

We use the following code to select columns that we want for the

```{r}
busstop3414 <- busstop3414 %>%
  select(1,3)
glimpse(busstop3414)
```

#### Generating Hexagon Grid

For this exercise, we will be computing the passenger trips generated by origin at the hexagon level. Before we join the busstop location with the passenger trips data in `origin_TRIPS` dataframe, we will generate the hexagon grid first.

First, we will make a hexagon tessellation using `busstop3414` to define the bounding box of the tessellation. As the hexagon layer that we want is 250m (the perpendicular distance between the centre of the hexagon and its edges), and the `cellsize` parameter in `st_make_grid` requires the length to be the distance to be between opposite edges, we multiply 250m by 2 to get 500m, which is the distance between opposite edges of a hexagon. In the code chunk below, we also specify the `crs = 3414` since we are using the SVY21 coordinate reference system and set `square = FALSE` to return a hexagon grid (rather than a square grid).

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
hex_grid <- st_make_grid(busstop3414, c(500,500), crs = 3414, what = "polygons", square = FALSE)
hex_grid
```

Next, we convert `hex_grid` from a sfc_POLYGON object to sf object for easier handling and add an unique ID to each cell. Each cell is a hexagon and in subsequent steps, we will check the number of bus stops within each hexagon.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
hex_grid_sf <- st_sf(hex_grid) %>%
  mutate(grid_id = 1:length(lengths(hex_grid)))

hex_grid_sf
```

We then use `st_intersects()` to find out which points (i.e., origin bus stops in our case) are lying inside each grid. As we want to know how many bus stops are within each hexagon grid, we use `lengths()` to return the number of each element of the list then attach it as a column back to `hex_grid_sf` data frame.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
hex_grid_sf$BS_count <- lengths(st_intersects(hex_grid_sf, busstop3414))
```

As there are some hexagon cells without any bus stops inside, we use the following code chunk to remove these cells, retain only hexagon cells with bus stops inside and generate a new sf data frame called `sgmap`.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
sgmap <- filter(hex_grid_sf, BS_count>0)
sgmap
```

We then use `st_intersection()` to perform point (i.e., `busstop3414` data frame) and polygon (`sgmap` data frame) overlay and the output will be in point sf object.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
busstop_grid_id <- st_intersection(busstop3414, sgmap) %>%
  st_drop_geometry()
busstop_grid_id
```

We save this output into rds format for future use.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
write_rds(busstop_grid_id, "data/rds/busstop_grid_id.rds")  
```

We then join the bus stop information, hexagon grid id with the passenger trips in `origin_TRIPS` so that the data frame has information on passenger trips. We name this output data frame as `busstop_trips`.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
busstop_trips <- left_join(busstop_grid_id,origin_TRIPS,
                           by = c("BUS_STOP_N" = "ORIGIN_PT_CODE")) %>%
  rename(ORIGIN_BS = BUS_STOP_N) 

busstop_trips
```

We use the following code chunk to check for duplicates in `busstop_trips`.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"

duplicate1 <- busstop_trips %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()

duplicate1
```

From the above output, we note that there are duplicate rows. Hence we will use `unique()` to retain the unique records.

```{r}
busstop_trips <- unique(busstop_trips)
```

We use the following code chunk to verify that there are no more duplicating records.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
duplicate2 <- busstop_trips %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()

duplicate2
```

Since the above output does not return any duplicates, we can confirm that the data frame has no duplicating records.

Next, we check if there are any missing values in the data frame and filter out those rows with these missing values for further verification.

::: panel-tabset
### Check for Missing Values

```{r}
busstop_trips %>% 
  map(is.na) %>%
  map(sum)
```

### Filter out Rows with Missing Values

```{r}
busstop_trips[rowSums(is.na(busstop_trips)) > 0, ] 
```
:::

From the output, we note that there are 8 bus stops without location description but they contain passenger trips. Hence We will retain these rows because they still have passenger trip information and our analysis will be at the hexagon layer level so missing location description does not have much impact on our analysis since we know these bus stops belong to which hexagon cell. As for those bus stops that have missing passenger trips, we will fill it with 0.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
busstop_trips$LOC_DESC <- replace(busstop_trips$LOC_DESC, is.na(busstop_trips$LOC_DESC), "NO_DESC") 
```

We then confirm that there are no missing values in LOC_DESC.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
busstop_trips %>% 
  map(is.na) %>%
  map(sum)
```

We use the following code chunk to fill all the missing values with 0 for easier handling in subsequent steps.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"

busstop_trips <- busstop_trips %>% 
  replace(is.na(.), 0) 

```

We then confirm that there are no missing values in the data frame.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
busstop_trips %>% 
  map(is.na) %>%
  map(sum)
```

We use the following code chunk to generate a new data frame `busstop_trips1` which will contain the total passenger trips generated by the origin bus stops within each hexagon cell.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
busstop_trips1 <- busstop_trips %>% 
  group_by(grid_id)%>%
  summarise(TOTALTRIPS_PER_GRID = sum(TOTAL),
            TOTALWDMP_PER_GRID = sum(WDMP),
            TOTALWDAP_PER_GRID = sum(WDAP), 
            TOTALWEMP_PER_GRID = sum(WEMP),
            TOTALWEEP_PER_GRID = sum(WEEP))

head(busstop_trips1)
```

We then join the passenger trips information for each grid with the hexagon grid's geometry information found in the sf dataframe `sgmap` using `left_join()` on the common column `grid_id`.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
origintrip_hex <- left_join(sgmap,busstop_trips1,
                            by = "grid_id")
head(origintrip_hex)
```

## GeoVisualisation

Using the `origintrip_hex` dataframe generated from previous section, we plot the geographical distribution of the passenger trips using **tmap** package.

### Comparing Weekday Morning and Afternoon Peak Hours

We first compare the geographical distribution of passenger trips between Weekday Morning and Afternoon Peak Hours. For ease of comparison, we plot the two charts side by side using `tmap_arrange()`.

We also [changed](https://gis.stackexchange.com/questions/378369/tmap-openstreetmap-basemap-in-greyscale) the default basemap from ESPI map to Onemap so that it is easier to locate the area which the hexagon grids are located in.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"

tiles ='https://maps-{s}.onemap.sg/v3/Grey/{z}/{x}/{y}.png'

tmap_mode("view")

WDMP <- tm_basemap(server = tiles)+ 
  tm_shape(origintrip_hex)+
  tm_fill("TOTALWDMP_PER_GRID", 
          style = "quantile", 
          palette = "Greens",
          title = "Passenger Trips") +
  tm_layout(main.title = "Passenger Trips during Weekday AM Peak in Oct 2023",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_scale_bar()

WDAP <- tm_basemap(server = tiles)+ tm_shape(origintrip_hex)+
  tm_fill("TOTALWDAP_PER_GRID", 
          style = "quantile", 
          palette = "Blues",
          title = "Passenger Trips") +
  tm_layout(main.title = "Passenger trips during Weekday PM Peak in Oct 2023",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5)  +
  tm_scale_bar()

tmap_arrange(WDMP, WDAP, ncol = 2, asp = 1)
```

#### Observations and Analysis

In the northern and eastern parts of Singapore, there seem to be clusters with high volume of passenger trips in the morning, but these same clusters were relatively lower in volume in the afternoon peak hour.

In the southern part, we observe that are more hexagons with high passenger trip volumes in the afternoon peak hour period rather than the morning peak hour period. This could be due to the central business district and more offices located in this area so people who are working there would leave the area to return to the residential areas after work.

For the western part, the number of hexagons with high passenger trips seems to be similar for both Weekday morning and afternoon peak period. This could be due to the western area also have offices and business park, in addition to large residential estates. As such, it could have experienced people moving out the area in the morning, while at the same time people from other areas also work there, leading to high volume of people leaving the area during the afternoon peak hour.

### Comparing Weekend Morning and Evening Peak Hours

```{r}
#| code-fold: true
#| code-summary: "Show the Code"

tmap_mode("view")
WEMP <- tm_basemap(server = tiles)+
  tm_shape(origintrip_hex)+
  tm_fill("TOTALWEMP_PER_GRID", 
          style = "quantile", 
          palette = "Greens",
          title = "Passenger Trips") +
  tm_layout(main.title = "Passenger trips during Weekend AM Peak in Oct 2023",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5)  +
  tm_scale_bar()

WEEP <- tm_basemap(server = tiles)+
  tm_shape(origintrip_hex)+
  tm_fill("TOTALWEEP_PER_GRID", 
          style = "quantile", 
          palette = "Blues",
          title = "Passenger Trips") +
  tm_layout(main.title = "Passenger trips during Weekend PM Peak in Oct 2023",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5)  +
  tm_scale_bar()

tmap_arrange(WEMP, WEEP, ncol = 2, asp=1)
```

#### Observations and Analysis

Overall, on weekends, the pattern of having high volume of passenger trips from residential areas (especially the Northern and Eastern parts of Singapore) is less apparent. Nonetheless, we observe that the southern part of Singapore continues to have more hexagons with high passenger trip volumes in the weekend evening peak hour, which could be due to the shopping district located there. Hence, people would leave the area to return to residential areas in the evening. For the western part, the number of hexagons with high passenger trips seems to be similar for both weekend morning and afternoon peak period. This could be due to the western area also have several large shopping malls, in addition to large residential estates.

## Local Indicators of Spatial Association (LISA) Analysis

Local measures of spatial association are statistics used to detect variations of a variable of interest across space when the spatial relationship of the variable is not constant across the study region, known as spatial non-stationarity or spatial heterogeneity. Unlike global measures that summarize the overall spatial autocorrelation of the study area in one single value, local measures of spatial association identify local clusters (observations nearby have similar attribute values) or spatial outliers (observations nearby have different attribute values).

### Deriving neighbours using Distance-based weight matrices

Before we can compute LISA, we need to derive the neighbours of each area (i.e., each hexagon cell). Because there are hexagons which are not connected to any other hexagons, we will choose a distance-based method to derive the neighbours. We learnt that there are three ways to derive distance-based weight matrix:

-   Fixed Distance
-   Adaptive Distance
-   Inverse Distance Weight

::: panel-tabset
## Fixed Distance Weights

```{r}
geo <- sf::st_geometry(origintrip_hex)
nb <- st_knn(geo, longlat = TRUE)
dists <- unlist(st_nb_dists(geo, nb))

```

```{r}
summary(dists)
```

```{r}
wm_fd <- origintrip_hex %>%
  mutate(nb = st_dist_band(hex_grid,
                           upper = 4273),
               wt = st_weights(nb),
               .before = 1)
```

```{r}
glimpse(wm_fd)
```

## Adaptive Distance Weights

```{r}
wm_ad <- origintrip_hex %>% 
  mutate(nb = st_knn(hex_grid,
                     k=8),
         wt = st_weights(nb),
               .before = 1)

glimpse(wm_ad)
```

## Inverse Distance Weights

```{r}
wm_idw <- origintrip_hex %>%
  mutate(nb = st_contiguity(hex_grid),
         wt = st_inverse_distance(nb, hex_grid,
                                   scale = 1,
                                   alpha = 1),
         .before = 1)

glimpse(wm_idw)
```
:::

For the purpose of this exercise, we will focus on computing Local Moran's I using the Fixed Distance Weight Matrix. Fixed distance weight matrices While the adaptive distance weight matrix ensures that no unit of area has no neighbour, it is difficult to idenfity the value of k that reflects the true underlying spatial relationships. As for Inverse weight distance matrices, while it is intuitive to have higher weights for distances nearer to the area of interest, it results in a harder to interpret chart and results.

### Computing Local Moran's I using Fixed Distance Weight Matrix

First, we check the Fixed Distance Weight Matrix generated from the above section for any missing values.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
wm_fd %>%
  map(is.na) %>% 
  map(sum)
```

### Weekday Morning Peak Hour Period

We then compute LISA using the fixed distance weight matrix and `local_moran()` function for Weekday Morning Peak Hour. `local_moran()` will create a data frame column which contains a number of informative variables such as mean, median or pysal calculations. Local Moran's I allows us to identify clusters of the following types:

-   High-High: areas of high values with neighbors of high values,
-   High-Low: areas of high values with neighbors of low values,
-   Low-High: areas of low values with neighbors of high values,
-   Low-Low: areas of low values with neighbors of low values.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
lisa_fd_WDMP <- wm_fd %>% 
  mutate(local_moran = local_moran(TOTALWDMP_PER_GRID, zero.policy=TRUE,
                                   nb, wt, nsim = 99),
         .before = 1) %>%
  unnest(local_moran)

```

We then plot the `ii` values and `p_ii_sim` values computed from `lisa_fd_WDMP` side by side for ease of comparison.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
tmap_mode("view")
map1 <- tm_basemap(server = tiles)+ 
  tm_shape(lisa_fd_WDMP) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +

  tm_layout(main.title = "local Moran's I",
            main.title.size = 0.8)

map2 <- tm_basemap(server = tiles)+ 
  tm_shape(lisa_fd_WDMP) +
  tm_fill("p_ii_sim",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

tmap_arrange(map1, map2, ncol = 2)

```

From the chart with `ii` values, we see that majority of the map is covered with values 0.0 and above, meaning that majority of the passenger trips of these hexagon cells seem to indicate clustering since it is higher than 0. However, with the values from `p_ii_sim`, we can see the only certain areas have significant p values. The areas with significant p values (i.e. p-values \< 0.05) are in the North, Northwest, North east and west.

To further our analysis, we plot the following LISA cluster map.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"



lisa_sig_WDMP <- lisa_fd_WDMP  %>%
  filter(p_ii_sim < 0.05)

tmap_mode("view")

tm_basemap(server = tiles)+
tm_shape(lisa_fd_WDMP) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig_WDMP) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4)
```

#### Analysis

Th red highlighted regions are the high-high area. This means that they have high values for passenger trips and they also have neighbours that have high values (hence high-high). The red areas corresponds to the areas in the above `p_ii_sim` chart where the northern, north-western and north-eastern parts of Singapore with significant values. These areas are high-high clusters because they have high residential populations, so in weekday morning peak hour period, residents from these area tend to travel out for work or school.

The green highlighted regions are the low-low areas and they are on the far west and eastern sides of Singapore. Low-low area means that they have low values for passenger trips and they also have neighbours with low values (hence low-low). From what we know, the extreme western and eastern parts of Singapore do not have much residential areas and are usually occupied by military camps or factories. Since our study focuses on passenger trips generated from origin bus stops, we would tend to see lower passenger trips originating from these places during weekday morning peak hours.

Both the high-high and low-low regions contribute significantly to a positive spatial autocorrelation outcome. For those high-low and low-high areas, they are considered outliers, which are indicated in purple and yellow cells. These areas contribute significantly to a negative autocorrelation outcome.

### Weekday Afternoon Peak Hour Period

We compute LISA using the fixed distance weight matrix and `local_moran()` function for Weekday Afternoon Peak Hour.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
lisa_fd_WDAP <- wm_fd %>% 
  mutate(local_moran = local_moran(TOTALWDAP_PER_GRID, zero.policy=FALSE,
                                   nb, wt, nsim = 99),
         .before = 1) %>%
  unnest(local_moran)

```

We then plot the `ii` values and `p_ii_sim` values computed from `lisa_fd_WDAP` side by side for ease of comparison.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
tmap_mode("view")
map1 <- tm_basemap(server = tiles)+ tm_shape(lisa_fd_WDAP) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Local Moran's I for Weekday Afternoon Peak Passenger Trips",
            main.title.size = 0.8)

map2 <- tm_basemap(server = tiles)+ tm_shape(lisa_fd_WDAP) +
  tm_fill("p_ii_sim",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I for Weekday Afternoon Peak Passenger Trips",
            main.title.size = 0.8)

tmap_arrange(map1, map2, ncol = 2)


```

Similar to the Weekday morning peak hour period, when we plot the `ii` values derived from local Moran I, the `ii` values tend to be around -1 to 1, with a few hexagon cells showing very high (`ii` values \> 1) or very low (`ii` values \< -1) values. When the `p_ii_sim` values for Weekday afternoon peak hour is plotted, we see that there are only a few areas with significant p values. In the above output, we note that the south-eastern, western and a part of north-western areas of Singapore have significant p values (p value \< 0.05), indicating presence of local clusters.

To further our analysis, we plot the following LISA cluster map.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
lisa_sig_WDAP <- lisa_fd_WDAP  %>%
  filter(p_ii_sim < 0.05)
tmap_mode("view")
tm_basemap(server = tiles)+ tm_shape(lisa_fd_WDAP) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig_WDAP) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4)
```

We note that the high-high clusters are all located in the south-eastern areas of Singapore, which could be due to these passenger trips are generated from origin bus stops in central business district areas. There are also low-high clusters found in the south-eastern areas of Singapore. This could be due to the origin bus stops located at the outskirts of the business districts.

The low-low clusters are in the western, northwestern and 2 hexagon cells in the eastern side of Singapore. These areas could have low passenger trips and neighbours with low passenger trips because the origin bus stops are located near industrial estates and military camps where the working hours could be different (e.g. shift work has different reporting hours). Interestingly within these low-low clusters, there are some high-low clusters. These hexagon cells could contain the key bus stops that ferries people in and out of the area. For example, if these high-low clusters have bus stops with popular bus services which cut across different residential estates, it could lead to higher passenger trips generated from these bus stops.

### Weekend Morning Peak Period

We compute LISA using the fixed distance weight matrix and `local_moran()` function for Weekend Morning Peak Hour.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
lisa_fd_WEMP <- wm_fd %>% 
  mutate(local_moran = local_moran(TOTALWEMP_PER_GRID, zero.policy=FALSE,
                                   nb, wt, nsim = 99),
         .before = 1) %>%
  unnest(local_moran)

```

We then plot the `ii` values and `p_ii_sim` values computed from `lisa_fd_WEMP` side by side for ease of comparison.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
tmap_mode("view")
map1 <- tm_basemap(server = tiles)+ tm_shape(lisa_fd_WEMP) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Local Moran's I for Weekend Morning Peak Passenger Trips",
            main.title.size = 0.8)

map2 <- tm_basemap(server = tiles)+ tm_shape(lisa_fd_WEMP) +
  tm_fill("p_ii_sim",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I for Weekend Morning Peak Passenger Trips",
            main.title.size = 0.8)

tmap_arrange(map1, map2, ncol = 2)


```

As compared to the Weekday afternoon peak period chart with `p_ii_sim` values, a larger area of southern and south-eastern parts of Singapore is considered high-high during Weekday morning peak period. This could be due to the timing of the morning peak period is defined (i.e. 11am to 2pm). As public transport starts around 5 to 6am on weekdays, some passengers could have already reached the southern / south eastern areas earlier than this morning peak period and they are already leaving these areas come 11am to 2pm.

To further our analysis, we plot the following LISA cluster map.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
lisa_sig_WEMP <- lisa_fd_WEMP  %>%
  filter(p_ii_sim < 0.05)
tmap_mode("view")
tm_basemap(server = tiles)+ tm_shape(lisa_fd_WEMP) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig_WEMP) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4)
```

While a relatively large area in the southern and southeastern parts had significant values, there were relatively less areas with high-high clusters. These high-high clusters could be due to being near certain amenities. Interestingly, there were a larger low-low cluster in the western part of Singapore, meaning that the area has very low passenger trips on weekend morning peak period.

### Weekend Evening Peak Period

We compute LISA using the fixed distance weight matrix and `local_moran()` function for Weekend Evening Peak Hour.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
lisa_fd_WEEP <- wm_fd %>% 
  mutate(local_moran = local_moran(TOTALWEEP_PER_GRID, zero.policy=FALSE,
                                   nb, wt, nsim = 99),
         .before = 1) %>%
  unnest(local_moran)

```

We then plot the `ii` values and `p_ii_sim` values computed from `lisa_fd_WEEP` side by side for ease of comparison.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
tmap_mode("view")
map1 <- tm_basemap(server = tiles)+ tm_shape(lisa_fd_WEEP) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Local Moran's I for Weekend Evening Peak Passenger Trips",
            main.title.size = 0.8)

map2 <- tm_basemap(server = tiles)+ tm_shape(lisa_fd_WEEP) +
  tm_fill("p_ii_sim",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I for Weekend Evening Peak Passenger Trips",
            main.title.size = 0.8)

tmap_arrange(map1, map2, ncol = 2)


```

Similar to the Weekend Morning Peak Period, the areas with significant `p_ii_sim` values were in the southern and western parts of Singapore.

To further our analysis, we plot the following LISA cluster map.

```{r}
#| code-fold: true
#| code-summary: "Show the Code"
lisa_sig_WEEP <- lisa_fd_WEEP  %>%
  filter(p_ii_sim < 0.05)
tmap_mode("view")
tm_basemap(server = tiles)+ 
  tm_shape(lisa_fd_WEEP) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig_WEEP) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4)
```

Similar to the other peak periods, the high-high clusters are in the southern area and the low-low clusters are in the western area. This means that on weekend evening peak period, we see a lot of passenger trips originating from the southern part of Singapore, which coincides with the shopping district.

## Conclusion and Future Work

We have done exploratory spatial data analysis on the datasets given in this exercise.If there were more time and data, we can explore the following: - Whether there are any differences when using Jenkins and other data classification methods when visualising the geographical distribution of passenger trips across Singapore. - Compare the LISA computed from other distance-based weight matrices (e.g. IDW and adaptive distance weight matrices). - Explore the origin and destination bus stops so that we can find more on the travelling patterns and where people are travelling towards. - Explore the travel patterns between buses and trains.

## References

-   Tin Seong, K. (2023). Local Measures of Spatial Autocorrelation. In R for Geospatial Data Science and Analytics. https://r4gdsa.netlify.app/chap10.html#computing-gi-statistics
-   Spatial dependence for simple features. (n.d.). https://sfdep.josiahparry.com/
-   SIRENT - Singapore Satellite Positioning Reference Network - Plane Coordinate System - SVY21. (n.d.). https://app.sla.gov.sg/sirent/About/PlaneCoordinateSystem
-   tmap OpenStreetMap basemap in greyscale. (n.d.). Geographic Information Systems Stack Exchange. https://gis.stackexchange.com/questions/378369/tmap-openstreetmap-basemap-in-greyscale
