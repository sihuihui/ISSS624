[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS624: Applied Geospatial Analytics",
    "section": "",
    "text": "Welcome! In this website, I will be sharing my learning journey on applied geospatial analytics."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "hands-on_ex1.html",
    "href": "hands-on_ex1.html",
    "title": "Hands-On Exercise 1: Geospatial Data Wrangling with R and Choropleth",
    "section": "",
    "text": "This is the overview paragraph."
  },
  {
    "objectID": "hands-on_ex1.html#overview",
    "href": "hands-on_ex1.html#overview",
    "title": "Hands-On Exercise 1: Geospatial Data Wrangling with R and Choropleth",
    "section": "",
    "text": "This is the overview paragraph."
  },
  {
    "objectID": "hands-on_ex1.html#getting-started",
    "href": "hands-on_ex1.html#getting-started",
    "title": "Hands-On Exercise 1: Geospatial Data Wrangling with R and Choropleth",
    "section": "Getting Started",
    "text": "Getting Started\nThis is the getting started paragraph. We need to do the following to start:\n\nXXX\nXXX\nXXX"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex01.html",
    "href": "Hands-on_Ex1/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, I will be sharing how to import and wrangle geospatial data using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex01.html#overview",
    "href": "Hands-on_Ex1/Hands-on_Ex01.html#overview",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, I will be sharing how to import and wrangle geospatial data using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex01.html#getting-started",
    "href": "Hands-on_Ex1/Hands-on_Ex01.html#getting-started",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Getting Started",
    "text": "Getting Started\nThe code chunk below installs and loads sf and tidyverse packages into R environment.\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex01.html#importing-geospatial-data",
    "href": "Hands-on_Ex1/Hands-on_Ex01.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Importing Geospatial Data",
    "text": "Importing Geospatial Data\nImporting polygon feature data\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\sihuihui\\ISSS624\\Hands-on_Ex1\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1a.html",
    "href": "Hands-on_Ex1/Hands-on_Ex1a.html",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, I will be sharing how to import and wrangle geospatial data using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1a.html#overview",
    "href": "Hands-on_Ex1/Hands-on_Ex1a.html#overview",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, I will be sharing how to import and wrangle geospatial data using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1a.html#getting-started",
    "href": "Hands-on_Ex1/Hands-on_Ex1a.html#getting-started",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Packages\nFor this exercise, we will be using sf and tidyverse packages. The code chunk below installs and loads sf and tidyverse packages into R environment.\n\npacman::p_load(sf, tidyverse)\n\n\n\n2.2 Data Acquisition and Extraction\nWe will extract the following data sets from these sources:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\nAfter we have downloaded these data sets, we created a sub-folder called data. Within the datasub-folder, we created 2 sub-folders, namely geospatial and aspatial. Master Plan 2014 Subzone Boundary (Web), Pre-Schools Location and Cycling Path files should be placed in the geospatial folder while the Singapore Airbnb listing data should be in the aspatial folder."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1a.html#importing-geospatial-data",
    "href": "Hands-on_Ex1/Hands-on_Ex1a.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "3 Importing Geospatial Data",
    "text": "3 Importing Geospatial Data\n\n3.1 Importing polygon feature data\nThe code chunk below uses st_read() function of sf package to import the planning subzones, which is a polygon feature data frame.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\sihuihui\\ISSS624\\Hands-on_Ex1\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe message above also tells us that mpsz’s geometry type is multipolygon, there are a total of 323 multipolygon features and 15 fields in mpsz and it is in svy21 projected coordinates systems.\n\n\n3.2 Importing polyline feature data in shapefile form\nThe code chunk below uses st_read() function of sf package to import CyclingPath shape file into R as line feature data frame.\n\ncyclingpath = st_read(dsn = \"data/geospatial\", layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\sihuihui\\ISSS624\\Hands-on_Ex1\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\nFrom the above, we know that cyclingpath has a total of 2558 features and 2 fields, is a multilinestring, and is in svy21 projected coordinates system.\n\n\n3.3 Importing GIS data in kml format\nWe will also use st_read() to import GIS data in kml format:\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\sihuihui\\ISSS624\\Hands-on_Ex1\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nFrom the above, we know that preschool has 2290 features and 2 fields, a point feature data frame, and is in wgs84 coordinates system."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1a.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex1/Hands-on_Ex1a.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "4 Checking the Content of A Simple Feature Data Frame",
    "text": "4 Checking the Content of A Simple Feature Data Frame\nWe will use different ways to retrieve information related to the content of a simple feature data frame.\n\n4.1 Working with st_geometry()\nst_geometry() only displays basic information of the feature class such as type of geometry, the geographic extent of the features and the coordinate system of the data.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\n\n\n4.2 Working with glimpse()\nglimpse() reveals the data type of each fields. \n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n4.3 Working with head()\nWhile glimpse() displays all the variables in the feature object, head() reveals the complete information of a feature object, which gives us a snapshot of the simple feature data frame.\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1a.html#plotting-geospatial-data",
    "href": "Hands-on_Ex1/Hands-on_Ex1a.html#plotting-geospatial-data",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "5 Plotting Geospatial Data",
    "text": "5 Plotting Geospatial Data\nOther than looking at feature information we should also visualise geospatial features. plot() is a quick and useful way to plot geospatial features:\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\nplot() returns us a multi-plot of all attributes, up to a reasonable maximum as shown above. We can choose to plot only the geometry by using the code chunk below.\n\nplot(st_geometry(mpsz))\n\n\n\n\nAlternatively, we can also choose the plot the sf object by using a specific attribute as shown in the code chunk below.\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1a.html#working-with-projection",
    "href": "Hands-on_Ex1/Hands-on_Ex1a.html#working-with-projection",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "6 Working with Projection",
    "text": "6 Working with Projection\n\n6.1 Assigning EPSG code to a simple feature data frame\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n6.2 Transforming the projection of preschool from wgs84 to svy21\n\nst_crs(preschool)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\npreschool3414 &lt;- st_transform(preschool, crs = 3414)\n\n\nst_crs(preschool3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1a.html#importing-and-converting-an-aspatial-data",
    "href": "Hands-on_Ex1/Hands-on_Ex1a.html#importing-and-converting-an-aspatial-data",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "7 Importing and Converting an Aspatial Data",
    "text": "7 Importing and Converting an Aspatial Data\nIn this section, we will import an aspatial data into R environment and save it as a tibble data frame. Then, convert it into a simple feature data frame using the x- and y- coordinates in listing of Inside Airbnb data.\n\n7.1 Importing the aspatial data\nWe use read_csv() of readr package to import the aspatial data in. The output is listings and it is a tibble data frame;\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3483 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): name, host_name, neighbourhood_group, neighbourhood, room_type, l...\ndbl  (11): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe check the imported data using list() of Base R.\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,483 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,473 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nThe output reveals that listing tibble data frame consists of 4252 rows and 16 columns. We will be using the latitude and longitude from listings to create a simple feature data frame.\n\n\n7.2 Creating a simple feature data frame from an aspatial data frame\nThe code chunk below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nlistings_sf &lt;- st_as_sf(listings, coords = c(\"longitude\", \"latitude\"), crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nWe then use glimpse() to examine the content of the newly created simple feature data frame.\n\nglimpse(listings_sf)\n\nRows: 3,483\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 55, 69, 220, 85, 75, 45, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 20, 24, 47, 22, 17, 12, 133, 18, 6, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.14, 0.16, 0.31, 0.17, 0.12, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 52, 52, 5, 7, 52, 52, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 89, 89, 89, 275, 274, 89, 365, 365, 365…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 3, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nTable above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1a.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex1/Hands-on_Ex1a.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "8 Geoprocessing with sf package",
    "text": "8 Geoprocessing with sf package\nIn this section, we will learn to perform tow commonly used geoprocessing functions: buffering and point in polygon count.\n\n8.1 Buffering\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, dist = 5, nQuadSegs = 30)\n\nThen, calculate the area of the buffers:\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nThen sum the total area to derive the total land involved.\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]\n\n\n\n\n8.2 Point-in-polygon Count\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\nFirst, we calculate the number of preschools in each subzone:\n\nmpsz3414$'PreSch Count' &lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nThen, check the summary statistics of the PreSch count filed using summary():\n\nsummary(mpsz3414$'PreSch Count')\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nWe use top_n() to list the planning subzone with the most number of pre-school:\n\ntop_n(mpsz3414, 1, 'PreSch Count')\n\nSimple feature collection with 323 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...            0\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...            6\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...            0\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...            5\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...            3\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...           13\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...            5\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...            1\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...           11\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...            1\n\n\nTo calculate the density of pre-school by planning subzone. we first derivethe area of each planning subzone:\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;% \n  st_area()\n\nThen use mutate() to compute the density of preschool by planning subzone\n\nmpsz3414 &lt;- mpsz3414 %&gt;% \n    mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1a.html#exploratory-data-analysis",
    "href": "Hands-on_Ex1/Hands-on_Ex1a.html#exploratory-data-analysis",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "9 Exploratory Data Analysis",
    "text": "9 Exploratory Data Analysis\nIn this section, we will learn how to use appropriate ggplot2 functions to create statistical graphs for exploratory data analysis purposes.\nOne quick way to plot the preschool density is to use hist() of R graphics:\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\nHowever hist() has limited room for further customisation. Hence, we will use functions from ggplot2:\n\nggplot(data = mpsz3414,\n       aes(x = as.numeric(`PreSch Density`))) + \n  geom_histogram(bins = 20,\n                 color = \"black\",\n                fill = \"light blue\") + \n  labs(title = \"Are Pre-Schools Evenly Distributed in Singapore?\",\n       subtitle = \"There are many planning subszones with a single pre-school, on the other hand, \\nthere are two planning subszones with at least 20 preschools\",\n       x = \"PreSchool Density (per km sq)\",\n       y = \"Frequency\")\n\n\n\n\nScatterplot showing the relationship between pre-school density and pre-school count.\n\nggplot(data = mpsz3414,\n       aes(y = `PreSch Count`,\n         x = as.numeric(`PreSch Density`))) +\n  geom_point(color = \"blue\") + \n  xlim(0, 40) + \n  ylim(0, 40) + \n  labs(title = \"Scatter Plot of PreSchool Density and PreSchool Count\", \n       x = \"PreSchool Density (per km sq)\", \n       y = \"PreSchool Count\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1b.html",
    "href": "Hands-on_Ex1/Hands-on_Ex1b.html",
    "title": "Hands-on Exercise 1B: Choropleth Mapping with R",
    "section": "",
    "text": "In this hands-on exercise, I will be sharing how to plot functional and truthful choropleth maps using an R package tmap."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1b.html#overview",
    "href": "Hands-on_Ex1/Hands-on_Ex1b.html#overview",
    "title": "Hands-on Exercise 1B: Choropleth Mapping with R",
    "section": "",
    "text": "In this hands-on exercise, I will be sharing how to plot functional and truthful choropleth maps using an R package tmap."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1b.html#getting-started",
    "href": "Hands-on_Ex1/Hands-on_Ex1b.html#getting-started",
    "title": "Hands-on Exercise 1B: Choropleth Mapping with R",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Packages\nFor this exercise, we will be using tmap, sf and tidyverse packages. The code chunk below loads tmap, sf and tidyverse packages into R environment.\n\npacman::p_load(tmap, sf, tidyverse)\n\n\n\n\n\n\n\nNote\n\n\n\nNote that we will be using the readr, tidyr and dplyr packages which are part of the tidyverse package.\n\n\n\n\n2.2 Data Acquisition\nThe datasets we are using are downloaded from the following sources:\n\nMaster Plan 2014 Subzone Boundary (Web): data.gov.sg.\nSingapore Residents by Planning Area/Subzone, Age, Group, Sex and Type of Dwelling, June 2011 - 2020: Department of Statistics, Singapore."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1b.html#importing-data",
    "href": "Hands-on_Ex1/Hands-on_Ex1b.html#importing-data",
    "title": "Hands-on Exercise 1B: Choropleth Mapping with R",
    "section": "3 Importing Data",
    "text": "3 Importing Data\n\n3.1 Importing Geospatial Data\nThe code chunk below uses st_read() function of sf package to import the planning subzones, which is a polygon feature data frame.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\sihuihui\\ISSS624\\Hands-on_Ex1\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nLet’s take a look at the contents of mpsz using the following code chunk:\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n3.2 Importing Attribute Data\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesexfa2011to2020.csv\")\n\nRows: 738492 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, FA\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nLet’s take a look at the data imported in:\n\nlist(popdata)\n\n[[1]]\n# A tibble: 738,492 × 7\n   PA         SZ                     AG     Sex     FA              Pop  Time\n   &lt;chr&gt;      &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;\n 1 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   &lt;= 60             0  2011\n 2 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   &gt;60 to 80        10  2011\n 3 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   &gt;80 to 100       30  2011\n 4 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   &gt;100 to 120      80  2011\n 5 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   &gt;120             20  2011\n 6 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Not Available     0  2011\n 7 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females &lt;= 60             0  2011\n 8 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females &gt;60 to 80        10  2011\n 9 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females &gt;80 to 100       40  2011\n10 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females &gt;100 to 120      90  2011\n# ℹ 738,482 more rows\n\n\nNote: We can do some exploratory data analysis after importing the data. For example, plot charts to understand the population data."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1b.html#data-preparation",
    "href": "Hands-on_Ex1/Hands-on_Ex1b.html#data-preparation",
    "title": "Hands-on Exercise 1B: Choropleth Mapping with R",
    "section": "4 Data Preparation",
    "text": "4 Data Preparation\nBefore a thematic map can be prepared, we need to prepare a data table with 2020 values. The data table should include the following variables:\n\nPA\nSZ\nYOUNG: age group 0 to 4 until age group 20 to 24\nECONOMY ACTIVE: age group 20 to 29 up till age group 60 to 64\nAGED: age group 65 and above\nTOTAL: all age group\nDEPENDENCY: the ratio between YOUNG and AGED against ECONOMY ACTIVE group\n\n\n4.1 Data Wrangling\nWe will be using the following functions from tidyverse package:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = AG,\n              values_from = POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         + rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\n         rowSums(.[13:15])) %&gt;%\nmutate(`AGED` = rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL` = rowSums(.[3:21])) %&gt;%\nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)/ `ECONOMY ACTIVE`) %&gt;%\nselect(`PA`,`SZ`, `YOUNG`,\n        `ECONOMY ACTIVE`, `AGED`,\n        `TOTAL`,`DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n4.2 Joining Attribute Data and Geospatial Data\nWe will convert the values in PA and SZ files to uppercase because the values of PA and SZ fields are made up of upper and lower case while the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ),\n            .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nℹ Please use a list of either functions or lambdas:\n\n# Simple named list: list(mean = mean, median = median)\n\n# Auto named with `tibble::lst()`: tibble::lst(mean, median)\n\n# Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n\n\nThen, we will use left_join() of dplyr to join the geographical data and trribute table using planning subzone name (SUBZON_N and SZ) as the common identifiers.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1b.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex1/Hands-on_Ex1b.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 1B: Choropleth Mapping with R",
    "section": "5 Choropleth Mapping Geospatial Data Using tmap",
    "text": "5 Choropleth Mapping Geospatial Data Using tmap\nTo prepare thematic map using tmap, we can:\n\nPlot a thematic map quickly using qtm().\nPlot highly customisable thematic map by using tmap elements.\n\n\n5.1 Plotting a choropleth map quickly using qtm()\nThe code chunk below draws a cartographic standard choropleth map.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, fill = \"DEPENDENCY\")\n\n\n\n\n\n\n5.2 Creating a choropleth map by using tmap’s elements\nTo draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"Dependency ratio\") + \n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) + \n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) + \n  tm_scale_bar() +\n  tm_grid(alpha = 0.2) +\n  tm_credits(\"Source: Planning Subzone boundary from Urban Redevelopment Authority (URA) \\n and Population data from Department of Statistics (DOS)\",\n             position = c(\"left\", \"bottom\"))\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n5.2.1 Drawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons.\n\n tm_shape(mpsz_pop2020) + \n   tm_polygons()\n\n\n\n\n\n\n5.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we can assign the target variable (e.g. Dependency) to tm_polygons().\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n5.2.3 Drawing a choropleth map using tm_fill() and tm_border()\ntm_polygons is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\") + \n  tm_borders(lw = 0.1, alpha = 1)\n\n\n\n\n\n\n\n5.3 Data Classification Methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n5.3.1 Plotting choropleth maps with built-in classification methods\nThe code chunk below shows a jenks data classification that used 5 classes\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\", \n          n = 5, \n          style = \"jenks\") + \n  tm_borders(alpha = 0.5)\n\n\n\n\nThe code chunk below uses the equal data classification method.\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\", \n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n5.3.2 Plotting choropleth map with custom break\nWe can also compute our own category breaks.\nFirst, we will compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.7113  0.7926  0.8561  0.8786 19.0000      92 \n\n\nUsing the above results, we set the break points at 0.60, 0.70, 0.80, 0.90, and 0 will be the minimum while 1 will be the maximum.\nWe plot the choropleth map using the following code chunk:\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", \n          breaks = c(0.0,0.60,0.70,0.80, 0.90, 1.00)) + \n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\n5.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n5.4.1 Using ColourBrewer palette\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\", \n          n = 6,\n          style = \"quantile\", \n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nTo revese the colour shading, add a “-” prefix under “palette”.\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\", \n          n = 6, \n          style = \"quantile\",\n          palette = \"-Greens\") + \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n5.5 Map Layouts\n\n5.5.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\",\n          palette = \"Blues\", \n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n (Jenks Classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) + \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n5.5.2 Map Style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\",\n          palette = \"-Greens\") + \n  tm_borders(alpha = 0.5) + \n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n5.5.3 Cartographic Furniture\ntmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\", style = \"quantile\",\n          palette = \"Blues\", \n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n (Based on Quantile)\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) + \n  tm_borders(alpha = 0.5) + \n  tm_compass(type = \"8star\", size = 2) + \n  tm_scale_bar(width = 0.15) + \n  tm_grid(lwd = 0.1, alpha = 0.2) + \n  tm_credits(\"Source: Planning Subzone boundary from Urban Redevelopment Authority (URA) \\n and Population data from Department of Statistics (DOS)\",\n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n5.6 Drawing Multiple Small Choropleth Maps\nIn tmap, small multiple maps (also known as facet maps) can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n5.6.1 By assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\")+\n  tm_layout(legend.position = c(\"right\", \"bottom\")) + \n  tm_borders(alpha = 0.5) + \n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(c(\"DEPENDENCY\", \"AGED\"),\n              style = c(\"equal\", \"quantile\"),\n              palette = list(\"Blues\", \"Greens\")) + \n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n5.6.2 By defining a group-by variable in tm_facets()\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords = TRUE,\n            drop.shapes = TRUE) + \n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"),\n            title.size = 20) + \n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n5.6.3 By creating multiple stand-alone maps with tmap_arrange()\n\nyoungmap &lt;- tm_shape(mpsz_pop2020) + \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\",\n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020) + \n  tm_polygons(\"AGED\", \n              style = \"quantile\",\n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n5.7 Mapping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N == \"CENTRAL REGION\", ]) +\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\",\n          palette = \"Blues\",\n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1)+\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45,\n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"), \n            frame = FALSE) + \n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1a.html#working-with-map-projection",
    "href": "Hands-on_Ex1/Hands-on_Ex1a.html#working-with-map-projection",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "6 Working with MAP Projection",
    "text": "6 Working with MAP Projection\nMap projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system. In this section, we will project a simple feature data frame from one coordinate sstem to another coordinate system.\n\n6.1 Assigning EPSG code to a simple feature data frame\nFirst, we will check the coordinate system of mpsz simple feature data frame using st_crs() of sf package:\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in svy21, the above results shows that the EPSG is 9001, which is the wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nHence we will assign the correct EPSG code to mpsz data frame using st_set_crs() of sf package:\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nWe will check the coordinate system of mpsz simple feature data frame using st_crs() and we should see that the EPSG code is now 3414.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n6.2 Transforming the projection of preschool from wgs84 to svy21\nUsing st_crs(), we check the projection of preschool data frame and note that it is in wgs84 coordinate system.\n\nst_crs(preschool)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nAs preschool is in wgs84 coordinate system, we will need to reproject preschool from a wgs84 coordinate system to svy21 coordinate system using st_transform() function. Note that st_transform() converts or transformates coordinates of simple feature while st_set_crs() change the coordinate reference system without modifying any coordinates.\n\npreschool3414 &lt;- st_transform(preschool, crs = 3414)\n\nWe will check the projection of preschool data frame.\n\nst_crs(preschool3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "In-class_Ex1/In-class_Ex1.html#getting-started",
    "href": "In-class_Ex1/In-class_Ex1.html#getting-started",
    "title": "In-class_Ex1",
    "section": "2 Getting Started",
    "text": "2 Getting Started"
  },
  {
    "objectID": "In-class_Ex1/data/MPSZ-2019/MPSZ-2019.html",
    "href": "In-class_Ex1/data/MPSZ-2019/MPSZ-2019.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#getting-started",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#getting-started",
    "title": "In-Class Exercise 1: My First Date with Geospatial Data Analytics",
    "section": "2 Getting Started",
    "text": "2 Getting Started\nWe will first load the necessary packages using the following code chunk:\n\ntmap: for thematic mapping\nsf: for geospatial data handling\ntidyverse: for non-spatial data handling\n\n\npacman::p_load(tmap, sf, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/data/spatial/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex1/data/spatial/MPSZ-2019.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html",
    "title": "In-Class Exercise 1: My First Date with Geospatial Data Analytics",
    "section": "",
    "text": "For this task, we are required to prepare a choropleth map showing the distribution of passenger trips across the planning sub-zones."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#overview",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#overview",
    "title": "In-class Exercise 1: My first date with Geospatial Data Analytics",
    "section": "",
    "text": "This in-class exercise will share with us how"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#preparing-the-flow-data",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#preparing-the-flow-data",
    "title": "In-class Exercise 1: My first date with Geospatial Data Analytics",
    "section": "2 Preparing the Flow Data",
    "text": "2 Preparing the Flow Data\n\n2.1 Importing the OD data\nWe will import the Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall by using read_csv() of readr package.\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\n\nWe convert the chr data type to categories using as.factor().\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE)\n\n\n\n2.2 Extracting the Study Data\nWe will extract the study data using filter(), group_by() and summarise() to get weekday trips that start from 7am and end before 10am.\n\norigintrip_7_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 7 & TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#working-with-geospatial-data",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#working-with-geospatial-data",
    "title": "In-class Exercise 1: My First Date with Geospatial Data Analytics",
    "section": "3 Working with Geospatial Data",
    "text": "3 Working with Geospatial Data\nWe will use st_read() from sf package to read the geospatial data and use st_transform() from sf package to project the data into svy21 using its ESPG code 3414.\n\nbusstop &lt;- st_read(dsn = \"data/spatial\", layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `C:\\sihuihui\\ISSS624\\In-class_Ex\\In-class_Ex1\\data\\spatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\nLet us take a look at the imported data:\n\nbusstop\n\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   BUS_STOP_N BUS_ROOF_N             LOC_DESC                  geometry\n1       22069        B06   OPP CEVA LOGISTICS POINT (13576.31 32883.65)\n2       32071        B23         AFT TRACK 13 POINT (13228.59 44206.38)\n3       44331        B01              BLK 239  POINT (21045.1 40242.08)\n4       96081        B05 GRACE INDEPENDENT CH POINT (41603.76 35413.11)\n5       11561        B05              BLK 166 POINT (24568.74 30391.85)\n6       66191        B03         AFT CORFE PL POINT (30951.58 38079.61)\n7       23389       B02A              PEC LTD   POINT (12476.9 32211.6)\n8       54411        B02              BLK 527 POINT (30329.45 39373.92)\n9       28531        B09              BLK 536 POINT (14993.31 36905.61)\n10      96139        B01              BLK 148  POINT (41642.81 36513.9)\n\n\n\nmpsz &lt;- st_read(dsn = \"data/spatial\", layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\sihuihui\\ISSS624\\In-class_Ex\\In-class_Ex1\\data\\spatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nLet us take a look at the imported data:\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26..."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#section",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#section",
    "title": "In-class Exercise 1: My first date with Geospatial Data Analytics",
    "section": "4 ",
    "text": "4"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1a.html",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1a.html",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, I will be sharing how to import and wrangle geospatial data using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1a.html#overview",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, I will be sharing how to import and wrangle geospatial data using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1a.html#getting-started",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Packages\nFor this exercise, we will be using sf and tidyverse packages. The code chunk below installs and loads sf and tidyverse packages into R environment.\n\npacman::p_load(sf, tidyverse)\n\n\n\n2.2 Data Acquisition and Extraction\nWe will extract the following data sets from these sources:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\nAfter we have downloaded these data sets, we created a sub-folder called data. Within the datasub-folder, we created 2 sub-folders, namely geospatial and aspatial. Master Plan 2014 Subzone Boundary (Web), Pre-Schools Location and Cycling Path files should be placed in the geospatial folder while the Singapore Airbnb listing data should be in the aspatial folder."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1a.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1a.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "3 Importing Geospatial Data",
    "text": "3 Importing Geospatial Data\n\n3.1 Importing polygon feature data\nThe code chunk below uses st_read() function of sf package to import the planning subzones, which is a polygon feature data frame.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\sihuihui\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe message above also tells us that mpsz’s geometry type is multipolygon, there are a total of 323 multipolygon features and 15 fields in mpsz and it is in svy21 projected coordinates systems.\n\n\n3.2 Importing polyline feature data in shapefile form\nThe code chunk below uses st_read() function of sf package to import CyclingPath shape file into R as line feature data frame.\n\ncyclingpath = st_read(dsn = \"data/geospatial\", layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\sihuihui\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\nFrom the above, we know that cyclingpath has a total of 2558 features and 2 fields, is a multilinestring, and is in svy21 projected coordinates system.\n\n\n3.3 Importing GIS data in kml format\nWe will also use st_read() to import GIS data in kml format:\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\sihuihui\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nFrom the above, we know that preschool has 2290 features and 2 fields, a point feature data frame, and is in wgs84 coordinates system."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1a.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1a.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "4 Checking the Content of A Simple Feature Data Frame",
    "text": "4 Checking the Content of A Simple Feature Data Frame\nWe can use different ways to retrieve information related to the content of a simple feature data frame.\n\n4.1 Working with st_geometry()\nst_geometry() displays basic information of the feature class such as type of geometry, the geographic extent of the features and the coordinate system of the data.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\n\n\n4.2 Working with glimpse()\nglimpse() reveals the data type of each fields. \n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n4.3 Working with head()\nWhile glimpse() displays all the variables in the feature object, head() reveals the complete information of a feature object, which gives us a snapshot of the simple feature data frame.\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\n\n\n\n\n\nInteresting info found!\n\n\n\nHere is an article on the difference between glimpse() and head().\n\n“the head() function shows the first few rows (observations) of the Data Frame. The glimpse() function displays the number of observations, and variables (columns) along with the type, name, and values of the latter.”"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1a.html#plotting-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1a.html#plotting-geospatial-data",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "5 Plotting Geospatial Data",
    "text": "5 Plotting Geospatial Data\nOther than looking at feature information, we should also visualise geospatial features. plot() is a quick and useful way to plot geospatial features:\n\nplot(mpsz)\n\n\n\n\nplot() returns us a multi-plot of all attributes, up to a reasonable maximum as shown above.\n\n\n\n\n\n\nNote\n\n\n\nIf plot() is unable to plot all attributes, a warning would appear.\n\n\nWe can choose to plot only the geometry using the code chunk below.\n\nplot(st_geometry(mpsz))\n\n\n\n\nAlternatively, we can also choose the plot the sf object by using a specific attribute as shown in the code chunk below.\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe will learn more about plotting high cartographic quality plots using tmap package in Hands-On Exercise 1B."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1a.html#working-with-map-projection",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1a.html#working-with-map-projection",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "6 Working with MAP Projection",
    "text": "6 Working with MAP Projection\nMap projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system. In this section, we will project a simple feature data frame from one coordinate sstem to another coordinate system.\n\n\n\n\n\n\nNote\n\n\n\nYou can read more about map projections in general here and Singapore’s map projections here.\n\n\n\n6.1 Assigning EPSG code to a simple feature data frame\nFirst, we will check the coordinate system of mpsz simple feature data frame using st_crs() of sf package:\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in svy21, the above results shows that the EPSG is 9001, which is the wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nHence we will assign the correct EPSG code to mpsz data frame using st_set_crs() of sf package:\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nWe will check the coordinate system of mpsz simple feature data frame using st_crs() and we should see that the EPSG code is now 3414.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n6.2 Transforming the projection of preschool from wgs84 to svy21\nUsing st_crs(), we check the projection of preschool data frame:\n\nst_crs(preschool)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nAs preschool is in wgs84 coordinate system, we will need to reproject preschool from a wgs84 coordinate system to svy21 coordinate system using st_transform() .\n\n\n\n\n\n\nNote\n\n\n\nNote that st_transform() converts or transforms coordinates of simple feature while st_set_crs() change the coordinate reference system without modifying any coordinates.\n\n\n\npreschool3414 &lt;- st_transform(preschool, crs = 3414)\n\nWe will check the projection of preschool data frame:\n\nst_crs(preschool3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1a.html#importing-and-converting-an-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1a.html#importing-and-converting-an-aspatial-data",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "7 Importing and Converting an Aspatial Data",
    "text": "7 Importing and Converting an Aspatial Data\nIn this section, we will import an aspatial data into R environment and save it as a tibble data frame. Then, convert it into a simple feature data frame using the x- and y- coordinates in listing of Inside Airbnb data.\n\n7.1 Importing the aspatial data\nWe use read_csv() of readr package to import the aspatial data in. The output is listings and it is a tibble data frame;\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nWe check the imported data using list() of Base R.\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,483 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,473 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nThe output reveals that listing tibble data frame consists of 4252 rows and 16 columns. We will be using the latitude and longitude from listings to create a simple feature data frame.\n\n\n7.2 Creating a simple feature data frame from an aspatial data frame\nThe code chunk below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nlistings_sf &lt;- st_as_sf(listings, coords = c(\"longitude\", \"latitude\"), crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nWe then use glimpse() to examine the content of the newly created simple feature data frame.\n\nglimpse(listings_sf)\n\nRows: 3,483\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 55, 69, 220, 85, 75, 45, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 20, 24, 47, 22, 17, 12, 133, 18, 6, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.14, 0.16, 0.31, 0.17, 0.12, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 52, 52, 5, 7, 52, 52, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 89, 89, 89, 275, 274, 89, 365, 365, 365…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 3, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nTable above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1a.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1a.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "8 Geoprocessing with sf package",
    "text": "8 Geoprocessing with sf package\nIn this section, we will learn to perform tow commonly used geoprocessing functions: buffering and point in polygon count.\n\n8.1 Buffering\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, dist = 5, nQuadSegs = 30)\n\nThen, calculate the area of the buffers:\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nThen sum the total area to derive the total land involved.\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]\n\n\n\n\n8.2 Point-in-polygon Count\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\nFirst, we calculate the number of preschools in each subzone:\n\nmpsz3414$'PreSch Count' &lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nThen, check the summary statistics of the PreSch count filed using summary():\n\nsummary(mpsz3414$'PreSch Count')\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nWe use top_n() to list the planning subzone with the most number of pre-school:\n\ntop_n(mpsz3414, 1, 'PreSch Count')\n\nSimple feature collection with 323 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...            0\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...            6\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...            0\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...            5\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...            3\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...           13\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...            5\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...            1\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...           11\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...            1\n\n\nTo calculate the density of pre-school by planning subzone. we first derives the area of each planning subzone:\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;% \n  st_area()\n\nThen use mutate() to compute the density of preschool by planning subzone\n\nmpsz3414 &lt;- mpsz3414 %&gt;% \n    mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1a.html#exploratory-data-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1a.html#exploratory-data-analysis",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "9 Exploratory Data Analysis",
    "text": "9 Exploratory Data Analysis\nIn this section, we will learn how to use appropriate ggplot2 functions to create statistical graphs for exploratory data analysis purposes.\nOne quick way to plot the preschool density is to use hist() of R graphics:\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\nHowever hist() has limited room for further customisation. Hence, we will use functions from ggplot2:\n\nggplot(data = mpsz3414,\n       aes(x = as.numeric(`PreSch Density`))) + \n  geom_histogram(bins = 20,\n                 color = \"black\",\n                fill = \"light blue\") + \n  labs(title = \"Are Pre-Schools Evenly Distributed in Singapore?\",\n       subtitle = \"There are many planning subszones with a single pre-school, on the other hand, \\nthere are two planning subszones with at least 20 preschools\",\n       x = \"PreSchool Density (per km sq)\",\n       y = \"Frequency\")\n\n\n\n\nHere is a scatterplot showing the relationship between pre-school density and pre-school count.\n\nggplot(data = mpsz3414,\n       aes(y = `PreSch Count`,\n         x = as.numeric(`PreSch Density`))) +\n  geom_point(color = \"blue\") + \n  xlim(0, 40) + \n  ylim(0, 40) + \n  labs(title = \"Scatter Plot of PreSchool Density and PreSchool Count\", \n       x = \"PreSchool Density (per km sq)\", \n       y = \"PreSchool Count\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1b.html",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1b.html",
    "title": "Hands-on Exercise 1B: Choropleth Mapping with R",
    "section": "",
    "text": "In this hands-on exercise, I will be sharing how to plot functional and truthful choropleth maps using an R package tmap."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1b.html#overview",
    "title": "Hands-on Exercise 1B: Choropleth Mapping with R",
    "section": "",
    "text": "In this hands-on exercise, I will be sharing how to plot functional and truthful choropleth maps using an R package tmap."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1b.html#getting-started",
    "title": "Hands-on Exercise 1B: Choropleth Mapping with R",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Packages\nFor this exercise, we will be using tmap, sf and tidyverse packages. The code chunk below loads tmap, sf and tidyverse packages into R environment.\n\npacman::p_load(tmap, sf, tidyverse)\n\n\n\n\n\n\n\nNote\n\n\n\nWe will be using the readr, tidyr and dplyr packages which are part of the tidyverse package.\n\n\n\n\n2.2 Data Acquisition\nThe datasets we are using are downloaded from the following sources:\n\nMaster Plan 2014 Subzone Boundary (Web): data.gov.sg.\nSingapore Residents by Planning Area/Subzone, Age, Group, Sex and Type of Dwelling, June 2011 - 2020: Department of Statistics, Singapore."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1b.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1b.html#importing-data",
    "title": "Hands-on Exercise 1B: Choropleth Mapping with R",
    "section": "3 Importing Data",
    "text": "3 Importing Data\n\n3.1 Importing Geospatial Data\nThe code chunk below uses st_read() function of sf package to import the planning subzones, which is a polygon feature data frame.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\sihuihui\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nLet’s take a look at the contents of mpsz using the following code chunk:\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n3.2 Importing Attribute Data\nWe will use read_csv()\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesexfa2011to2020.csv\")\n\nLet’s take a look at the data imported in:\n\nlist(popdata)\n\n[[1]]\n# A tibble: 738,492 × 7\n   PA         SZ                     AG     Sex     FA              Pop  Time\n   &lt;chr&gt;      &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;\n 1 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   &lt;= 60             0  2011\n 2 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   &gt;60 to 80        10  2011\n 3 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   &gt;80 to 100       30  2011\n 4 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   &gt;100 to 120      80  2011\n 5 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   &gt;120             20  2011\n 6 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Not Available     0  2011\n 7 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females &lt;= 60             0  2011\n 8 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females &gt;60 to 80        10  2011\n 9 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females &gt;80 to 100       40  2011\n10 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females &gt;100 to 120      90  2011\n# ℹ 738,482 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe can do some exploratory data analysis after importing the data. For example, plot charts to understand more about the population data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1b.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1b.html#data-preparation",
    "title": "Hands-on Exercise 1B: Choropleth Mapping with R",
    "section": "4 Data Preparation",
    "text": "4 Data Preparation\nBefore a thematic map can be prepared, we need to prepare a data table just for year 2020 values. The data table should include the following variables:\n\nPA\nSZ\nYOUNG: age group 0 to 4 until age group 20 to 24\nECONOMY ACTIVE: age group 20 to 29 up till age group 60 to 64\nAGED: age group 65 and above\nTOTAL: all age group\nDEPENDENCY: the ratio between YOUNG and AGED against ECONOMY ACTIVE group\n\n\n4.1 Data Wrangling\nWe will be using the following functions from tidyverse package:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = AG,\n              values_from = POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         + rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\n         rowSums(.[13:15])) %&gt;%\nmutate(`AGED` = rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL` = rowSums(.[3:21])) %&gt;%\nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)/ `ECONOMY ACTIVE`) %&gt;%\nselect(`PA`,`SZ`, `YOUNG`,\n        `ECONOMY ACTIVE`, `AGED`,\n        `TOTAL`,`DEPENDENCY`)\n\n\n\n4.2 Joining Attribute Data and Geospatial Data\nWe will convert the values in PA and SZ files to uppercase because the values of PA and SZ fields are made up of upper and lower case while the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ),\n            .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nThen, we will use left_join() of dplyr to join the geographical data and trribute table using planning subzone name (SUBZON_N and SZ) as the common identifiers.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1b.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1b.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 1B: Choropleth Mapping with R",
    "section": "5 Choropleth Mapping Geospatial Data Using tmap",
    "text": "5 Choropleth Mapping Geospatial Data Using tmap\nTo prepare thematic map using tmap, we can:\n\nPlot a thematic map quickly using qtm().\nPlot highly customisable thematic map by using tmap elements.\n\n\n5.1 Plotting a choropleth map quickly using qtm()\nThe code chunk below draws a cartographic standard choropleth map.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, fill = \"DEPENDENCY\")\n\n\n\n\n\n\n5.2 Creating a choropleth map by using tmap’s elements\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n5.2.1 Drawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons.\n\n tm_shape(mpsz_pop2020) + \n   tm_polygons()\n\n\n\n\n\n\n5.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we can assign the target variable (e.g. Dependency) to tm_polygons().\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n5.2.3 Drawing a choropleth map using tm_fill() and tm_border()\ntm_polygons is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\") + \n  tm_borders(lw = 0.1, alpha = 1)\n\n\n\n\n\n\n5.2.4 Putting it all together\nTo draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020) +    \n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,             \n            legend.height = 0.45,             \n            legend.width = 0.35,             \n            frame = TRUE) +    \n  tm_borders(alpha = 0.5) +   \n  tm_compass(type = \"8star\", size = 2) +    \n  tm_scale_bar() +   \n  tm_grid(alpha = 0.2) +   \n  tm_credits(\"Source: Planning Subzone boundary from Urban Redevelopment Authority (URA) \\n and Population data from Department of Statistics (DOS)\",              \n             position = c(\"left\", \"bottom\")) \n\n\n\n\n\n\n\n5.3 Data Classification Methods of tmap\nMost choropleth maps use some methods of data classification in order to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\n\n\n\n\n\n\nNote\n\n\n\nFor more information on data classification for choropleth maps, you can refer here.\n\n\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n5.3.1 Plotting choropleth maps with built-in classification methods\nThe code chunk below shows a jenks data classification that used 5 classes\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\", \n          n = 5, \n          style = \"jenks\") + \n  tm_borders(alpha = 0.5)\n\n\n\n\nThe code chunk below uses the equal data classification method.\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\", \n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n5.3.2 Plotting choropleth map with custom break\nWe can also compute our own category breaks.\nFirst, we will compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.7113  0.7926  0.8561  0.8786 19.0000      92 \n\n\nUsing the above results, we set the break points at 0.60, 0.70, 0.80, 0.90, and 0 will be the minimum while 1 will be the maximum.\nWe plot the choropleth map with our customised breaks using the following code chunk:\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", \n          breaks = c(0.0,0.60,0.70,0.80, 0.90, 1.00)) + \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n5.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n5.4.1 Using ColourBrewer palette\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\", \n          n = 6,\n          style = \"quantile\", \n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nTo revese the colour shading, add a “-” prefix under “palette”.\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\", \n          n = 6, \n          style = \"quantile\",\n          palette = \"-Greens\") + \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n5.5 Map Layouts\n\n5.5.1 Map Legend\nIn tmap, several legend options are available to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\",\n          palette = \"Blues\", \n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n (Jenks Classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) + \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n5.5.2 Map Style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\",\n          palette = \"-Greens\") + \n  tm_borders(alpha = 0.5) + \n  tmap_style(\"classic\")\n\n\n\n\n\n\n5.5.3 Cartographic Furniture\ntmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\", style = \"quantile\",\n          palette = \"Blues\", \n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n (Based on Quantile)\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) + \n  tm_borders(alpha = 0.5) + \n  tm_compass(type = \"8star\", size = 2) + \n  tm_scale_bar(width = 0.15) + \n  tm_grid(lwd = 0.1, alpha = 0.2) + \n  tm_credits(\"Source: Planning Subzone boundary from Urban Redevelopment Authority (URA) \\n and Population data from Department of Statistics (DOS)\",\n             position = c(\"left\", \"bottom\"))\n\n\n\n\nTo return to the previous map style, use the following code chunk:\n\ntmap_style(\"white\")\n\n\n\n\n5.6 Drawing Multiple Small Choropleth Maps\nIn tmap, small multiple maps (also known as facet maps) can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n5.6.1 By assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\")+\n  tm_layout(legend.position = c(\"right\", \"bottom\")) + \n  tm_borders(alpha = 0.5) + \n  tmap_style(\"white\")\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(c(\"DEPENDENCY\", \"AGED\"),\n              style = c(\"equal\", \"quantile\"),\n              palette = list(\"Blues\", \"Greens\")) + \n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n5.6.2 By defining a group-by variable in tm_facets()\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords = TRUE,\n            drop.shapes = TRUE) + \n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"),\n            title.size = 20) + \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n5.6.3 By creating multiple stand-alone maps with tmap_arrange()\n\nyoungmap &lt;- tm_shape(mpsz_pop2020) + \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\",\n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020) + \n  tm_polygons(\"AGED\", \n              style = \"quantile\",\n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n5.7 Mapping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N == \"CENTRAL REGION\", ]) +\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\",\n          palette = \"Blues\",\n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1)+\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45,\n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"), \n            frame = FALSE) + \n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#preparing-the-data",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#preparing-the-data",
    "title": "In-class Exercise 1: My First Date with Geospatial Data Analytics",
    "section": "2 Preparing the Data",
    "text": "2 Preparing the Data\n\n2.1 Importing the Origin Destination (OD) data\nWe will import the Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall by using read_csv() of readr package, which is part of tidyverse package.\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\n\nWe now take a peek at the imported data:\n\nglimpse(odbus)\n\nFrom the above, we see that ORIGIN_PT_CODE and DESTINATION_PT_CODE are character data type. We should convert these two columns from characters into factors because these two columns contains the bus stop numbers and we will need these bus stop numbers to get the bus stop locations in subsequent steps. We will use as.factor() to convert the data from character to factor.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE)\n\n\n\n\n\n\n\nDo you know?\n\n\n\nIn R, factors allow for ordered categories with a fixed set of acceptable values. Typically, we would convert a column from character or numeric class to a factor if we want to set an intrinsic order to the values (“levels”) so they can be displayed non-alphabetically in plots and tables.\nIf you are interested to read more about factors, this webpage has more interesting information and references.\n\n\n\n\n2.2 Extracting the Study Data\nWe will extract the study data using filter(), group_by() and summarise() to get our study data (i.e., weekday trips that start from 7am and end before 10am).\n\norigintrip_7_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 7 & TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))"
  },
  {
    "objectID": "Hands-on_Ex2a.html",
    "href": "Hands-on_Ex2a.html",
    "title": "Hands-on Exercise 2A",
    "section": "",
    "text": "Overview\nIn this exercise, we will learn how to compute spatial weights using R.\nGetting Started\nPackages\nData Acquisition\nData Wrangling\nVisualising Regional Development Indicator\nAbout Spatial Weights\nComputing Spatial Weights based on Contiguity\nQueen + visualising\nRook + visualising\nComputing Spatial Weights based on distance\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 1A: Geospatial Data Wrangling with R\n\n\n\n\n\n\nGoh Si Hui\n\n\nNovember 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 1B: Choropleth Mapping with R\n\n\n\n\n\n\nGoh Si Hui\n\n\nNovember 16, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#latest-content",
    "href": "index.html#latest-content",
    "title": "ISSS624: Applied Geospatial Analytics",
    "section": "1 Latest Content",
    "text": "1 Latest Content\n\n\n\n\n\n\n\n\nHands-on Exercise 1A: Geospatial Data Wrangling with R\n\n\n\n\n\n\nGoh Si Hui\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 1B: Choropleth Mapping with R\n\n\n\n\n\n\nGoh Si Hui\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 1: My First Date with Geospatial Data Analytics\n\n\n\n\n\n\nGoh Si Hui\n\n\nNov 18, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#hands-on-exercises",
    "href": "index.html#hands-on-exercises",
    "title": "ISSS624: Applied Geospatial Analytics",
    "section": "Hands-On Exercises",
    "text": "Hands-On Exercises\n\n\n\n\n\n\n\n\nHands-on Exercise 1A: Geospatial Data Wrangling with R\n\n\n\n\n\n\nGoh Si Hui\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 1B: Choropleth Mapping with R\n\n\n\n\n\n\nGoh Si Hui\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 2A: Spatial Weights and Applications\n\n\n\n\n\n\nGoh Si Hui\n\n\nNov 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 2B: Global and Local Measures of Spatial Autocorrelations\n\n\n\n\n\n\nGoh Si Hui\n\n\nNov 24, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#in-class-exercises",
    "href": "index.html#in-class-exercises",
    "title": "ISSS624: Applied Geospatial Analytics",
    "section": "In-Class Exercises",
    "text": "In-Class Exercises\n\n\n\n\n\n\n\n\nIn-Class Exercise 1: My First Date with Geospatial Data Analytics\n\n\n\n\n\n\nGoh Si Hui\n\n\nNov 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 2A: Spatial Weights\n\n\n\n\n\n\nGoh Si Hui\n\n\nNov 25, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 2B: Global and Local Spatial Autocorrelations\n\n\n\n\n\n\nGoh Si Hui\n\n\nNov 25, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 2C: Emerging Hot Spot Analysis\n\n\n\n\n\n\nGoh Si Hui\n\n\nNov 25, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#take-home-exercises",
    "href": "index.html#take-home-exercises",
    "title": "ISSS624",
    "section": "3 Take-home Exercises",
    "text": "3 Take-home Exercises"
  },
  {
    "objectID": "index.html#latest",
    "href": "index.html#latest",
    "title": "ISSS624: Applied Geospatial Analytics",
    "section": "Latest",
    "text": "Latest\n\n\n\n\n\n\n\n\nHands-on Exercise 1A: Geospatial Data Wrangling with R\n\n\n\n\n\n\nGoh Si Hui\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 1B: Choropleth Mapping with R\n\n\n\n\n\n\nGoh Si Hui\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#preparing-the-aspatial-data",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#preparing-the-aspatial-data",
    "title": "In-Class Exercise 1: My First Date with Geospatial Data Analytics",
    "section": "3 Preparing the Aspatial Data",
    "text": "3 Preparing the Aspatial Data\n\n3.1 Importing the Origin Destination (OD) data\nWe will import the Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall by using read_csv() of readr package, which is part of tidyverse package.\n\nCodesImported Data\n\n\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\n\n\n\n\nglimpse(odbus)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"4406…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"1722…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n\n\n\n\nFrom the above, we see that ORIGIN_PT_CODE and DESTINATION_PT_CODE are character data type. We should convert these two columns from characters into factors because these two columns contains the bus stop numbers and we will need these bus stop numbers to get the bus stop locations in subsequent steps. We will use as.factor() to convert the data from character to factor.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE)\n\n\n\n\n\n\n\nDo you know?\n\n\n\nIn R, factors allow for ordered categories with a fixed set of acceptable values. Typically, we would convert a column from character or numeric class to a factor if we want to set an intrinsic order to the values (“levels”) so they can be displayed non-alphabetically in plots and tables.\nIf you are interested to read more about factors, this webpage has more interesting information and references.\n\n\n\n\n3.2 Extracting the Study Data\nWe will extract the study data using filter(), group_by() and summarise() to get our study data (i.e., weekday trips that start from 7am and end before 10am).\n\nCodesData\n\n\n\norigintrip_7_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 7 & TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\n\n\nhead(origintrip_7_9)\n\n# A tibble: 6 × 2\n  ORIGIN_PT_CODE TRIPS\n  &lt;fct&gt;          &lt;dbl&gt;\n1 01012           1617\n2 01013            813\n3 01019           1620\n4 01029           2383\n5 01039           2727\n6 01059           1415"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#preparing-the-geospatial-data",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#preparing-the-geospatial-data",
    "title": "In-Class Exercise 1: My First Date with Geospatial Data Analytics",
    "section": "4 Preparing the Geospatial Data",
    "text": "4 Preparing the Geospatial Data\n\n4.1 Importing Geospatial Data\nWe will use st_read() from sf package to read the geospatial data and use st_transform() from sf package to project the data into svy21 using its ESPG code 3414.\n\nCodesOutput\n\n\n\nbusstop &lt;- st_read(dsn = \"data/spatial\", layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\n\n\n\n\nReading layer `BusStop' from data source \n  `C:\\sihuihui\\ISSS624\\In-class_Ex\\In-class_Ex1\\data\\spatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\n\n\nFrom the above, we know that the busstop data is a point feature data frame. There are a total of 5161 features and 3 fields, and it uses the svy21 projected coordinates system.\nWe will now bring in the master plan subzone dataset using the code chunk below.\n\nCodesOutput\n\n\n\nmpsz &lt;- st_read(dsn = \"data/spatial\", layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\n\n\n\n\nReading layer `MPSZ-2019' from data source \n  `C:\\sihuihui\\ISSS624\\In-class_Ex\\In-class_Ex1\\data\\spatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\n\n\nFrom the above, we know that the MPSZ-2019 data is a multipolygon feature data frame. There are a total of 332 features and 6 fields, and it uses the WGS84 geographic coordinates system."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#geospatial-data-wrangling",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#geospatial-data-wrangling",
    "title": "In-Class Exercise 1: My First Date with Geospatial Data Analytics",
    "section": "5 Geospatial Data Wrangling",
    "text": "5 Geospatial Data Wrangling\n\n5.1 Combining busstop and mpsz\nWe will now populate the planning subzone code (SUBZONE_C) of mpsz dataframe (multipolyon feature) into busstop (point feature) dataframe.\n\nCodesData\n\n\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\n\n\n\nhead(busstop_mpsz)\n\n     BUS_STOP_N SUBZONE_C\n1346      13099    RVSZ05\n5067      13089    RVSZ05\n839       06151    SRSZ01\n965       13211    SRSZ01\n974       13139    SRSZ01\n1197      13109    SRSZ01\n\n\n\n\n\nWe will save the output into rds format for future use.\n\nwrite_rds(busstop_mpsz, \"data/rds/busstop_mpsz.csv\")\n\nWe will then append the planning subzone code (SUBZONE_C) from busstop_mpsz data frame onto origintrip7_9 dataframe using the following code:\n\nCodesData\n\n\n\norigintrip_7_9_subzone &lt;- left_join(origintrip_7_9,busstop_mpsz,\n                                    by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE, \n         ORIGIN_SZ = SUBZONE_C)\n\n\n\n\nhead(origintrip_7_9_subzone)\n\n# A tibble: 6 × 3\n  ORIGIN_BS TRIPS ORIGIN_SZ\n  &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;    \n1 01012      1617 RCSZ10   \n2 01013       813 RCSZ10   \n3 01019      1620 DTSZ01   \n4 01029      2383 DTSZ01   \n5 01039      2727 DTSZ01   \n6 01059      1415 DTSZ01   \n\n\n\n\n\nLet us check for duplicate records:\n\nCodesOutput\n\n\n\nduplicate &lt;- origintrip_7_9_subzone %&gt;% \n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\n\n\n\nglimpse(duplicate)\n\nRows: 26\nColumns: 3\n$ ORIGIN_BS &lt;chr&gt; \"11009\", \"11009\", \"22501\", \"22501\", \"43709\", \"43709\", \"47201…\n$ TRIPS     &lt;dbl&gt; 13826, 13826, 9743, 9743, 1118, 1118, 23998, 23998, 6218, 62…\n$ ORIGIN_SZ &lt;chr&gt; \"QTSZ01\", \"QTSZ01\", \"JWSZ09\", \"JWSZ09\", \"BKSZ07\", \"BKSZ07\", …\n\n\n\n\n\nFrom the above, we know that there are duplicate records. Hence, we will use the following code chunk to retain only the unique records.\n\nCodesData\n\n\n\norigin_data &lt;- unique(origintrip_7_9_subzone)\n\n\n\n\nhead(origin_data)\n\n# A tibble: 6 × 3\n  ORIGIN_BS TRIPS ORIGIN_SZ\n  &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;    \n1 01012      1617 RCSZ10   \n2 01013       813 RCSZ10   \n3 01019      1620 DTSZ01   \n4 01029      2383 DTSZ01   \n5 01039      2727 DTSZ01   \n6 01059      1415 DTSZ01   \n\n\n\n\n\nLet us confirm if there are any duplicate records in the above dataframe:\n\nCodesOutput\n\n\n\nduplicate2 &lt;- origin_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\n\n\n\nglimpse(duplicate2)\n\nRows: 0\nColumns: 3\n$ ORIGIN_BS &lt;chr&gt; \n$ TRIPS     &lt;dbl&gt; \n$ ORIGIN_SZ &lt;chr&gt; \n\n\n\n\n\nSince there are no rows returned, it means that origin_data has no duplicates and we will now update the origin_data data frame with the planning subzone codes found in mpsz using the following code chunk.\n\nCodesOutput\n\n\n\nmpsz_origin_data &lt;- left_join(mpsz, origin_data,\n                              by = c(\"SUBZONE_C\" = \"ORIGIN_SZ\"))\n\n\n\n\nhead(mpsz_origin_data)\n\nSimple feature collection with 6 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 27668.3 ymin: 29212.16 xmax: 33316.59 ymax: 30965.02\nProjected CRS: SVY21 / Singapore TM\n         SUBZONE_N SUBZONE_C      PLN_AREA_N PLN_AREA_C       REGION_N REGION_C\n1      MARINA EAST    MESZ01     MARINA EAST         ME CENTRAL REGION       CR\n2 INSTITUTION HILL    RVSZ05    RIVER VALLEY         RV CENTRAL REGION       CR\n3 INSTITUTION HILL    RVSZ05    RIVER VALLEY         RV CENTRAL REGION       CR\n4   ROBERTSON QUAY    SRSZ01 SINGAPORE RIVER         SR CENTRAL REGION       CR\n5   ROBERTSON QUAY    SRSZ01 SINGAPORE RIVER         SR CENTRAL REGION       CR\n6   ROBERTSON QUAY    SRSZ01 SINGAPORE RIVER         SR CENTRAL REGION       CR\n  ORIGIN_BS TRIPS                       geometry\n1      &lt;NA&gt;    NA MULTIPOLYGON (((33222.98 29...\n2     13089  3241 MULTIPOLYGON (((28481.45 30...\n3     13099  3735 MULTIPOLYGON (((28481.45 30...\n4     04321  1492 MULTIPOLYGON (((28087.34 30...\n5     06129  3031 MULTIPOLYGON (((28087.34 30...\n6     06151  1159 MULTIPOLYGON (((28087.34 30..."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#choropleth-visualisation",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#choropleth-visualisation",
    "title": "In-Class Exercise 1: My First Date with Geospatial Data Analytics",
    "section": "6 Choropleth Visualisation",
    "text": "6 Choropleth Visualisation\nWe will now visualise the distribution of passenger trips on weekdays from 7am till before 10am across the planning subzones using the following code chunk.\n\nCodesOutput\n\n\n\ntm_shape(mpsz_origin_data)+\n  tm_fill(\"TRIPS\", \n          n = 5, \n          style = \"quantile\",\n          palette = \"Blues\", \n          title = \"Passenger Trips\")+\n  tm_layout(main.title = \"Passenger Trips Generated at Planning Subzone Level\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE)+\n  tm_borders(alpha = 0.5)+\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar()+\n  tm_grid(alpha = 0.2)+\n  tm_credits(\"Source: Planning Subzone boundary from URA and \\nPassenger Trips Data from LTA\", size = 0.5, position = c(\"left\", \"bottom\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#task",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#task",
    "title": "In-Class Exercise 1: My First Date with Geospatial Data Analytics",
    "section": "",
    "text": "For this task, we are required to prepare a choropleth map showing the distribution of passenger trips across the planning sub-zones."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "",
    "text": "In this exercise, we will learn how to compute spatial weights using R.\n\n\n\n\n\n\nDo you know?\n\n\n\nSpatial Weights is a way to define spatial neighbourhood. Defining the neighbourhood is an essential step towards measuring the strength of the spatial relationships between objects."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html#overview",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "",
    "text": "In this exercise, we will learn how to compute spatial weights using R.\n\n\n\n\n\n\nDo you know?\n\n\n\nSpatial Weights is a way to define spatial neighbourhood. Defining the neighbourhood is an essential step towards measuring the strength of the spatial relationships between objects."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html#getting-started",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Packages\nFirst, we will import the relevant packages that we will be using for this hands-on exercise.\n\npacman::p_load(sf,spdep,tmap,tidyverse,knitr)\n\n\n\n2.2 Importing Data\nThe datasets used in this hands-on exercise are:\n\nHunan county boundary layer: a geospatial data set in ESRI shapefile format\nHunan_2012.csv: an aspatial data set in csv format. It contains selected Hunan’s local development indicators in 2012.\n\n\n\n\n\n\n\nNote\n\n\n\nThe datasets from this exercise were provided as part of the coursework and downloaded from the student learning portal.\n\n\n\n2.2.1 Geospatial Data\nFirst, we will use st_read() of sf package to import Hunan county boundary layer (a shapefile) into R.\n\nCodesOutputData\n\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", layer = \"Hunan\")\n\n\n\n\n\nReading layer `Hunan' from data source \n  `C:\\sihuihui\\ISSS624\\Hands-on_Ex\\Hands-on_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nglimpse(hunan)\n\nRows: 88\nColumns: 8\n$ NAME_2     &lt;chr&gt; \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Cha…\n$ ID_3       &lt;int&gt; 21098, 21100, 21101, 21102, 21103, 21104, 21109, 21110, 211…\n$ NAME_3     &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"L…\n$ ENGTYPE_3  &lt;chr&gt; \"County\", \"County\", \"County City\", \"County\", \"County\", \"Cou…\n$ Shape_Leng &lt;dbl&gt; 1.869074, 2.360691, 1.425620, 3.474325, 2.289506, 4.171918,…\n$ Shape_Area &lt;dbl&gt; 0.10056190, 0.19978745, 0.05302413, 0.18908121, 0.11450357,…\n$ County     &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"L…\n$ geometry   &lt;POLYGON [°]&gt; POLYGON ((112.0625 29.75523..., POLYGON ((112.2288 …\n\n\n\n\n\nFrom the output, we know that hunan is a polygon sf dataframe with 88 features and 7 fields. It also uses a WGS84 geometric coordinates system.\n\n\n2.2.2 Aspatial Data\nWe will import Hunan_2012.csv into R using read_csv() of readr package.\n\nCodesData\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\nglimpse(hunan2012)\n\nRows: 88\nColumns: 29\n$ County      &lt;chr&gt; \"Anhua\", \"Anren\", \"Anxiang\", \"Baojing\", \"Chaling\", \"Changn…\n$ City        &lt;chr&gt; \"Yiyang\", \"Chenzhou\", \"Changde\", \"Hunan West\", \"Zhuzhou\", …\n$ avg_wage    &lt;dbl&gt; 30544, 28058, 31935, 30843, 31251, 28518, 54540, 28597, 33…\n$ deposite    &lt;dbl&gt; 10967.0, 4598.9, 5517.2, 2250.0, 8241.4, 10860.0, 24332.0,…\n$ FAI         &lt;dbl&gt; 6831.7, 6386.1, 3541.0, 1005.4, 6508.4, 7920.0, 33624.0, 1…\n$ Gov_Rev     &lt;dbl&gt; 456.72, 220.57, 243.64, 192.59, 620.19, 769.86, 5350.00, 1…\n$ Gov_Exp     &lt;dbl&gt; 2703.0, 1454.7, 1779.5, 1379.1, 1947.0, 2631.6, 7885.5, 11…\n$ GDP         &lt;dbl&gt; 13225.0, 4941.2, 12482.0, 4087.9, 11585.0, 19886.0, 88009.…\n$ GDPPC       &lt;dbl&gt; 14567, 12761, 23667, 14563, 20078, 24418, 88656, 10132, 17…\n$ GIO         &lt;dbl&gt; 9276.90, 4189.20, 5108.90, 3623.50, 9157.70, 37392.00, 513…\n$ Loan        &lt;dbl&gt; 3954.90, 2555.30, 2806.90, 1253.70, 4287.40, 4242.80, 4053…\n$ NIPCR       &lt;dbl&gt; 3528.3, 3271.8, 7693.7, 4191.3, 3887.7, 9528.0, 17070.0, 3…\n$ Bed         &lt;dbl&gt; 2718, 970, 1931, 927, 1449, 3605, 3310, 582, 2170, 2179, 1…\n$ Emp         &lt;dbl&gt; 494.310, 290.820, 336.390, 195.170, 330.290, 548.610, 670.…\n$ EmpR        &lt;dbl&gt; 441.4, 255.4, 270.5, 145.6, 299.0, 415.1, 452.0, 127.6, 21…\n$ EmpRT       &lt;dbl&gt; 338.0, 99.4, 205.9, 116.4, 154.0, 273.7, 219.4, 94.4, 174.…\n$ Pri_Stu     &lt;dbl&gt; 54.175, 33.171, 19.584, 19.249, 33.906, 81.831, 59.151, 18…\n$ Sec_Stu     &lt;dbl&gt; 32.830, 17.505, 17.819, 11.831, 20.548, 44.485, 39.685, 7.…\n$ Household   &lt;dbl&gt; 290.4, 104.6, 148.1, 73.2, 148.7, 211.2, 300.3, 76.1, 139.…\n$ Household_R &lt;dbl&gt; 234.5, 121.9, 135.4, 69.9, 139.4, 211.7, 248.4, 59.6, 110.…\n$ NOIP        &lt;dbl&gt; 101, 34, 53, 18, 106, 115, 214, 17, 55, 70, 44, 84, 74, 17…\n$ Pop_R       &lt;dbl&gt; 670.3, 243.2, 346.0, 184.1, 301.6, 448.2, 475.1, 189.6, 31…\n$ RSCG        &lt;dbl&gt; 5760.60, 2386.40, 3957.90, 768.04, 4009.50, 5220.40, 22604…\n$ Pop_T       &lt;dbl&gt; 910.8, 388.7, 528.3, 281.3, 578.4, 816.3, 998.6, 256.7, 45…\n$ Agri        &lt;dbl&gt; 4942.253, 2357.764, 4524.410, 1118.561, 3793.550, 6430.782…\n$ Service     &lt;dbl&gt; 5414.5, 3814.1, 14100.0, 541.8, 5444.0, 13074.6, 17726.6, …\n$ Disp_Inc    &lt;dbl&gt; 12373, 16072, 16610, 13455, 20461, 20868, 183252, 12379, 1…\n$ RORP        &lt;dbl&gt; 0.7359464, 0.6256753, 0.6549309, 0.6544614, 0.5214385, 0.5…\n$ ROREmp      &lt;dbl&gt; 0.8929619, 0.8782065, 0.8041262, 0.7460163, 0.9052651, 0.7…\n\n\n\n\n\n\n\n\n2.3 Performing Relational Join\nWe will update the attribute table of hunan’s spatial polygons dataframe with the attribute fields of hunan2012 dataframe using the left_join() of dplyr package.\n\nCodesOutput\n\n\n\nhunan1 &lt;- left_join(hunan, hunan2012,\n                   by=\"County\") \n\n\n\n\nkable(head(hunan1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNAME_2\nID_3\nNAME_3\nENGTYPE_3\nShape_Leng\nShape_Area\nCounty\nCity\navg_wage\ndeposite\nFAI\nGov_Rev\nGov_Exp\nGDP\nGDPPC\nGIO\nLoan\nNIPCR\nBed\nEmp\nEmpR\nEmpRT\nPri_Stu\nSec_Stu\nHousehold\nHousehold_R\nNOIP\nPop_R\nRSCG\nPop_T\nAgri\nService\nDisp_Inc\nRORP\nROREmp\ngeometry\n\n\n\n\nChangde\n21098\nAnxiang\nCounty\n1.869074\n0.1005619\nAnxiang\nChangde\n31935\n5517.2\n3541.0\n243.64\n1779.5\n12482.0\n23667\n5108.9\n2806.9\n7693.7\n1931\n336.39\n270.5\n205.9\n19.584\n17.819\n148.1\n135.4\n53\n346.0\n3957.9\n528.3\n4524.41\n14100\n16610\n0.6549309\n0.8041262\nPOLYGON ((112.0625 29.75523…\n\n\nChangde\n21100\nHanshou\nCounty\n2.360691\n0.1997875\nHanshou\nChangde\n32265\n7979.0\n8665.0\n386.13\n2062.4\n15788.0\n20981\n13491.0\n4550.0\n8269.9\n2560\n456.78\n388.8\n246.7\n42.097\n33.029\n240.2\n208.7\n95\n553.2\n4460.5\n804.6\n6545.35\n17727\n18925\n0.6875466\n0.8511756\nPOLYGON ((112.2288 29.11684…\n\n\nChangde\n21101\nJinshi\nCounty City\n1.425620\n0.0530241\nJinshi\nChangde\n28692\n4581.7\n4777.0\n373.31\n1148.4\n8706.9\n34592\n10935.0\n2242.0\n8169.9\n848\n122.78\n82.1\n61.7\n8.723\n7.592\n81.9\n43.7\n77\n92.4\n3683.0\n251.8\n2562.46\n7525\n19498\n0.3669579\n0.6686757\nPOLYGON ((111.8927 29.6013,…\n\n\nChangde\n21102\nLi\nCounty\n3.474324\n0.1890812\nLi\nChangde\n32541\n13487.0\n16066.0\n709.61\n2459.5\n20322.0\n24473\n18402.0\n6748.0\n8377.0\n2038\n513.44\n426.8\n227.1\n38.975\n33.938\n268.5\n256.0\n96\n539.7\n7110.2\n832.5\n7562.34\n53160\n18985\n0.6482883\n0.8312558\nPOLYGON ((111.3731 29.94649…\n\n\nChangde\n21103\nLinli\nCounty\n2.289506\n0.1145036\nLinli\nChangde\n32667\n564.1\n7781.2\n336.86\n1538.7\n10355.0\n25554\n8214.0\n358.0\n8143.1\n1440\n307.36\n272.2\n100.8\n23.286\n18.943\n129.1\n157.2\n99\n246.6\n3604.9\n409.3\n3583.91\n7031\n18604\n0.6024921\n0.8856065\nPOLYGON ((111.6324 29.76288…\n\n\nChangde\n21104\nShimen\nCounty\n4.171918\n0.3719471\nShimen\nChangde\n33261\n8334.4\n10531.0\n548.33\n2178.8\n16293.0\n27137\n17795.0\n6026.5\n6156.0\n2502\n392.05\n329.6\n193.8\n29.245\n26.104\n190.6\n184.7\n122\n399.2\n6490.7\n600.5\n5266.51\n6981\n19275\n0.6647794\n0.8407091\nPOLYGON ((110.8825 30.11675…\n\n\n\n\n\n\n\n\nAs we intend to only show the distribution of Gross Domestic Product Per Capita (GDPPC), we can drop some of the columns that we will not be using by selecting the columns that we want using select().\n\nCodesOutput\n\n\n\nhunan2 &lt;- hunan1 %&gt;% \n  select(c(1:4, 6, 15)) \n\n\n\n\nkable(head(hunan2))\n\n\n\n\n\n\n\n\n\n\n\n\n\nNAME_2\nID_3\nNAME_3\nENGTYPE_3\nShape_Area\nGDPPC\ngeometry\n\n\n\n\nChangde\n21098\nAnxiang\nCounty\n0.1005619\n23667\nPOLYGON ((112.0625 29.75523…\n\n\nChangde\n21100\nHanshou\nCounty\n0.1997875\n20981\nPOLYGON ((112.2288 29.11684…\n\n\nChangde\n21101\nJinshi\nCounty City\n0.0530241\n34592\nPOLYGON ((111.8927 29.6013,…\n\n\nChangde\n21102\nLi\nCounty\n0.1890812\n24473\nPOLYGON ((111.3731 29.94649…\n\n\nChangde\n21103\nLinli\nCounty\n0.1145036\n25554\nPOLYGON ((111.6324 29.76288…\n\n\nChangde\n21104\nShimen\nCounty\n0.3719471\n27137\nPOLYGON ((110.8825 30.11675…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "3 Visualising Regional Development Indicator",
    "text": "3 Visualising Regional Development Indicator\nWe will show the distribution of Gross Domestic Product per Capita (GDPPC) using qtm() of tmap package using the following code chunk.\n\nCodesVisualisation\n\n\n\nbasemap &lt;- tm_shape(hunan2) + \n  tm_polygons() + \n  tm_text(\"NAME_3\", size = 0.5)\n\ngdppc &lt;- qtm(hunan2, fill = \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp = 1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html#computing-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html#computing-spatial-weights",
    "title": "Hands-on Exercise 2A",
    "section": "4 Computing Spatial Weights",
    "text": "4 Computing Spatial Weights\n\n4.1 Based on Contiguity\n\n4.1.1 Queen\nvisualising\n\n\n4.1.2 Rook\nvisualising\n\n\n\n4.2 Based on Distance"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html#defining-and-computing-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html#defining-and-computing-spatial-weights",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "4 Defining and Computing Spatial Weights",
    "text": "4 Defining and Computing Spatial Weights\nThere are at least two popular methods can be used to define spatial weights of geographical areas. They are contiguity and distance.\nIn this hands-on exercise, we will be learning how to compute contiguity-, distance- and inverse-distance based spatial weights.\n\n4.1 Contiguity-Based Weight matrix\nThere are three different ways to define contiguity neighbours. They are Rooks, Bishops and Queen’s methods. Rooks and Queens are the two commonly used methods. The main difference between Queen’s and Rooks is that Rooks only considers geographical areas that shared common boundaries but Queen’s method includes geographical areas touching at the tips of the target geographical area.\n\n\n\nFig 1 - Types of Contiguity Methods\n\n\nIn this section, we will use poly2nb() of spdep package to compute contiguity weight matrices for the study area. This function builds a neigbours list based on regions with contiguous boundaries that is sharing one or more boundary point. For poly2nb() function, it is defined in QUEEN contiguity by default. Hence if we want to compute Rook contiguity based neighbours, we would need to pass the argument “queen = False”.\n\n4.1.1 Computing Contiguity Weight Matrix\nWe use the following code chunk to compute Queen and Rook contiguity weight matrix.\n\nQueenRook\n\n\n\nwm_q &lt;- poly2nb(hunan2, queen=TRUE)\n\n\n\n\nwm_r &lt;- poly2nb(hunan2, queen = FALSE)\n\n\n\n\n\n\n4.1.2 Retrieving Neighbours in the Contiguity Weight Matrix\nWe use summary() to get a summary report of the computed weight matrix.\n\nQueenRook\n\n\n\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\n\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\n\n\n\nFrom the output of the Queen continguity weight matrix, we see that there are 88 regions in total within Hunan and 448 non-zero links in total. There is only 1 most-connected region and it has 11 neigbours. There are 2 least-connected area and each has only 1 neighbour.\nFrom the output of the Rook contiguity weight matrix, we see that there are 440 non-zero links in total. There is only 1 most-connected region and it has 10 neigbours. There are 2 least-connected area and each has only 1 neighbour.\nFor each polygon in our polygon object, wm_q (Queen) and wm_r (Rook), we can use the following code chunk to find out the list of neigbours for each most-connected region (a.k.a polygon).\n\nQueen’s Polygon 85Rook’s Polygon 85\n\n\n\nwm_q[[85]]\n\n [1]  1  2  3  5  6 32 56 57 69 75 78\n\n\n\n\n\nwm_r[[85]]\n\n [1]  1  2  3  5  6 32 56 69 75 78\n\n\n\n\n\nThe numbers in the output represent the polygon IDs stored in the hunan spatial polygon data frame.\nTo retrieve the county name of PolygonID=85, which is the most well connected region as seen from previous output, we use the following code chunk:\n\nhunan$NAME_3[85]\n\n[1] \"Taoyuan\"\n\n\nSo we now know that polygon ID 85 is Taoyuan County in hunan.\nTo find out the names of the 11 neigbouring polygons that we got from the Queen Contiguity Matrix, we use the following code chunk:\n\nhunan2$NAME_3[c(1,2,3,5,6,32,56,57,69,75,78)]\n\n [1] \"Anxiang\"  \"Hanshou\"  \"Jinshi\"   \"Linli\"    \"Shimen\"   \"Yuanling\"\n [7] \"Anhua\"    \"Nan\"      \"Cili\"     \"Sangzhi\"  \"Taojiang\"\n\n\nWe can retrieve the GDPPC of these 11 counties using the following code chunk:\n\nnb85q &lt;- wm_q[[85]]\nnb85q &lt;- hunan2$GDPPC[nb85q]\nnb85q\n\n [1] 23667 20981 34592 25554 27137 24194 14567 21311 18714 14624 19509\n\n\nThe output above shows the GDPPC of the 11 nearest neighbours based on Queen’s method are: 23667, 20981, 34592, 25554, 27137, 24194, 14567, 21311, 18714, 14624 and 19509 respectively.\nWe can display the complete weight matrix using str().\n\nCodeOutput\n\n\n\nstr(wm_q)\n\n\n\n\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan2, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\n\n\n\n4.1.3 Visualising Continguity Neighbours\nTo visualise the contiguity neigbours, we will use a connectivity graph. A connectivity graph takes a point and displays a line to each neighboring point. As we are working with polygons currently, we will need to get points in order to make our connectivity graphs. The typical method for this will be polygon centroids. We will first calculate the polygon centroids using the sf package. To get the latitude and longitude of polygon centroids, we will use a mapping function to return a vector of the same length for each element. For this exercise, we will be using map_dbl variation of map from purrr package.\nTo get the longtitude values, we map the st_centroid() function over the geometry column of hunan and access the longitude value through the double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan2$geometry, ~st_centroid(.x)[[1]])\n\nTo get the latitude, we will use change the “1” in the double bracket notation to “2” since latitude is the second value in each centroid.\n\nlatitude &lt;- map_dbl(hunan2$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind() to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\nWe check the first few observations to see if things are formatted correctly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n4.1.3.1 Plotting Queen and Rook Contiguity Based Neighbours Map\nWe can use the following code chunk to plot the Queen- and Rook- Contiguity based neighbours map.\n\nQueen Contiguity Based Neighbours MapRook Contiguity Based Neighbours Map\n\n\n\nplot(hunan2$geometry, border = \"lightgrey\")\nplot(wm_q, coords, pch=19, cex=0.6, add=TRUE, col = \"red\")\n\n\n\n\n\n\n\nplot(hunan2$geometry, border = \"lightgrey\")\nplot(wm_r, coords, pch=19, cex=0.6, add=TRUE, col = \"red\")\n\n\n\n\n\n\n\nThe chode chunk below plots both maps side by side.\n\npar(mfrow=c(1,2))\nplot(hunan2$geometry, border = \"lightgrey\")\nplot(wm_q, coords, pch=19, cex=0.6, add=TRUE, col = \"red\")\ntitle(\"Queen Contiguity\")\nplot(hunan2$geometry, border = \"lightgrey\")\nplot(wm_r, coords, pch=19, cex=0.6, add=TRUE, col = \"red\")\ntitle(\"Rook Contiguity\")\n\n\n\n\n\n\n\n\n4.2 Distance-based Weight Matrix\nIn this section, we will derive distance-based weight matrices using dnearneigh() of spdep package.\nThis function identifies neighbours of region points using Euclidean distance with a distance band with lower and upper bounds.The parameters necessary for dnearneigh() are the coordinates, the lower distance bound, and the upper distance bound. Another important parameter is the longlat. This is used for point data in longitude and latitude form. It is necessary to use this to get great circle distance in kilometres instead of euclidean for accuracy purposes.\n\n4.2.1 Determine the cut-off distance\nFirst, we need to determine the upper limit for distance band using the steps below.\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other using knearneigh() of spdep.\nConvert the k-nearest neighbour object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids using knn2nb().\nReturn the length of neighbour relationship edges using nbdists() of spdep. This function returns the Euclidean distances along the links in a list of the same form as the neighbours list. If longlat=TRUE, Great Circle distances are used.\nRemove the list structure of the returned object using unlist().\n\n\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79km, so using this as an upper bound would ensure that all regions would at least have 1 neighbour.\n\n\n4.2.2 Computing fixed distance weight matrix\nWe will now compute the distance weight matrix using dnearneigh() and the following code chunk.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nFrom the above output, we know that there are 88 regions in Hunan and on average each region has 3.68 neighbours.\nWe can use str() to display the contents of wm_d62 weight matrix.\n\nCodesOutput\n\n\n\nstr(wm_d62)\n\n\n\n\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep.\n\nCodesOutput\n\n\n\ntable(hunan$County, card(wm_d62))\n\n\n\n\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\n\n\n\n4.2.2.1 Checking for disjoint connected subgraphs\nTo check if there are any disjoint connected subgraphs, we can use n.comp.nb() and it will return the number of disjoint connected subgraphs, and a vector with the indices of the disjoint connected subgraphs of the nodes in the spatial neighbours list object.\n\nnumber_of_components &lt;- n.comp.nb(wm_d62)\nnumber_of_components$nc\n\n[1] 1\n\n\nFrom the above, we know that there is 1 component. We will use the following code to check if all 88 regions of Hunan are in this component.\n\ntable(number_of_components$comp.id)\n\n\n 1 \n88 \n\n\nFrom the above, we know that there is a single component with 88 regions. This means that each region is connected to at least 1 region and there are no isolated regions.\n\n\n4.2.2.2 Plotting fixed distance weight matrix\nWe plot the distance weight matrix using the following code chunk.\n\nplot(hunan2$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nTo plot these two type of information side by side, we can using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(hunan2$geometry, border=\"lightgrey\")\nplot(k1,coords,add=TRUE, col=\"red\", length=0.08)\ntitle(\"1st Nearest Neighbour(s)\")\nplot(hunan2$geometry, border=\"lightgrey\")\nplot(wm_d62,coords, add=TRUE, pch=19, cex=0.6)\ntitle(\"Distance Link\")\n\n\n\n\n\n\n\n4.2.3 Computing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothens the neighbour relationship across more neighbours.\nWe can control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nWe can display the content of the matrix using str().\n\nCodesOutput\n\n\n\nstr(knn6)\n\n\n\n\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\n\n\n\nNotice that each county has exactly 6 neighbours.\n\n4.2.3.1 Plotting adaptive distance weight matrix\nWe can plot the weight matrix using the code chunk below.\n\nplot(hunan2$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch=19, cex= 0.6, add=TRUE, col=\"red\")\n\n\n\n\n\n\n\n\n4.3 Inverse Distance-Based Weight matrix\nIn inverse distanced-based weight matrix, spatial weights are calculated as the inverse function of the distance. This means that 2 locations that are closer (i.e. shorter in distance) will be given higher weight than two locations that are further away (i.e. longer in distance).\nFirst, we compute the distances between regions using nbdists() of spdep.\n\nCodesOutput\n\n\n\ndist &lt;- nbdists(wm_q, coords, longlat=TRUE)\nids &lt;- lapply(dist, function(x) 1/(x))\n\n\n\n\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034\n\n\n\n\n\nNext, we need to assign weights to each neighbouring polygon. We will assign each neighbouring polygon with equal weight (style=\"W\"). This is accomplished by assigning the fraction 1/(total number of neighbours) to each neighbouring county then summing the weighted income values.\nWhile assigning each neighbouring polygon with the same weight is most intuitive way to summarise the neighbours’ values, polygons which are situated along the edges of the map will base their lagged values on fewer polygons (due to the nature of their positions on the map). This could cause potential over- or under- estimation of the true nature of the spatial autocorrelation in the data.\nFor the purpose of this hands-on exercise, we will stick with the style=\"W\" option for simplicity sake.\n\n\n\n\n\n\nNote\n\n\n\nThe nb2listw() function can take in the following styles:\n\nB is the basic binary coding\nW is row standardised (sums over all links to n)\nC is globally standardised (sums over all links to n)\nU is equal to C divided by the number of neighbours (sums over all links to unity)\nS is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999\nminmax is based on Kelejian and Prucha (2010), and divides the weights by the minimum of the maximum row sums and maximum column sums of the input weights. It is similar to the C and U styles.\n\n\n\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy = FALSE would return an error.\n\n\nTo see the weight of first polygon’s neighbours, we use the following code chunk.\n\nrswm_q$weights[1]\n\n[[1]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n\nFrom the output, we know that the first polygon has 5 neighbours, and they are each assigned 0.2 of the total weight. When R computes the average neighbouring income values, each neihgbour’s income will be multiplied by 0.2 befire being tallied.\nUsing the same method, we can also derive a row-standardised distance weight matrix using the following code chunk.\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style = \"B\", zero.policy = TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html#output-3",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html#output-3",
    "title": "Hands-on Exercise 2A",
    "section": "5 Output",
    "text": "5 Output\n\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan2, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n:::\n\n5.0.1 Visualising Continguity Weights\nA connectivity graph takes a point and displays a line to each neighboring point. As we are working with polygons currently, we will need to get points in order to make our connectivity graphs. The typical method for this will be polygon centroids. We will calculate the polygon centroids using the sf package before getting Latitude and Longitude of Polygon Centroids\n\n\n5.1 Distance-based Weight Matrix\n\n5.1.1 Computing Distance Weight Matrix"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html#output-4",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html#output-4",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "5 Output",
    "text": "5 Output\n\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\n:::\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep.\n\nCodesOutput\n\n\n\ntable(hunan$County, card(wm_d62))\n\n\n\n\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\n\n\n\n5.0.0.1 Checking for disjoint connected subgraphs\nTo check if there are any disjoint connected subgraphs, we can use n.comp.nb() and it will return the number of disjoint connected subgraphs, and a vector with the indices of the disjoint connected subgraphs of the nodes in the spatial neighbours list object.\n\nnumber_of_components &lt;- n.comp.nb(wm_d62)\nnumber_of_components$nc\n\n[1] 1\n\n\nFrom the above, we know that there is 1 component. We will use the following code to check if all 88 regions of Hunan are in this component.\n\ntable(number_of_components$comp.id)\n\n\n 1 \n88 \n\n\nFrom the above, we know that there is a single component with 88 regions. This means that each region is connected to at least 1 region and there are no isolated regions.\n\n\n5.0.0.2 Plotting fixed distance weight matrix\nWe plot the distance weight matrix using the following code chunk.\n\nplot(hunan2$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nTo plot these two type of information side by side, we can using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(hunan2$geometry, border=\"lightgrey\")\nplot(k1,coords,add=TRUE, col=\"red\", length=0.08)\ntitle(\"1st Nearest Neighbour(s)\")\nplot(hunan2$geometry, border=\"lightgrey\")\nplot(wm_d62,coords, add=TRUE, pch=19, cex=0.6)\ntitle(\"Distance Link\")\n\n\n\n\n\n\n5.0.1 Computing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothens the neighbour relationship across more neighbours.\nWe can control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nWe can display the content of the matrix using str().\n\nCodesOutput\n\n\n\nstr(knn6)\n\n\n\n\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\n\n\n\nNotice that each county has exactly 6 neighbours.\n\n5.0.1.1 Plotting adaptive distance weight matrix\nWe can plot the weight matrix using the code chunk below.\n\nplot(hunan2$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch=19, cex= 0.6, add=TRUE, col=\"red\")\n\n\n\n\n\n\n\n5.1 Inverse Distance-Based Weight matrix\nIn inverse distanced-based weight matrix, spatial weights are calculated as the inverse function of the distance. This means that 2 locations that are closer (i.e. shorter in distance) will be given higher weight than two locations that are further away (i.e. longer in distance).\nFirst, we compute the distances between regions using nbdists() of spdep.\n\nCodesOutput\n\n\n\ndist &lt;- nbdists(wm_q, coords, longlat=TRUE)\nids &lt;- lapply(dist, function(x) 1/(x))\n\n\n\n\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034\n\n\n\n\n\nNext, we need to assign weights to each neighbouring polygon. We will assign each neighbouring polygon with equal weight (style=\"W\"). This is accomplished by assigning the fraction 1/(total number of neighbours) to each neighbouring county then summing the weighted income values.\nWhile assigning each neighbouring polygon with the same weight is most intuitive way to summarise the neighbours’ values, polygons which are situated along the edges of the map will base their lagged values on fewer polygons (due to the nature of their positions on the map). This could cause potential over- or under- estimation of the true nature of the spatial autocorrelation in the data.\nFor the purpose of this hands-on exercise, we will stick with the style=\"W\" option for simplicity sake.\n\n\n\n\n\n\nNote\n\n\n\nThe nb2listw() function can take in the following styles:\n\nB is the basic binary coding\nW is row standardised (sums over all links to n)\nC is globally standardised (sums over all links to n)\nU is equal to C divided by the number of neighbours (sums over all links to unity)\nS is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999\nminmax is based on Kelejian and Prucha (2010), and divides the weights by the minimum of the maximum row sums and maximum column sums of the input weights. It is similar to the C and U styles.\n\n\n\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy = FALSE would return an error.\n\n\nTo see the weight of first polygon’s neighbours, we use the following code chunk.\n\nrswm_q$weights[1]\n\n[[1]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n\nFrom the output, we know that the first polygon has 5 neighbours, and they are each assigned 0.2 of the total weight. When R computes the average neighbouring income values, each neihgbour’s income will be multiplied by 0.2 befire being tallied.\nUsing the same method, we can also derive a row-standardised distance weight matrix using the following code chunk.\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style = \"B\", zero.policy = TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html#application-of-spatial-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html#application-of-spatial-weight-matrix",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "5 Application of Spatial Weight Matrix",
    "text": "5 Application of Spatial Weight Matrix\nAfter defining a neighbour structure with non-zero elements of the spatial weights, we can compute spatial lags, which is a weighted sum or a weighted average of the neighbouring values for that variable. In this section, we will create four different spatial lagged variables:\n\nspatial lag with row-standardised weights,\nspatial lag as a sum of neighbouring values,\nspatial window average, and\nspatial window sum.\n\n\n5.1 Spatial Lag with row-standardised weights\nWe can compute the average neigbour GDPPC value for each polygon using the following code chunk. These values are often referred to as spatially lagged values.\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan2$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nThe above output is the spatially lagged values for each region. This value is calculated by averaging each region’s neighbour’s GDPPC.\nFor example, in the previous section, we retrieved the GDPPC of polygon 1’s neighbouring counties using the following code chunk:\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan2$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nYou notice that the average of the GDPPC of polygon 1’s neighbouring counties is 24847.20, which is the same value as the the first spatial value in GDPPC.lag.\nTo plot both the GDPPC and spatial lag GDPPC for comparison, we will first append the spatially lag GDPPC values onto hunan2 sf data frame using the following code chunk:\n\nlag.list &lt;- list(hunan2$NAME_3, lag.listw(rswm_q, hunan2$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan3 &lt;- left_join(hunan2, lag.res)\n\nThe following table shows the average neighboring income values (stored in the Inc.lag object) for each county.\n\nhead(hunan3)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3 Shape_Area GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County 0.10056190 23667  24847.20\n2 Changde 21100 Hanshou      County 0.19978745 20981  22724.80\n3 Changde 21101  Jinshi County City 0.05302413 34592  24143.25\n4 Changde 21102      Li      County 0.18908121 24473  27737.50\n5 Changde 21103   Linli      County 0.11450357 25554  27270.25\n6 Changde 21104  Shimen      County 0.37194707 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nWe will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan3, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan3, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n5.2 Spatial Lag as a sum of neighbouring values\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which applies a function across each value in the neighbors structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x+1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights,\n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.\n\nlag_sum &lt;- list(hunan2$NAME_3, lag.listw(b_weights2, hunan2$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nWe will append lag_sum GDPPC field into hunan2 of sf data frame using the following code chunk.\n\nhunan4 &lt;- left_join(hunan2, lag.res)\n\nWe can plot both the GDPPC and Spatial Lag Sum GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan4, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan4, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\n5.3 Spatial Window Average\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\n\n\nwm_qwm_qs\n\n\n\nwm_q\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\n\n\n\n\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\n\n\n\nNotice that the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909.\nWe will now look at the neighbour list of region [[1]] of wm_q and wm_qs\n\nwm_qwm_qs\n\n\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\n\n\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\n\n\n\nNotice that now [1] has six neighbours instead of five because it has included itself in the list.\nNow we obtain the weights using nb2listw()\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nWe use nb2listw() and glist() to explicitly assign weight values.Then create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, hunan2$GDPPC)\n\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nlag.list.wm_qs &lt;- list(hunan2$NAME_3, lag.listw(wm_qs, hunan2$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nWe will then append lag_window_avg GDPPC column values onto hunan3 sf data frame using left_join() of dplyr package.\n\nhunan5 &lt;- left_join(hunan3, lag_wm_qs.res)\nhead(hunan5)\n\nSimple feature collection with 6 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3 Shape_Area GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County 0.10056190 23667  24847.20\n2 Changde 21100 Hanshou      County 0.19978745 20981  22724.80\n3 Changde 21101  Jinshi County City 0.05302413 34592  24143.25\n4 Changde 21102      Li      County 0.18908121 24473  27737.50\n5 Changde 21103   Linli      County 0.11450357 25554  27270.25\n6 Changde 21104  Shimen      County 0.37194707 27137  21248.80\n  lag_window_avg GDPPC                       geometry\n1             24650.50 POLYGON ((112.0625 29.75523...\n2             22434.17 POLYGON ((112.2288 29.11684...\n3             26233.00 POLYGON ((111.8927 29.6013,...\n4             27084.60 POLYGON ((111.3731 29.94649...\n5             26927.00 POLYGON ((111.6324 29.76288...\n6             22230.17 POLYGON ((110.8825 30.11675...\n\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nCodesOutput\n\n\n\nhunan5 %&gt;% \n  select(\"NAME_3\", \"lag GDPPC\", \"lag_window_avg GDPPC\", \"geometry\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNAME_3\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\nw_avg_gdppc &lt;- qtm(hunan5, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol = 2)\n\n\n\n\n\n\n5.4 Spatial Window Sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights. Similar to the spatial window average, each region’s neighhour includes the region itself. We first add diagonal element to the neighbour list.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nwe will now assign binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights3 &lt;- lapply(wm_qs, function(x) 0*x + 1)\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights3 &lt;- nb2listw(wm_qs, \n                       glist = b_weights3,\n                       style = \"B\")\n\nb_weights3\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nTo compute the lag variable with lag.listw(), we use the following code chunk.\n\nw_sum_gdppc &lt;- list(hunan2$NAME_3, lag.listw(b_weights3, hunan2$GDPPC) )\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\nWe will append w_sum GDPPC values onto hunan3 sf data.frame by using left_join() of dplyr package using the following code chunk.\n\nhunan6 &lt;- left_join(hunan4, w_sum_gdppc.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan6 %&gt;%\n  select(\"NAME_3\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nNAME_3\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.\n\nw_sum_gdppc &lt;- qtm(hunan6, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html#applications-of-spatial-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html#applications-of-spatial-weight-matrix",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "5 Applications of Spatial Weight Matrix",
    "text": "5 Applications of Spatial Weight Matrix\nAfter defining a neighbour structure with non-zero elements of the spatial weights, we can compute spatial lags, which is a weighted sum or a weighted average of the neighbouring values for that variable. In this section, we will create four different spatial lagged variables:\n\nspatial lag with row-standardised weights,\nspatial lag as a sum of neighbouring values,\nspatial window average, and\nspatial window sum.\n\n\n5.1 Spatial Lag with row-standardised weights\nWe can compute the average neigbour GDPPC value for each polygon using the following code chunk. These values are often referred to as spatially lagged values.\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan2$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nThe above output is the spatially lagged values for each region. This value is calculated by averaging each region’s neighbour’s GDPPC.\nFor example, in the previous section, we retrieved the GDPPC of polygon 1’s neighbouring counties using the following code chunk:\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan2$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nYou notice that the average of the GDPPC of polygon 1’s neighbouring counties is 24847.20, which is the same value as the the first spatial value in GDPPC.lag.\nTo plot both the GDPPC and spatial lag GDPPC for comparison, we will first append the spatially lag GDPPC values onto hunan2 sf data frame using the following code chunk:\n\nlag.list &lt;- list(hunan2$NAME_3, lag.listw(rswm_q, hunan2$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan3 &lt;- left_join(hunan2, lag.res)\n\nThe following table shows the average neighboring income values (column “lag GDPPC”) for each county.\n\nhead(hunan3)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3 Shape_Area GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County 0.10056190 23667  24847.20\n2 Changde 21100 Hanshou      County 0.19978745 20981  22724.80\n3 Changde 21101  Jinshi County City 0.05302413 34592  24143.25\n4 Changde 21102      Li      County 0.18908121 24473  27737.50\n5 Changde 21103   Linli      County 0.11450357 25554  27270.25\n6 Changde 21104  Shimen      County 0.37194707 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nWe will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan3, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan3, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n5.2 Spatial Lag as a sum of neighbouring values\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, apply a function that will assign binary weights, then we use glist = in the nb2listw() function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbour. This is done with lapply(), which applies a function across each value in the neighbors structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x+1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights,\n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw() to compute a lag variable from our weight and GDPPC.\n\nlag_sum &lt;- list(hunan2$NAME_3, lag.listw(b_weights2, hunan2$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nWe will append lag_sum GDPPC field into hunan2 of sf data frame using the following code chunk.\n\nhunan4 &lt;- left_join(hunan2, lag.res)\n\nWe can plot both the GDPPC and Spatial Lag Sum GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan4, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan4, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\n5.3 Spatial Window Average\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\n\n\nwm_qwm_qs\n\n\n\nwm_q\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\n\n\n\n\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\n\n\n\nNotice that the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909.\nWe will now look at the neighbour list of region [[1]] of wm_q and wm_qs.\n\nwm_qwm_qs\n\n\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\n\n\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\n\n\n\nNotice that now [1] has six neighbours instead of five because it has included itself in the list.\nNow we obtain the weights using nb2listw().\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nWe use nb2listw() and glist() to explicitly assign weight values.Then create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, hunan2$GDPPC)\n\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nlag.list.wm_qs &lt;- list(hunan2$NAME_3, lag.listw(wm_qs, hunan2$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nWe will then append lag_window_avg GDPPC column values onto hunan3 sf data frame using left_join() of dplyr package.\n\nhunan5 &lt;- left_join(hunan3, lag_wm_qs.res)\nhead(hunan5)\n\nSimple feature collection with 6 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3 Shape_Area GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County 0.10056190 23667  24847.20\n2 Changde 21100 Hanshou      County 0.19978745 20981  22724.80\n3 Changde 21101  Jinshi County City 0.05302413 34592  24143.25\n4 Changde 21102      Li      County 0.18908121 24473  27737.50\n5 Changde 21103   Linli      County 0.11450357 25554  27270.25\n6 Changde 21104  Shimen      County 0.37194707 27137  21248.80\n  lag_window_avg GDPPC                       geometry\n1             24650.50 POLYGON ((112.0625 29.75523...\n2             22434.17 POLYGON ((112.2288 29.11684...\n3             26233.00 POLYGON ((111.8927 29.6013,...\n4             27084.60 POLYGON ((111.3731 29.94649...\n5             26927.00 POLYGON ((111.6324 29.76288...\n6             22230.17 POLYGON ((110.8825 30.11675...\n\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nCodesOutput\n\n\n\nhunan5 %&gt;% \n  select(\"NAME_3\", \"lag GDPPC\", \"lag_window_avg GDPPC\", \"geometry\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNAME_3\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\nw_avg_gdppc &lt;- qtm(hunan5, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol = 2)\n\n\n\n\n\n\n5.4 Spatial Window Sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights. Similar to the spatial window average, each region’s neighhour includes the region itself. We first add diagonal element to the neighbour list.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nWe will now assign binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights3 &lt;- lapply(wm_qs, function(x) 0*x + 1)\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights3 &lt;- nb2listw(wm_qs, \n                       glist = b_weights3,\n                       style = \"B\")\n\nb_weights3\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nTo compute the lag variable with lag.listw(), we use the following code chunk.\n\nw_sum_gdppc &lt;- list(hunan2$NAME_3, lag.listw(b_weights3, hunan2$GDPPC) )\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\nWe will append w_sum GDPPC values onto hunan3 sf data.frame by using left_join() of dplyr package using the following code chunk.\n\nhunan6 &lt;- left_join(hunan4, w_sum_gdppc.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nCodesOutput\n\n\n\nhunan6 %&gt;%\n  select(\"NAME_3\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNAME_3\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.\n\nw_sum_gdppc &lt;- qtm(hunan6, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html",
    "title": "Hands-on Exercise 2B: Global and Local Measures of Spatial Autocorrelations",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to compute Global and Local Measure of Spatial Autocorrelation (GLSA) using the spdep package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html#overview",
    "title": "Hands-on Exercise 2B: Global and Local Measures of Spatial Autocorrelations",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to compute Global and Local Measure of Spatial Autocorrelation (GLSA) using the spdep package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html#output-9",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2a.html#output-9",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "6 Output",
    "text": "6 Output\n\n\n\n\n\n\n\n\n\n\n\nNAME_3\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.\n\nw_sum_gdppc &lt;- qtm(hunan6, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html#the-analytical-question",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html#the-analytical-question",
    "title": "Hands-on Exercise 2B: Global and Local Measures of Spatial Autocorrelations",
    "section": "2 The Analytical Question",
    "text": "2 The Analytical Question\nIn spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Province, People’s Republic of China."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html#getting-started",
    "title": "Hands-on Exercise 2B: Global and Local Measures of Spatial Autocorrelations",
    "section": "3 Getting Started",
    "text": "3 Getting Started\n\n3.1 Packages\nFirst, we will import the relevant packages that we will be using for this hands-on exercise.\n\npacman::p_load(sf,spdep,tmap,tidyverse,knitr)\n\nWe will be using the following packages:\n\nsf: to import and handle geospatial data,\ntidyverse: to handle and wrangle attribute data,\nknitr: to generate tables for matrices,\nspdep: to compute spatial weights, global and local spatial autocorrelation statistics; and\ntmap: to prepare and plot cartographic quality chropleth map.\n\n\n\n3.2 Importing Data\nThe datasets used in this hands-on exercise are:\n\nHunan county boundary layer: a geospatial data set in ESRI shapefile format\nHunan_2012.csv: an aspatial data set in csv format. It contains selected Hunan’s local development indicators in 2012.\n\n\n\n\n\n\n\nNote\n\n\n\nThe datasets from this exercise were provided as part of the coursework and downloaded from the student learning portal.\n\n\n\n3.2.1 Geospatial Data\nFirst, we will use st_read() of sf package to import Hunan county boundary layer (a shapefile) into R.\n\nCodesOutputData\n\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", layer = \"Hunan\")\n\n\n\n\n\nReading layer `Hunan' from data source \n  `C:\\sihuihui\\ISSS624\\Hands-on_Ex\\Hands-on_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nglimpse(hunan)\n\nRows: 88\nColumns: 8\n$ NAME_2     &lt;chr&gt; \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Cha…\n$ ID_3       &lt;int&gt; 21098, 21100, 21101, 21102, 21103, 21104, 21109, 21110, 211…\n$ NAME_3     &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"L…\n$ ENGTYPE_3  &lt;chr&gt; \"County\", \"County\", \"County City\", \"County\", \"County\", \"Cou…\n$ Shape_Leng &lt;dbl&gt; 1.869074, 2.360691, 1.425620, 3.474325, 2.289506, 4.171918,…\n$ Shape_Area &lt;dbl&gt; 0.10056190, 0.19978745, 0.05302413, 0.18908121, 0.11450357,…\n$ County     &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"L…\n$ geometry   &lt;POLYGON [°]&gt; POLYGON ((112.0625 29.75523..., POLYGON ((112.2288 …\n\n\n\n\n\nFrom the output, we know that hunan is a polygon sf dataframe with 88 features and 7 fields. It also uses a WGS84 geometric coordinates system.\n\n\n3.2.2 Aspatial Data\nWe will import Hunan_2012.csv into R using read_csv() of readr package.\n\nCodesData\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\nglimpse(hunan2012)\n\nRows: 88\nColumns: 29\n$ County      &lt;chr&gt; \"Anhua\", \"Anren\", \"Anxiang\", \"Baojing\", \"Chaling\", \"Changn…\n$ City        &lt;chr&gt; \"Yiyang\", \"Chenzhou\", \"Changde\", \"Hunan West\", \"Zhuzhou\", …\n$ avg_wage    &lt;dbl&gt; 30544, 28058, 31935, 30843, 31251, 28518, 54540, 28597, 33…\n$ deposite    &lt;dbl&gt; 10967.0, 4598.9, 5517.2, 2250.0, 8241.4, 10860.0, 24332.0,…\n$ FAI         &lt;dbl&gt; 6831.7, 6386.1, 3541.0, 1005.4, 6508.4, 7920.0, 33624.0, 1…\n$ Gov_Rev     &lt;dbl&gt; 456.72, 220.57, 243.64, 192.59, 620.19, 769.86, 5350.00, 1…\n$ Gov_Exp     &lt;dbl&gt; 2703.0, 1454.7, 1779.5, 1379.1, 1947.0, 2631.6, 7885.5, 11…\n$ GDP         &lt;dbl&gt; 13225.0, 4941.2, 12482.0, 4087.9, 11585.0, 19886.0, 88009.…\n$ GDPPC       &lt;dbl&gt; 14567, 12761, 23667, 14563, 20078, 24418, 88656, 10132, 17…\n$ GIO         &lt;dbl&gt; 9276.90, 4189.20, 5108.90, 3623.50, 9157.70, 37392.00, 513…\n$ Loan        &lt;dbl&gt; 3954.90, 2555.30, 2806.90, 1253.70, 4287.40, 4242.80, 4053…\n$ NIPCR       &lt;dbl&gt; 3528.3, 3271.8, 7693.7, 4191.3, 3887.7, 9528.0, 17070.0, 3…\n$ Bed         &lt;dbl&gt; 2718, 970, 1931, 927, 1449, 3605, 3310, 582, 2170, 2179, 1…\n$ Emp         &lt;dbl&gt; 494.310, 290.820, 336.390, 195.170, 330.290, 548.610, 670.…\n$ EmpR        &lt;dbl&gt; 441.4, 255.4, 270.5, 145.6, 299.0, 415.1, 452.0, 127.6, 21…\n$ EmpRT       &lt;dbl&gt; 338.0, 99.4, 205.9, 116.4, 154.0, 273.7, 219.4, 94.4, 174.…\n$ Pri_Stu     &lt;dbl&gt; 54.175, 33.171, 19.584, 19.249, 33.906, 81.831, 59.151, 18…\n$ Sec_Stu     &lt;dbl&gt; 32.830, 17.505, 17.819, 11.831, 20.548, 44.485, 39.685, 7.…\n$ Household   &lt;dbl&gt; 290.4, 104.6, 148.1, 73.2, 148.7, 211.2, 300.3, 76.1, 139.…\n$ Household_R &lt;dbl&gt; 234.5, 121.9, 135.4, 69.9, 139.4, 211.7, 248.4, 59.6, 110.…\n$ NOIP        &lt;dbl&gt; 101, 34, 53, 18, 106, 115, 214, 17, 55, 70, 44, 84, 74, 17…\n$ Pop_R       &lt;dbl&gt; 670.3, 243.2, 346.0, 184.1, 301.6, 448.2, 475.1, 189.6, 31…\n$ RSCG        &lt;dbl&gt; 5760.60, 2386.40, 3957.90, 768.04, 4009.50, 5220.40, 22604…\n$ Pop_T       &lt;dbl&gt; 910.8, 388.7, 528.3, 281.3, 578.4, 816.3, 998.6, 256.7, 45…\n$ Agri        &lt;dbl&gt; 4942.253, 2357.764, 4524.410, 1118.561, 3793.550, 6430.782…\n$ Service     &lt;dbl&gt; 5414.5, 3814.1, 14100.0, 541.8, 5444.0, 13074.6, 17726.6, …\n$ Disp_Inc    &lt;dbl&gt; 12373, 16072, 16610, 13455, 20461, 20868, 183252, 12379, 1…\n$ RORP        &lt;dbl&gt; 0.7359464, 0.6256753, 0.6549309, 0.6544614, 0.5214385, 0.5…\n$ ROREmp      &lt;dbl&gt; 0.8929619, 0.8782065, 0.8041262, 0.7460163, 0.9052651, 0.7…\n\n\n\n\n\n\n\n\n3.3 Performing Relational Join\nWe will update the attribute table of hunan’s spatial polygons dataframe with the attribute fields of hunan2012 dataframe using the left_join() of dplyr package.\n\nCodesOutput\n\n\n\nhunan_joined &lt;- left_join(hunan, hunan2012,\n                   by=\"County\") \n\n\n\n\nkable(head(hunan_joined))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNAME_2\nID_3\nNAME_3\nENGTYPE_3\nShape_Leng\nShape_Area\nCounty\nCity\navg_wage\ndeposite\nFAI\nGov_Rev\nGov_Exp\nGDP\nGDPPC\nGIO\nLoan\nNIPCR\nBed\nEmp\nEmpR\nEmpRT\nPri_Stu\nSec_Stu\nHousehold\nHousehold_R\nNOIP\nPop_R\nRSCG\nPop_T\nAgri\nService\nDisp_Inc\nRORP\nROREmp\ngeometry\n\n\n\n\nChangde\n21098\nAnxiang\nCounty\n1.869074\n0.1005619\nAnxiang\nChangde\n31935\n5517.2\n3541.0\n243.64\n1779.5\n12482.0\n23667\n5108.9\n2806.9\n7693.7\n1931\n336.39\n270.5\n205.9\n19.584\n17.819\n148.1\n135.4\n53\n346.0\n3957.9\n528.3\n4524.41\n14100\n16610\n0.6549309\n0.8041262\nPOLYGON ((112.0625 29.75523…\n\n\nChangde\n21100\nHanshou\nCounty\n2.360691\n0.1997875\nHanshou\nChangde\n32265\n7979.0\n8665.0\n386.13\n2062.4\n15788.0\n20981\n13491.0\n4550.0\n8269.9\n2560\n456.78\n388.8\n246.7\n42.097\n33.029\n240.2\n208.7\n95\n553.2\n4460.5\n804.6\n6545.35\n17727\n18925\n0.6875466\n0.8511756\nPOLYGON ((112.2288 29.11684…\n\n\nChangde\n21101\nJinshi\nCounty City\n1.425620\n0.0530241\nJinshi\nChangde\n28692\n4581.7\n4777.0\n373.31\n1148.4\n8706.9\n34592\n10935.0\n2242.0\n8169.9\n848\n122.78\n82.1\n61.7\n8.723\n7.592\n81.9\n43.7\n77\n92.4\n3683.0\n251.8\n2562.46\n7525\n19498\n0.3669579\n0.6686757\nPOLYGON ((111.8927 29.6013,…\n\n\nChangde\n21102\nLi\nCounty\n3.474324\n0.1890812\nLi\nChangde\n32541\n13487.0\n16066.0\n709.61\n2459.5\n20322.0\n24473\n18402.0\n6748.0\n8377.0\n2038\n513.44\n426.8\n227.1\n38.975\n33.938\n268.5\n256.0\n96\n539.7\n7110.2\n832.5\n7562.34\n53160\n18985\n0.6482883\n0.8312558\nPOLYGON ((111.3731 29.94649…\n\n\nChangde\n21103\nLinli\nCounty\n2.289506\n0.1145036\nLinli\nChangde\n32667\n564.1\n7781.2\n336.86\n1538.7\n10355.0\n25554\n8214.0\n358.0\n8143.1\n1440\n307.36\n272.2\n100.8\n23.286\n18.943\n129.1\n157.2\n99\n246.6\n3604.9\n409.3\n3583.91\n7031\n18604\n0.6024921\n0.8856065\nPOLYGON ((111.6324 29.76288…\n\n\nChangde\n21104\nShimen\nCounty\n4.171918\n0.3719471\nShimen\nChangde\n33261\n8334.4\n10531.0\n548.33\n2178.8\n16293.0\n27137\n17795.0\n6026.5\n6156.0\n2502\n392.05\n329.6\n193.8\n29.245\n26.104\n190.6\n184.7\n122\n399.2\n6490.7\n600.5\n5266.51\n6981\n19275\n0.6647794\n0.8407091\nPOLYGON ((110.8825 30.11675…\n\n\n\n\n\n\n\n\nAs we intend to only show the distribution of Gross Domestic Product Per Capita (GDPPC), we can drop some of the columns that we will not be using by selecting the columns that we want using select().\n\nCodesOutput\n\n\n\nhunans &lt;- hunan_joined %&gt;% \n  select(c(1:4, 7, 15)) \n\n\n\n\nkable(head(hunans))\n\n\n\n\n\n\n\n\n\n\n\n\n\nNAME_2\nID_3\nNAME_3\nENGTYPE_3\nCounty\nGDPPC\ngeometry\n\n\n\n\nChangde\n21098\nAnxiang\nCounty\nAnxiang\n23667\nPOLYGON ((112.0625 29.75523…\n\n\nChangde\n21100\nHanshou\nCounty\nHanshou\n20981\nPOLYGON ((112.2288 29.11684…\n\n\nChangde\n21101\nJinshi\nCounty City\nJinshi\n34592\nPOLYGON ((111.8927 29.6013,…\n\n\nChangde\n21102\nLi\nCounty\nLi\n24473\nPOLYGON ((111.3731 29.94649…\n\n\nChangde\n21103\nLinli\nCounty\nLinli\n25554\nPOLYGON ((111.6324 29.76288…\n\n\nChangde\n21104\nShimen\nCounty\nShimen\n27137\nPOLYGON ((110.8825 30.11675…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 2B: Global and Local Measures of Spatial Autocorrelations",
    "section": "4 Visualising Regional Development Indicator",
    "text": "4 Visualising Regional Development Indicator\nWe will show the distribution of Gross Domestic Product per Capita (GDPPC) 2012 using qtm() of tmap package using the following code chunk.\n\nCodesVisualisation\n\n\n\nequal &lt;- tm_shape(hunans) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunans) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html#global-spatial-autocorrelation",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html#global-spatial-autocorrelation",
    "title": "Hands-on Exercise 2B: Global and Local Measures of Spatial Autocorrelations",
    "section": "5 Global Spatial Autocorrelation",
    "text": "5 Global Spatial Autocorrelation\nIn this section, we will learn how to compute global spatial autocorrelation statistics and perform spatial complete randomness test for global spatial autocorrelation.\n\n5.1 Computing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct spatial weights of the study area. Spatial weights is used to define the neighbourhood relationships between the geographical units (i.e., county) in the study area.\n\n\n\n\n\n\nNote\n\n\n\nTo learn more about computing spatial weights, please refer to Hands-on Exercise 2a.\n\n\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries.\nAs mentioned in Hands-on Exercise 2a, poly2nb()’s default argument for Queen is queen=TRUE, meaning that the function computes Queen contiguity by default. If we want to compute Rook contiguity, we need to set queen=FALSE.\nWe use the following code chunk to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunans, queen = TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 regions in Hunan. The most connected region has 11 neighbours and there are 2 regions with only 1 neighbours. On average, each region has 5.090909 neighbours.\n\n\n5.2 Row-standardised Weight Matrix\nNext, we need to assign weights to each neighbouring polygon. We will assign each neighbouring polygon with equal weight (style=\"W\"). This is accomplished by assigning the fraction 1/(total number of neighbours) to each neighbouring county then summing the weighted income values.\nWhile assigning each neighbouring polygon with the same weight is most intuitive way to summarise the neighbours’ values, polygons which are situated along the edges of the map will base their lagged values on fewer polygons (due to the nature of their positions on the map). This could cause potential over- or under- estimation of the true nature of the spatial autocorrelation in the data.\nFor the purpose of this hands-on exercise, we will use the style=\"W\" option for simplicity sake.\n\n\n\n\n\n\nNote\n\n\n\nThe nb2listw() function can take in the following styles:\n\nB is the basic binary coding\nW is row standardised (sums over all links to n)\nC is globally standardised (sums over all links to n)\nU is equal to C divided by the number of neighbours (sums over all links to unity)\nS is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999\nminmax is based on Kelejian and Prucha (2010), and divides the weights by the minimum of the maximum row sums and maximum column sums of the input weights. It is similar to the C and U styles.\n\n\n\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy = FALSE would return an error.\n\n\n\n\n5.3 Global Spatial Autocorrelation: Moran’s I\nIn this section, we will learn how to perform Moran’s I statistics testing using moran.test() of spdep package.\n\nMoran’s test for spatial autocorrelation using a spatial weights matrix in weights list form. The assumptions underlying the test are sensitive to the form of the graph of neighbour relationships and other factors, and results may be checked against those of moran.mc permutations.\n\n\n5.3.1 Moran’s I test\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep package.\n\nmoran.test(hunans$GDPPC, \n           listw = rswm_q,\n          zero.policy = TRUE,\n          alternative = \"greater\",\n          na.action = na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunans$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nThe Moran I test is a measure of spatial autocorrelation, which assesses whether the observed pattern in the spatial distribution of a variable is different from what would be expected under spatial randomness.\nFrom the above outcome, we see that the Moran I statistic is 0.30075, and its standard deviation is 4.7351. The p-value is 1.095e-06, which is very small. Assuming that our chosen significance level is 0.05, we would reject the null hypothesis since p-value &lt; 0.05, suggesting strong evidence against the null hypothesis of spatial randomness.\n\nThe alternative hypothesis is “greater”, indicating that we are testing if there is a positive spatial autocorrelation (i.e., similar values are close to each other). We can specify the alternative hypothesis using alternative =. The default value is \"greater\", but it can be changed to \"less\" or \"two.sided\".\n\nHence, the results suggests that there is a significant positive spatial autocorrelation in the variable GDPPC and the observed spatial pattern is not likely to have occurred by random chance.\n\n\n5.3.2 Computing Monte Carlo Moran’s I\nIf we doubt that the assumptions of Moran’s I are true (normality and randomisation), we can use a Monte Carlo simulation. The purpose of the Monte Carlo simulation is to estimate the significance of the Moran I statistic through random permutations. We will: - Simulate Moran’s I n times under the assumption of no spatial pattern, - Assign all regions the mean value, - Calculate Moran’s I, - Compare the actual value of Moran’s I to randomly simulated distribution to obtain p-value (pseudo significance).\nThe code chunk below performs permutation test for Moran’s I statistic using moran.mc() of spdep package. A total of 1000 simulation will be performed.\n\nset.seed(1234)\nbperm = moran.mc(hunans$GDPPC,\n                 listw = rswm_q,\n                 nsim = 999,\n                 zero.policy = TRUE,\n                 na.action = na.omit)\n\n\n\n\n\n\n\nNote\n\n\n\nThe simulation was run with 999 permutations (nsim = 999) plus the observed statistic, making a total of 1000 simulations.\n\n\nThe Monte Carlo simulation supports the earlier findings from the Moran I test. The small p-value (0.001) indicates that the observe spatial pattern in the variable GDPPC is unlikely due to random chance and there is a strong evidence of positive spatial autocorrelation.\n\n\n5.3.3 Visualising Monte Carlo Moran’s I\nIt is a good practice for us the examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\nWe will use hist() and abline() of R Graphics to plot the histogram.\n\nhist(bperm$res,\n     freq=TRUE,\n     breaks = 20,\n     xlab = \"Simulated Moran's I\")\n\nabline(v=0,\n       col=\"red\")\n\n\n\n\nThe observed statistic from Monte Carlo Moran’s I Simulation is 0.300749970, which falls way to the right of the histogram distribution suggesting that GDPPC values are clustered (a positive Moran’s I value suggests clustering while a negative Moran’sI value suggests dispersion).\n\n\n\n5.4 Global Spatial Autocorrelation: Geary’s C\nIn this section, we will learn how to perform Geary’s c statistics testing by using appropriate functions of spdep package.\n\n5.4.1 Geary’s C test\nThe code chunk below performs Geary’s C test for spatial autocorrelation by using geary.test() of spdep package.\n\ngeary.test(hunans$GDPPC, listw = rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunans$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\nThe p-value associated with the Geary C test is 0.0001526, which is very small and less than 0.05. This means that we can reject the null hypothesis of spatial randomness.\n\nThe alternative hypothesis’s default value is “Expectation greater than statistic”, indicating that we are testing whether the expected value of Geary’s C is greater than the observed statistic. This suggests positive spatial autocorrelation.\n\nThe Geary’s C test result suggests that there is significant positive spatial autocorrelation in the variable GDPPC in the hunans dataset based on the specified spatial weights matrix. The observed spatial pattern is not likely to have occurred by random chance.\n\n\n5.4.2 Computing Monte Carlo Geary’s C\nThe code chunk below performs permutation test for Geary’s C statistuc using geary.mc() of spdep package.\n\nset.seed(1234)\nbperm_g = geary.mc(hunans$GDPPC,\n                 listw = rswm_q,\n                 nsim = 999)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunans$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n5.4.3 Visualising Monte Carlo Geary’s C\nWe will plot a histogram to reveal the distribution of the simulated values using the following code chunks.\n\nmean(bperm_g$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm_g$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm_g$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm_g$res, freq = TRUE, breaks = 20, xlab=\"Simulated Geary C\")\nabline(v=1, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html#spatial-correlogram",
    "title": "Hands-on Exercise 2B: Global and Local Measures of Spatial Autocorrelations",
    "section": "6 Spatial Correlogram",
    "text": "6 Spatial Correlogram\nSpatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\n6.1 Compute Moran’s I Correlogram\nWe will use sp.correlogram() of spdep package to compute a 6-lag spatial correlogram of GDPPC for Moran’s I (method = \"I\").We will then use the plot() function of base Graph to plot the output.\n\nMI_corr &lt;- sp.correlogram(wm_q, hunans$GDPPC,\n                          order = 6, method = \"I\",\n                          style = \"W\")\n\nplot(MI_corr)\n\n\n\n\nPlotting the output might not allow us to provide complete interpretation because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunans$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n6.2 Compute Geary’s C Correlogram and Plot\nWe will use sp.correlogram() of spdep package to compute a 6-lag spatial correlogram of GDPPC for Geary’s C (method = \"C\").We will then use the plot() function of base Graph to plot the output.\n\nGC_corr &lt;- sp.correlogram(wm_q,\n                          hunans$GDPPC,\n                          order = 6,\n                          method = \"C\",\n                          style = \"W\")\n\nplot(GC_corr)\n\n\n\n\nSimilar to the previous step, we will print out the analysis report by using the code chunk below.\n\nprint(GC_corr)\n\nSpatial correlogram for hunans$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html#cluster-and-outlier-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html#cluster-and-outlier-analysis",
    "title": "Hands-on Exercise 2B: Global and Local Measures of Spatial Autocorrelations",
    "section": "7 Cluster and Outlier Analysis",
    "text": "7 Cluster and Outlier Analysis\nLocal Indicators of Spatial Association (LISA) are statistics that evaluate the existence of clusters in the spatial arrangement of a given variable. For instance, if we are studying cancer rates among census tracts in a given city, local clusters in the rates mean that there are areas that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.\nIn this section, we will learn how to apply appropriate LISA, especially local Moran’I, to detect clusters and/or outliers from GDPPC of Hunan Province.\n\n7.1 Computing Local Moran’s I\nTo compute local Moran’s I, the localmoran() function of spdep will be used. localmoran() computes li values, given a set of zi values and a listw object providing neighbouring weights information for the polygon associated with the zi values.\nThe code chunk below computes local Moran’s I of GDPPC at the county level.\n\nfips &lt;- order(hunans$County)\nlocalMI &lt;- localmoran(hunans$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() function returns a matrix of values with the following columns:\n\nli: the local Moran’s I statistics\nE.li: the expectation of local moran statistic under the randomisation hypothesis\nVar.li: the variance of local moran statistic under the randomisation hypothesis\nZ.li: the standard deviation of local moran statistic\nPr(): the p-value of local moran statistic\n\nWe use printCoefmat() to list the content of the local Moran matrix.\n\n\n\n\n\n\n\n\n7.2 Mapping Local Moran’s I values and p-values\nBefore mapping the local Moran’s I map, we append the local Moran’s I dataframe (localMI) onto the Hunan Spatial Polygon Data Frame (hunans).\n\nhunan.localMI &lt;- cbind(hunans,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\nWe then use choropleth mapping functions of tmap package to plot the local Moran’s I values using the following code chunk:\n\ntm_shape(hunan.localMI) + \n  tm_fill(col= \"Ii\",\n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"Local Moran Statistics\") + \n  tm_borders(alpha = 0.5)\n\n\n\n\nThe choropleth map shows that there are both positive and negative li values. Hence, we should consider the p-values for each of these values to determine their significance.\nThe following code chunk creates a choropleth map of Moran’s I p-values using tmap package.\n\ntm_shape(hunan.localMI) + \n  tm_fill(col= \"Pr.Ii\",\n          breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette = \"-Blues\",\n          title = \"Local Moran's I p-values\") + \n  tm_borders(alpha = 0.5)\n\n\n\n\nFor effective interpretation, we plot both the local Moran’s I values map and its corresponding p-values map next to each other.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"Local Moran Statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html#creating-a-lisa-cluster-map",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html#creating-a-lisa-cluster-map",
    "title": "Hands-on Exercise 2B: Global and Local Measures of Spatial Autocorrelations",
    "section": "8 Creating a LISA Cluster Map",
    "text": "8 Creating a LISA Cluster Map\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. Before we generate the LISA cluster map, we would need to plot the Moran Scatterplot.\n###Plotting Moran Scatterplot The Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\n\nnci &lt;- moran.plot(hunans$GDPPC, rswm_q, \n                  labels=as.character(hunans$County),\n                  xlab=\"GDPPC 2012\",\n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\nNotice that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC.\n\n8.1 Plotting Moran Scatterplot with Standardised Variable\nWe will use scale() to center and scale the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\nhunans$Z.GDPPC &lt;- scale(hunans$GDPPC) %&gt;%\n  as.vector()\n\nThe as.vector() added to the end if to make sure that the data type we get from this vector maps neatly onto our dataframe.\nWe now plot the Moran scatterplot with standardised variable using the following code chunk.\n\nnci2 &lt;- moran.plot(hunans$Z.GDPPC, rswm_q,\n                   labels = as.character((hunans$County),                   xlab= \"z-GDPPC 2012\",                            ylab=\"Spatially Lag z-GDPPC 2012\"))\n\n\n\n\n\n\n8.2 Preparing LISA Map Classes\nFirst we generate the quadrants of the LISA cluster map.\n\nquadrant &lt;-vector(mode=\"numeric\", length=nrow(localMI))\n\nNext, we derive the spatially legged variable of interest (i.e., GDPPC) and centers the spatially lagged variable around its mean.\n\nhunans$lag_GDPPC &lt;- lag.listw(rswm_q, hunans$GDPPC)\n\nDV &lt;- hunan$lag_GDPPC - mean(hunans$lag_GDPPC)\n\nThen, we center the local Moran’s around the mean.\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])\n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif &lt;- 0.05\n\nWe also define the low-low(1), low-high(2), high-low(3) and high-high(4) categories.\n\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4  \n\nLastly,we place non-significant Moran in the category 0.\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\nhunans$lag_GDPPC &lt;- lag.listw(rswm_q, hunans$GDPPC)\nDV &lt;- hunans$lag_GDPPC - mean(hunans$lag_GDPPC)     \nLM_I &lt;- localMI[,1]   \nsignif &lt;- 0.05       \nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4    \nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\n\n\n8.3 Plotting LISA Map\nNow, we can build the LISA map by using the following code chunk.\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\nFor effective interpretation,we plot both the local Moran’s I values map and its corresponding p-values map next to each other.\n\ngdppc &lt;- qtm(hunans, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\nWe can also include the local Moran’s I map and p-value map as shown below for easy comparison.\n\ngdppc &lt;- qtm(hunans, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"Local Moran Statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc,LISAmap,localMI.map, pvalue.map)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html#hot-spot-and-cold-spot-area-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html#hot-spot-and-cold-spot-area-analysis",
    "title": "Hands-on Exercise 2B: Global and Local Measures of Spatial Autocorrelations",
    "section": "9 Hot Spot and Cold Spot Area Analysis",
    "text": "9 Hot Spot and Cold Spot Area Analysis\nBesides detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.\nThe term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).\n\n9.1 Getis and Ord’s G-Statistics\nThe Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995) looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\n9.2 Deriving Distance-based Weight Matrix\nFirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\n9.2.1 Deriving the centroid\nWe will need points to associate with each polygon before we can make our connectivity graph. We will need to run st_centroid() and also use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length.\nTo get the longtitude values, we map the st_centroid() function over the geometry column of hunan and access the longitude value through the double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunans$geometry, ~st_centroid(.x)[[1]])\n\nTo get the latitude, we will use change the “1” in the double bracket notation to “2” since latitude is the second value in each centroid.\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind() to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\n\n\n9.2.2 Determine the cut-off distance\nFirst, we need to determine the upper limit for distance band using the steps below.\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other using knearneigh() of spdep.\nConvert the k-nearest neighbour object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids using knn2nb().\nReturn the length of neighbour relationship edges using nbdists() of spdep. This function returns the Euclidean distances along the links in a list of the same form as the neighbours list. If longlat=TRUE, Great Circle distances are used.\nRemove the list structure of the returned object using unlist().\n\n\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n9.2.3 Computing the fixed distance weight matrix\nWe will now compute the distance weight matrix using dnearneigh() and the following code chunk.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nFrom the above output, we know that there are 88 regions in Hunan and on average each region has 3.68 neighbours.\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nwm62_lw &lt;- nb2listw(wm_d62, style = \"B\")\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\n\n9.3 Computing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothens the neighbour relationship across more neighbours.\nWe can control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn8 &lt;- knn2nb(knearneigh(coords, k=8))\nknn8\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nknn8_lw &lt;- nb2listw(knn8, style = 'B')\nsummary(knn8_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html#computing-gi-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2b.html#computing-gi-statistics",
    "title": "Hands-on Exercise 2B: Global and Local Measures of Spatial Autocorrelations",
    "section": "10 Computing Gi Statistics",
    "text": "10 Computing Gi Statistics\n\n10.1 Gi statistics using fixed distance\n\nfips &lt;- order(hunans$County)\ngi.fixed &lt;- localG(hunans$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunans$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding hunan sf data frame by using the code chunk below.\n\nhunan.gi &lt;- cbind(hunans, as.matrix(gi.fixed)) %&gt;% \n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nThe code chunk above performs three tasks. 1. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). 2. Next, cbind() is used to join hunans data frame and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().\n\n\n10.2 Mapping Gi values with fixed distance weights\nThe code chunk below maps the Gi values derived using fixed distance weight matrix.\n\ngdppc &lt;- qtm(hunans, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style= \"pretty\",\n          palette = \"-RdBu\",\n          title = \"Local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp = 1, ncol = 2)\n\n\n\n\n\n\n10.3 Gi statistics using adaptive distance\nWe will now compute the Gi values for GDPPC2012 using an adaptive distance weight matrix (i.e. knb_lw).\n\nfips &lt;- order(hunans$County)\ngi.adaptive &lt;- localG(hunans$GDPPC, knn8_lw)\nhunan.gi &lt;- cbind(hunans, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\n10.4 Mapping Gi values with adaptive distance weights\nTo visualise the hot and cold spot areas, we will use tmap package to map the Gi values derived using adaptive distance weight matrix.\n\ngdppc &lt;- qtm(hunans, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_adaptive\", \n          style=\"pretty\",\n          palette=\"-RdBu\",\n          title = \"Local Gi using adaptive distance weights\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html",
    "title": "In-Class Exercise 2B: Global and Local Spatial Autocorrelations",
    "section": "",
    "text": "For this task, we will be learning how to compute global and local spatial autocorrelations using the sfdep package."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#preparing-the-geospatial-data",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#preparing-the-geospatial-data",
    "title": "In-Class Exercise 2B: Global and Local Spatial Autocorrelations",
    "section": "3 Preparing the Geospatial Data",
    "text": "3 Preparing the Geospatial Data\n\n3.1 Importing the data\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", layer=\"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\sihuihui\\ISSS624\\In-class_Ex\\In-class_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nFrom the above outcome, we know that hunandata is simple feature (sf) data frame with 88 features (each representing 1 geographical entity), and each feature is a polygon.It uses the WGS84 projection."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#create-time-series-cube",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#create-time-series-cube",
    "title": "EHSA",
    "section": "2 Create Time Series Cube",
    "text": "2 Create Time Series Cube\n\nGDPPC_st &lt;-spacetime(GDPPC, hunan, .loc_col = \"County\", .time_col = \"Year\")\n\noutput is a spacetime cube\n\nis_spacetime_cube(GDPPC_st)\n\n[1] TRUE\n\n\n\nis_spacetime_cube(GDPPC)\n\n[1] FALSE\n\n\n##Compute Gi*\nDerive spatial weight (Got errors! to check again)\n{r} GDPPC_nb &lt;- GDPPC_st %&gt;% activate(“geometry”) %&gt;% mutate(nb= include_self(st_contiguity(geometry)), wt = st_inverse_distance(nb, geometry, scale=1, alpha=1), .before=1) %&gt;% set_nbs(“nb”)\ngi_stars &lt;- GDPPC_nb %&gt;% group_by(Year) %&gt;% mutate(gi_star = local_gstar_perm(GDPPC, nb, wt)) %&gt;% tidyr::unnest(gi_star)\n\n2.0.0.1 to fill in later!\ncbg &lt;- gi_stars %&gt;%\nggplot(data = cbg)\nehsa &lt;- emerging_hotspot_analysis( x = GDPPC_st, .var = “GDPPC”, k = 1, nsim=99)\nno pattern is not equals to cold spot; they are not significantly significant"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#global-measures-of-spatial-autocorrelation",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#global-measures-of-spatial-autocorrelation",
    "title": "EHSA",
    "section": "3 Global Measures of Spatial Autocorrelation",
    "text": "3 Global Measures of Spatial Autocorrelation"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#local-autocorrelation",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#local-autocorrelation",
    "title": "EHSA",
    "section": "4 Local Autocorrelation",
    "text": "4 Local Autocorrelation\n\nlisa &lt;- wm_q %&gt;% mutate(local_moran =local_moran(GDPPC, nb, wt, nsim=99), .before=1) %&gt;% unnest(local_moran)\nneed to unnest to ungroup the table data frame %&gt;% then syntax to decide between mean and median. look at the distribution. if the distribution is skewed, use median"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#emerging-hot-spot-analysis",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#emerging-hot-spot-analysis",
    "title": "EHSA",
    "section": "5 Emerging Hot Spot Analysis",
    "text": "5 Emerging Hot Spot Analysis"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html",
    "title": "In-Class Exercise 2A: Spatial Weights",
    "section": "",
    "text": "For this task, we will be learning how to derive spatial weights using the sfdep package.\nAccording to Josiah Parry, the developer of the package,\n\n“sfdep builds on the great shoulders of spdep package for spatial dependence. sfdep creates an sf and tidyverse friendly interface to the package as well as introduces new functionality that is not present in spdep. sfdep utilizes list columns extensively to make this interface possible.”"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html#task",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html#task",
    "title": "In-Class Exercise 2A: Spatial Weights",
    "section": "",
    "text": "For this task, we will be learning how to derive spatial weights using the sfdep package.\nAccording to Josiah Parry, the developer of the package,\n\n“sfdep builds on the great shoulders of spdep package for spatial dependence. sfdep creates an sf and tidyverse friendly interface to the package as well as introduces new functionality that is not present in spdep. sfdep utilizes list columns extensively to make this interface possible.”"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html#getting-started",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html#getting-started",
    "title": "In-Class Exercise 2A: Spatial Weights",
    "section": "2 Getting Started",
    "text": "2 Getting Started\nWe will first load the necessary packages using the following code chunk:\n\ntmap: for thematic mapping\nsf: for geospatial data handling (e.g. importing and exporting for spatial data and geoprocessing)\ntidyverse: a family of R packages for non-spatial data handling\nknitr: to generate static html tables\nsfdep: to calculate spatial weights and matrices, space time cube and hot spot analysis\n\n\npacman::p_load(tmap, sf, tidyverse, sfdep, knitr)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html#preparing-the-geospatial-data",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html#preparing-the-geospatial-data",
    "title": "In-Class Exercise 2A: Spatial Weights",
    "section": "3 Preparing the Geospatial Data",
    "text": "3 Preparing the Geospatial Data\n\n3.1 Importing the data\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", layer=\"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\sihuihui\\ISSS624\\In-class_Ex\\In-class_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nFrom the above outcome, we know that hunandata is simple feature (sf) data frame with 88 features (each representing 1 geographical entity), and each feature is a polygon.It uses the WGS84 projection."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html#preparing-the-aspatial-data",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html#preparing-the-aspatial-data",
    "title": "In-Class Exercise 2A: Spatial Weights",
    "section": "4 Preparing the Aspatial Data",
    "text": "4 Preparing the Aspatial Data\n\n4.1 Importing the data\n\nhunan2012 &lt;- read.csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html#combining-both-data-frames-using-left-join",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html#combining-both-data-frames-using-left-join",
    "title": "In-Class Exercise 2A: Spatial Weights",
    "section": "5 Combining Both Data Frames Using Left Join",
    "text": "5 Combining Both Data Frames Using Left Join\n\nhunan_GDPPC&lt;- left_join(hunan, hunan2012) %&gt;% \n                select(1:4, 7, 15)\n\nWhen joining these 2 data frames, we did not specify the by= because there is a common column in both data frames (i.e., Country )\nOther than joining both data frames, we also use select() to pick the relevant columns that we want. Note that the geometry column was retained even though it was not specified.\n\nWe typically use a left join with a spatial layer (e.g. hunan) and nonspatial layer (hunan_GDPPC) so that we can retain spatial geometric properties."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html#visualising-the-map",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html#visualising-the-map",
    "title": "In-class Exercise 2: Spatial Weights",
    "section": "6 Visualising the Map",
    "text": "6 Visualising the Map\nWe use the following code to visualise the choropleth map of Hunan’s 2012 GDPPC.\n\ntmap_mode(\"plot\")\ntm_shape(hunan_GDPPC) +\n  tm_fill(\"GDPPC\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"GDPPC\") + \n  tm_borders(alpha = 0.5) + \n  tm_layout(main.title = \"Distribution of GDP per capita by district in Hunan (2012)\", main.title.position=\"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35, \n            frame= TRUE) +\n  tm_compass(type = \"8star\", size=2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html#contiguity-weight-matrix",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html#contiguity-weight-matrix",
    "title": "In-class Exercise 2: Spatial Weights",
    "section": "7 Contiguity weight matrix",
    "text": "7 Contiguity weight matrix\n\nwm_q &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt= st_weights(nb, \n                        style= \"W\"),\n                        .before = 1)\n\nnb: neighbour list object crreated by st_neighbour style: Default:W” for row standardised weight matrix\nCombine neighbour list and weights in 1 code"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html#defining-weight-matrix",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html#defining-weight-matrix",
    "title": "In-Class Exercise 2A: Spatial Weights",
    "section": "7 Defining Weight Matrix",
    "text": "7 Defining Weight Matrix\nAs learnt in our hands-on exercises, we can define weight matrices based on contiguity (adjacency) or distance.\n\n7.1 Contiguity Weight Matrix\nTo compute contiguity weight matrix using sfdep package, we perform the following steps:\n\nidentify contiguity neighbour list using st_contiguity() of sfdep package, and\nderive the contiguity spatial weights using st_weights() of sfdep package.\n\nTo identify the contiguity neighbour list using Queen and Rook method, we use the following code chunks.\n\nQueenRook\n\n\n\nnb_queen &lt;- hunan_GDPPC %&gt;% \n  mutate(nb=st_contiguity(geometry),\n         .before=1)\n\n\n\n\nnb_rook &lt;- hunan_GDPPC %&gt;% \n  mutate(nb=st_contiguity(geometry, queen=FALSE),\n         .before=1)\n\n\n\n\nLet us take a look at the summary of the first lag neighbour list (i.e. nb) using the following code chunks.\n\nQueenRook\n\n\n\nsummary(nb_queen$nb)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\n\nsummary(nb_rook$nb)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\n\n\n\nThe summary report for Queen Contiguity based weight matrix shows that there are 88 area units in Hunan province. The most connected area unit has 11 neighbours. There are two are units with only one neighbour.\nThe summary report for Rook Contiguity based weight matrix shows that there are 88 area units in Hunan province. The most connected area unit has 10 neighbours. There are two are units with only one neighbour.\nWe can also display the output data frame using the following Methods. For the codes below, we will use nb_queen as example.\n\nOption 1 - using the dataframe itselfOption 2 - Using kable() and head()\n\n\n\nnb_queen\n\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb   NAME_2  ID_3    NAME_3   ENGTYPE_3\n1                 2, 3, 4, 57, 85  Changde 21098   Anxiang      County\n2               1, 57, 58, 78, 85  Changde 21100   Hanshou      County\n3                     1, 4, 5, 85  Changde 21101    Jinshi County City\n4                      1, 3, 5, 6  Changde 21102        Li      County\n5                     3, 4, 6, 85  Changde 21103     Linli      County\n6                4, 5, 69, 75, 85  Changde 21104    Shimen      County\n7                  67, 71, 74, 84 Changsha 21109   Liuyang County City\n8       9, 46, 47, 56, 78, 80, 86 Changsha 21110 Ningxiang      County\n9           8, 66, 68, 78, 84, 86 Changsha 21111 Wangcheng      County\n10 16, 17, 19, 20, 22, 70, 72, 73 Chenzhou 21112     Anren      County\n      County GDPPC                       geometry\n1    Anxiang 23667 POLYGON ((112.0625 29.75523...\n2    Hanshou 20981 POLYGON ((112.2288 29.11684...\n3     Jinshi 34592 POLYGON ((111.8927 29.6013,...\n4         Li 24473 POLYGON ((111.3731 29.94649...\n5      Linli 25554 POLYGON ((111.6324 29.76288...\n6     Shimen 27137 POLYGON ((110.8825 30.11675...\n7    Liuyang 63118 POLYGON ((113.9905 28.5682,...\n8  Ningxiang 62202 POLYGON ((112.7181 28.38299...\n9  Wangcheng 70666 POLYGON ((112.7914 28.52688...\n10     Anren 12761 POLYGON ((113.1757 26.82734...\n\n\n\n\n\nkable(head(nb_queen, n=10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnb\nNAME_2\nID_3\nNAME_3\nENGTYPE_3\nCounty\nGDPPC\ngeometry\n\n\n\n\n2, 3, 4, 57, 85\nChangde\n21098\nAnxiang\nCounty\nAnxiang\n23667\nPOLYGON ((112.0625 29.75523…\n\n\n1, 57, 58, 78, 85\nChangde\n21100\nHanshou\nCounty\nHanshou\n20981\nPOLYGON ((112.2288 29.11684…\n\n\n1, 4, 5, 85\nChangde\n21101\nJinshi\nCounty City\nJinshi\n34592\nPOLYGON ((111.8927 29.6013,…\n\n\n1, 3, 5, 6\nChangde\n21102\nLi\nCounty\nLi\n24473\nPOLYGON ((111.3731 29.94649…\n\n\n3, 4, 6, 85\nChangde\n21103\nLinli\nCounty\nLinli\n25554\nPOLYGON ((111.6324 29.76288…\n\n\n4, 5, 69, 75, 85\nChangde\n21104\nShimen\nCounty\nShimen\n27137\nPOLYGON ((110.8825 30.11675…\n\n\n67, 71, 74, 84\nChangsha\n21109\nLiuyang\nCounty City\nLiuyang\n63118\nPOLYGON ((113.9905 28.5682,…\n\n\n9, 46, 47, 56, 78, 80, 86\nChangsha\n21110\nNingxiang\nCounty\nNingxiang\n62202\nPOLYGON ((112.7181 28.38299…\n\n\n8, 66, 68, 78, 84, 86\nChangsha\n21111\nWangcheng\nCounty\nWangcheng\n70666\nPOLYGON ((112.7914 28.52688…\n\n\n16, 17, 19, 20, 22, 70, 72, 73\nChenzhou\n21112\nAnren\nCounty\nAnren\n12761\nPOLYGON ((113.1757 26.82734…\n\n\n\n\n\n\n\n\n\n7.1.1 Identifying higher Order Neighbours\nIn class, we learnt that other than the immediate neighbours (i.e. those regions along the boundaries of an area), we can also find out their neighbour’s neigbours (i.e., higher order contiguity neighbours). We can do this using st_nb_lag_cumul() of sfdep package.This function Creates an encompassing neighbor list of the order specified. For example, if the order is 2 the result contains both 1st and 2nd order neighbors.\nIn the following code chunk, we will generate the 1st and 2nd order neighbours for each region in Hunan.\n\nnb2_queen &lt;- hunan_GDPPC %&gt;% \n  mutate(nb = st_contiguity(geometry), \n         nb2 = st_nb_lag_cumul(nb,2),\n         .before = 1) \n\nLet’s take a look at the differences between 1st order only and output with both 1st and 2nd order neighhbours\n\n1st Order Only1st and 2nd Order\n\n\n\nnb &lt;- st_contiguity(sf::st_geometry(hunan_GDPPC))\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\n\nsummary(nb2_queen)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 1324 \nPercentage nonzero weights: 17.09711 \nAverage number of links: 15.04545 \nLink number distribution:\n\n 5  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 26 28 33 \n 2  1  6  4  5  4  8  5 10  4  4  8  4  8  5  2  2  1  2  1  1  1 \n2 least connected regions:\n30 88 with 5 links\n1 most connected region:\n56 with 33 links\n\n\n    nb         nb2          NAME_2               ID_3          NAME_3         \n NULL:NULL   NULL:NULL   Length:88          Min.   :21098   Length:88         \n                         Class :character   1st Qu.:21125   Class :character  \n                         Mode  :character   Median :21150   Mode  :character  \n                                            Mean   :21150                     \n                                            3rd Qu.:21174                     \n                                            Max.   :21201                     \n  ENGTYPE_3            County              GDPPC                geometry \n Length:88          Length:88          Min.   : 8497   POLYGON      :88  \n Class :character   Class :character   1st Qu.:14566   epsg:4326    : 0  \n Mode  :character   Mode  :character   Median :20433   +proj=long...: 0  \n                                       Mean   :24405                     \n                                       3rd Qu.:27224                     \n                                       Max.   :88656                     \n\n\n\n\n\nWhen higher order neighbours are included, we note that the number of nonzero links and the average number of links increased.\n\n\n\n7.2 Distance- based Weight Matrix\nThere are three popularly used distance-based spatial weights, they are:\n\nfixed distance weights,\nadaptive distance weights, and\ninverse distance weights (IDW).\n\n\n7.2.1 Fixed Distance weights\nWe will use the following code chunk to determine the upper limit for distance band. This will be needed for the subsequent computation of fixed distance weight matrix.\n\ngeo &lt;- sf::st_geometry(hunan_GDPPC)\nnb &lt;- st_knn(geo, longlat=TRUE)\ndists &lt;- unlist(st_nb_dists(geo, nb))\n\n\n\n\n\n\n\nExplanation of the functions used above\n\n\n\n\nst_geometry(): Get, set, replace or rename geometry from an sf object\nst_knn(): Identifies the k nearest neighbors for given point geometry\nst_nb_dists():From an nb list and point geometry, return a list of distances for each observation’s neighbors list.\nunlist(): Given a list structure, simplifies it to produce a vector which contains all the atomic components which occur in the list.\n\n\n\nWe will derive the summary statistics of the nearest neighbour distances vector (i.e., dists) using the following code chunk.\n\nsummary(dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  21.56   29.11   36.89   37.34   43.21   65.80 \n\n\nThe summary statistics report above shows that the maximum nearest neighbour distance is 65.80km. By using a threshold value of 66km will ensure that each area will have at least one neighbour.\nNow we will go ahead to compute the fixed distance weights by using the code chunk below.\n\nwm_fd &lt;- hunan_GDPPC %&gt;%\n  mutate(nb=st_dist_band(geometry, upper=66),\n         wt = st_weights(nb), \n         .before = 1)\n\n\n\n\n\n\n\nExplanation of the functions used above\n\n\n\n\nst_dist_band: To identify neighbours based on a distance band (i.e., 66km). The output is a list of neighbours (i.e., nb).\nst_weights: To calcualte polygon spatial weights of the nb list. Note that:\n\nthe default style argument is set to “W” for row standardised weights, and\nthe default allow_zero is set to TRUE, assigns zero as lagged value to zone without neighbours.\n\n\n\n\nLet’s take a look at the data frame.\n\nwm_fd\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                       nb\n1      2, 3, 4, 5, 57, 64\n2       1, 57, 58, 78, 85\n3             1, 4, 5, 57\n4              1, 3, 5, 6\n5          1, 3, 4, 6, 69\n6                4, 5, 69\n7              67, 71, 84\n8       9, 46, 47, 78, 80\n9   8, 46, 66, 68, 84, 86\n10 16, 20, 22, 70, 72, 73\n                                                                 wt   NAME_2\n1  0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667  Changde\n2                                           0.2, 0.2, 0.2, 0.2, 0.2  Changde\n3                                            0.25, 0.25, 0.25, 0.25  Changde\n4                                            0.25, 0.25, 0.25, 0.25  Changde\n5                                           0.2, 0.2, 0.2, 0.2, 0.2  Changde\n6                                   0.3333333, 0.3333333, 0.3333333  Changde\n7                                   0.3333333, 0.3333333, 0.3333333 Changsha\n8                                           0.2, 0.2, 0.2, 0.2, 0.2 Changsha\n9  0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667 Changsha\n10 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667 Chenzhou\n    ID_3    NAME_3   ENGTYPE_3    County GDPPC                       geometry\n1  21098   Anxiang      County   Anxiang 23667 POLYGON ((112.0625 29.75523...\n2  21100   Hanshou      County   Hanshou 20981 POLYGON ((112.2288 29.11684...\n3  21101    Jinshi County City    Jinshi 34592 POLYGON ((111.8927 29.6013,...\n4  21102        Li      County        Li 24473 POLYGON ((111.3731 29.94649...\n5  21103     Linli      County     Linli 25554 POLYGON ((111.6324 29.76288...\n6  21104    Shimen      County    Shimen 27137 POLYGON ((110.8825 30.11675...\n7  21109   Liuyang County City   Liuyang 63118 POLYGON ((113.9905 28.5682,...\n8  21110 Ningxiang      County Ningxiang 62202 POLYGON ((112.7181 28.38299...\n9  21111 Wangcheng      County Wangcheng 70666 POLYGON ((112.7914 28.52688...\n10 21112     Anren      County     Anren 12761 POLYGON ((113.1757 26.82734...\n\n\n\n\n7.2.2 Adaptive Distance weights\nWe will derive adaptive spatial weights using the following code chunk.\n\nwm_ad &lt;- hunan_GDPPC %&gt;% \n  mutate(nb = st_knn(geometry, \n         k = 8),\n         wt = st_weights(nb),\n         .before = 1) \n\n\n\n\n\n\n\nExplanation of the functions used above\n\n\n\n\nst_knn(): To identify neighbours based on a k (i.e., k=8 indicates the nearest 8 neighbours). The output is a list of neighbours (i.e., nb).\n\n\n\n\n\n7.2.3 Inverse Distance weights\nWe will derive an inverse distance weights using the following code chunk.\n\nwm_idw &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry), \n         wt = st_inverse_distance(nb, geometry, \n                                  scale = 1,\n                                  alpha = 1),\n         .before=1)\n\n\n\n\n\n\n\nExplanation of the function used above\n\n\n\n\nst_inverse_distance(): To calculate inverse distance weights of neighbours on the nb list."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html#explanation-of-the-functions-used-above",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html#explanation-of-the-functions-used-above",
    "title": "In-class Exercise 2: Spatial Weights",
    "section": "8 Explanation of the functions used above",
    "text": "8 Explanation of the functions used above\n\nst_dist_band: To identify neighbours based on a distance band (i.e., 66km). The output is a list of neighbours (i.e., nb).\nst_weights: To calcualte polygon spatial weights of the nb list. Note that:\n\nthe default style argument is set to “W” for row standardised weights, and\nthe default allow_zero is set to TRUE, assigns zero as lagged value to zone without neighbours."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html#plotting-the-choropleth-map",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2a.html#plotting-the-choropleth-map",
    "title": "In-Class Exercise 2A: Spatial Weights",
    "section": "6 Plotting the choropleth Map",
    "text": "6 Plotting the choropleth Map\nWe use the following code to visualise the choropleth map of Hunan’s 2012 GDPPC.\n\ntmap_mode(\"plot\")\ntm_shape(hunan_GDPPC) +\n  tm_fill(\"GDPPC\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"GDPPC\") + \n  tm_borders(alpha = 0.5) + \n  tm_layout(main.title = \"Distribution of GDP per capita by district in Hunan (2012)\", main.title.position=\"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35, \n            frame= TRUE) +\n  tm_compass(type = \"8star\", size=2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#overview",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#overview",
    "title": "In-Class Exercise 2B: Global and Local Spatial Autocorrelations",
    "section": "",
    "text": "For this task, we will be learning how to compute global and local spatial autocorrelations using the sfdep package."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#getting-started",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#getting-started",
    "title": "In-Class Exercise 2B: Global and Local Spatial Autocorrelations",
    "section": "2 Getting Started",
    "text": "2 Getting Started\nWe will first load the necessary packages using the following code chunk:\n\ntmap: for thematic mapping\nsf: for geospatial data handling (e.g. importing and exporting for spatial data and geoprocessing)\ntidyverse: a family of R packages for non-spatial data handling\nknitr: to generate static html tables\nsfdep: to calculate spatial weights and matrices, space time cube and hot spot analysis\nplotly: to make the graphs interactive\n\n\npacman::p_load(tmap, sf, tidyverse, sfdep, knitr, plotly)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#preparing-the-aspatial-data",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#preparing-the-aspatial-data",
    "title": "In-Class Exercise 2B: Global and Local Spatial Autocorrelations",
    "section": "4 Preparing the Aspatial Data",
    "text": "4 Preparing the Aspatial Data\n\n4.1 Importing the data\n\nhunan2012 &lt;- read.csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#combining-both-data-frames-using-left-join",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#combining-both-data-frames-using-left-join",
    "title": "In-Class Exercise 2B: Global and Local Spatial Autocorrelations",
    "section": "5 Combining Both Data Frames Using Left Join",
    "text": "5 Combining Both Data Frames Using Left Join\n\nhunan_GDPPC&lt;- left_join(hunan, hunan2012) %&gt;% \n                select(1:4, 7, 15)\n\nWhen joining these 2 data frames, we did not specify the by= because there is a common column in both data frames (i.e., Country )\nOther than joining both data frames, we also use select() to pick the relevant columns that we want. Note that the geometry column was retained even though it was not specified.\n\nWe typically use a left join with a spatial layer (e.g. hunan) and nonspatial layer (hunan_GDPPC) so that we can retain spatial geometric properties."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#plotting-the-choropleth-map",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#plotting-the-choropleth-map",
    "title": "In-Class Exercise 2B: Global and Local Spatial Autocorrelations",
    "section": "6 Plotting the Choropleth Map",
    "text": "6 Plotting the Choropleth Map\nWe use the following code to visualise the choropleth map of Hunan’s 2012 GDPPC.\n\ntmap_mode(\"plot\")\ntm_shape(hunan_GDPPC) +\n  tm_fill(\"GDPPC\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"GDPPC\") + \n  tm_borders(alpha = 0.5) + \n  tm_layout(main.title = \"Distribution of GDP per capita by district in Hunan (2012)\", main.title.position=\"center\",\n            main.title.size=0.8,\n            legend.height = 0.45,\n            legend.width = 0.35, \n            frame= TRUE) +\n  tm_compass(type = \"8star\", size=2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#global-measures-of-spatial-association",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#global-measures-of-spatial-association",
    "title": "In-Class Exercise 2B: Global and Local Spatial Autocorrelations",
    "section": "7 Global Measures of Spatial Association",
    "text": "7 Global Measures of Spatial Association\n\n7.1 Deriving Contiguity Weights (Queen’s Method)\nThe following code chunk derives the Queen’s method contiguity weights.\n\nwm_q &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry), \n         wt = st_weights(nb, \n                         style = \"W\"),\n         .before = 1)\n\n\n\n\n\n\n\nExplanation of the function(s) used above\n\n\n\n\nst_weights() provides 3 arguments:\n\nnb: a neighbour list object as creatd by st_neighbours()\nstyle: Default is “W” for row standardised weights. This value can also be “B”, “C”, “U”, “minmax”, and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nallow_zero: If TRUE, it assigns zero as lagged value to zone without neighbours.\n\n\n\n\nLet us take a look at the data frame generated.\n\nwm_q\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1                 2, 3, 4, 57, 85\n2               1, 57, 58, 78, 85\n3                     1, 4, 5, 85\n4                      1, 3, 5, 6\n5                     3, 4, 6, 85\n6                4, 5, 69, 75, 85\n7                  67, 71, 74, 84\n8       9, 46, 47, 56, 78, 80, 86\n9           8, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                                            wt\n1                                                      0.2, 0.2, 0.2, 0.2, 0.2\n2                                                      0.2, 0.2, 0.2, 0.2, 0.2\n3                                                       0.25, 0.25, 0.25, 0.25\n4                                                       0.25, 0.25, 0.25, 0.25\n5                                                       0.25, 0.25, 0.25, 0.25\n6                                                      0.2, 0.2, 0.2, 0.2, 0.2\n7                                                       0.25, 0.25, 0.25, 0.25\n8  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n9             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n10                      0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734...\n\n\n\n\n7.2 Computing Global Moran’s I\nIn the code chunk below, global_moran() function is used to compute the Moran’s I value. Different from spdep package, the output is a tibble data.frame.\n\nmoranI &lt;- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\n\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\n\n\n7.3 Performing Global Moran’s I test\nIn general, Moran’s I test will be performed instead of just computing the Moran’s I statistics. With sfdep package, Moran’s I test can be performed by using global_moran_test() as shown in the code chunk below.\n\nglobal_moran_test(wm_q$GDPPC, \n                  wm_q$nb,\n                  wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe default for alternative argument is “two.sided”. Other supported arguments are “greater” or “less”.\nBy default, the randomizaton argument is TRUE. If FALSE, it assumes normality.\n\n\n\n\n\n7.4 Performning Global Moran’s I permutation test\nIn practice, monte carlo simulation should be used to perform the statistical test. For sfdep, it is supported by globel_moran_perm().\n\n\n\n\n\n\nNote\n\n\n\nIt is a good practice to use set.seed() before performing simulation. This is to ensure that the computation is reproducible.\n\n\n\nset.seed(1234)\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt, \n                  nsim=99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nSince the p value is &lt;2.2e-16, which is lower than the significance level of 0.05, we can reject the null hypothesis that the spatial patterns are random. Because the Moran’s I statistic is greater than 0, we can infer that the spatial distribution shows signs of clustering.\n\n\n\n\n\n\nNote\n\n\n\nThe numbers of simulation is alway equal to nsim + 1. This mean in nsim = 99. This mean 100 simulation will be performed.\n\n\n\n\n7.5 Computing Local Moran’s I\nWe can compute Local Moran’s I of GDPPC at county level using local_moran() of sfdep package.\n\nlisa &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(GDPPC, nb, wt, nsim = 99),\n         .before=1) %&gt;% \n  unnest(local_moran)\n\nLet us take a look at the output.\n\nlisa\n\nSimple feature collection with 88 features and 20 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 21\n         ii        eii     var_ii    z_ii    p_ii p_ii_sim p_folded_sim skewness\n      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1 -0.00147  0.00177   0.000418   -0.158  0.874       0.82         0.41   -0.812\n 2  0.0259   0.00641   0.0105      0.190  0.849       0.96         0.48   -1.09 \n 3 -0.0120  -0.0374    0.102       0.0796 0.937       0.76         0.38    0.824\n 4  0.00102 -0.0000349 0.00000437  0.506  0.613       0.64         0.32    1.04 \n 5  0.0148  -0.00340   0.00165     0.449  0.654       0.5          0.25    1.64 \n 6 -0.0388  -0.00339   0.00545    -0.480  0.631       0.82         0.41    0.614\n 7  3.37    -0.198     1.41        3.00   0.00266     0.08         0.04    1.46 \n 8  1.56    -0.265     0.804       2.04   0.0417      0.08         0.04    0.459\n 9  4.42     0.0450    1.79        3.27   0.00108     0.02         0.01    0.746\n10 -0.399   -0.0505    0.0859     -1.19   0.234       0.28         0.14   -0.685\n# ℹ 78 more rows\n# ℹ 13 more variables: kurtosis &lt;dbl&gt;, mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;,\n#   nb &lt;nb&gt;, wt &lt;list&gt;, NAME_2 &lt;chr&gt;, ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;,\n#   ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;int&gt;, geometry &lt;POLYGON [°]&gt;\n\n\nThe output of local_moran() is an sf data.frame containing the columns ii, eii, var_ii, z_ii, p_ii, p_ii_sim, p_folded_sim, skewness and kurtosis.\n\nii: local moran statistic\neii: expectation of local moran statistic; for localmoran_perm(), it refers to the permutation sample means\nvar.ii:variance of local moran statistic; for localmoran_perm(), it refers to the permutation sample standard deviations\nz_ii: standard deviate of local moran statistic; for localmoran_perm(), based on permutation sample means and standard deviations\np_ii:p-value of local moran statistic using pnorm(); for localmoran_perm() using standard\np_ii_sim: For localmoran_perm(), rank() and punif() of observed statistic rank for [0, 1] p-values using alternative=\np_folded_sim: the simulation folded [0, 0.5] range ranked p-value (based on this)\nskewness: For localmoran_perm(), the output of e1071::skewness() for the permutation samples underlying the standard deviates\nKurtosis: For localmoran_perm(), the output of e1071::kurtosis() for the permutation samples underlying the standard deviates\n\n\n\n7.6 Visualising Local Moran’s I\nWe can use tmap package to prepare a choropleth map using the values in the ii field.\n\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I of GDPPC\", \n            main.title.size = 0.8)\n\n\n\n\n\n\n7.7 Visualising Local Moran’s p-values\nWe can use tmap package to prepare a choropleth map using the values in the p_ii field.\n\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"p_ii\", breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Local Moran's I\", \n            main.title.size = 0.8)\n\n\n\n\n\n\n7.8 Visualising Local Moran’s I and p-values\nFor effective comparison, let us plot both maps next to each other.\n\ntmap_mode(\"plot\")\nii_val &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I of GDPPC\", \n            main.title.size = 0.8)\n\npii_val &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\", breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Local Moran's I\", \n            main.title.size = 0.8)\n\ntmap_arrange(ii_val, pii_val, asp = 1, ncol = 2)\n\n\n\n\n\n\n7.9 Visualising LISA Map\nLISA map is a categorical map showing outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two type of clusters namely: High-High and Low-Low cluaters. In fact, LISA map is an interpreted map by combining local Moran's I of geographical areas and their respective p-values.\nIn lisa sf data.frame, we can find three fields contain the LISA categories. They are mean, median and pysal. In general, classification in mean will be used as shown in the code chunk below.\n\nlisa_sig &lt;- lisa %&gt;% \n  filter(p_ii &lt;0.05)\n\ntmap_mode(\"plot\")\ntm_shape(lisa) + \n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  tm_shape(lisa_sig) + \n  tm_fill(\"mean\") +\n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#hot-spot-and-cold-spot-area-analysis-hcsa",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#hot-spot-and-cold-spot-area-analysis-hcsa",
    "title": "In-Class Exercise 2B: Global and Local Spatial Autocorrelations",
    "section": "8 Hot Spot and Cold Spot Area Analysis (HCSA)",
    "text": "8 Hot Spot and Cold Spot Area Analysis (HCSA)\nHCSA uses spatial weights to identify locations of statistically significant hot spots and cold spots in an spatially weighted attribute that are in proximity to one another based on a calculated distance. The analysis groups features when similar high (hot) or low (cold) values are found in a cluster. The polygon features usually represent administration boundaries or a custom grid structure."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html",
    "title": "In-Class Exercise 2C: Emerging Hot Spot Analysis",
    "section": "",
    "text": "Emerging Hot Spot Analysis (EHSA) is a spatio-temporal analysis method for revealing and describing how hot spot and cold spot areas evolve over time. The analysis consist of four main steps:\n\nBuilding a space-time cube,\nCalculating Getis-Ord local Gi* statistic for each bin by using an FDR correction,\nEvaluating these hot and cold spot trends by using Mann-Kendall trend test,\nCategorising each study area location by referring to the resultant trend z-score and p-value for each location with data, and with the hot spot z-score and p-value for each bin."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html#overview",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html#overview",
    "title": "In-Class Exercise 2C: Emerging Hot Spot Analysis",
    "section": "",
    "text": "Emerging Hot Spot Analysis (EHSA) is a spatio-temporal analysis method for revealing and describing how hot spot and cold spot areas evolve over time. The analysis consist of four main steps:\n\nBuilding a space-time cube,\nCalculating Getis-Ord local Gi* statistic for each bin by using an FDR correction,\nEvaluating these hot and cold spot trends by using Mann-Kendall trend test,\nCategorising each study area location by referring to the resultant trend z-score and p-value for each location with data, and with the hot spot z-score and p-value for each bin."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html#getting-started",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html#getting-started",
    "title": "In-Class Exercise 2C: Emerging Hot Spot Analysis",
    "section": "2 Getting Started",
    "text": "2 Getting Started\nWe will first load the necessary packages using the following code chunk:\n\ntmap: for thematic mapping\nsf: for geospatial data handling (e.g. importing and exporting for spatial data and geoprocessing)\ntidyverse: a family of R packages for non-spatial data handling\nknitr: to generate static html tables\nsfdep: to calculate spatial weights and matrices, space time cube and hot spot analysis\nplotly: to make the graphs interactive\n\n\npacman::p_load(tmap, sf, tidyverse, sfdep, knitr, plotly)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html#preparing-the-geospatial-data",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html#preparing-the-geospatial-data",
    "title": "In-Class Exercise 2C: Emerging Hot Spot Analysis",
    "section": "3 Preparing the Geospatial Data",
    "text": "3 Preparing the Geospatial Data\n\n3.1 Importing the data\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", layer=\"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\sihuihui\\ISSS624\\In-class_Ex\\In-class_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nFrom the above outcome, we know that hunandata is simple feature (sf) data frame with 88 features (each representing 1 geographical entity), and each feature is a polygon.It uses the WGS84 projection."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html#preparing-the-aspatial-data",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html#preparing-the-aspatial-data",
    "title": "In-Class Exercise 2C: Emerging Hot Spot Analysis",
    "section": "4 Preparing the Aspatial Data",
    "text": "4 Preparing the Aspatial Data\n\n4.1 Importing the data\n\nGDPPC &lt;- read.csv(\"data/aspatial/Hunan_GDPPC.csv\")\n\nLet us take a look at the GDPPC data.\n\nkable(head(GDPPC))\n\n\n\n\nYear\nCounty\nGDPPC\n\n\n\n\n2005\nLongshan\n3469\n\n\n2005\nChangsha\n24612\n\n\n2005\nWangcheng\n14659\n\n\n2005\nNingxiang\n11687\n\n\n2005\nLiuyang\n13406\n\n\n2005\nZhuzhou\n8546\n\n\n\n\n\n\nglimpse(GDPPC)\n\nRows: 1,496\nColumns: 3\n$ Year   &lt;int&gt; 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 200…\n$ County &lt;chr&gt; \"Longshan\", \"Changsha\", \"Wangcheng\", \"Ningxiang\", \"Liuyang\", \"Z…\n$ GDPPC  &lt;dbl&gt; 3469, 24612, 14659, 11687, 13406, 8546, 10944, 8040, 7383, 1168…"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html#creating-a-time-series-cube",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html#creating-a-time-series-cube",
    "title": "In-Class Exercise 2C: Emerging Hot Spot Analysis",
    "section": "5 Creating a Time Series Cube",
    "text": "5 Creating a Time Series Cube\nWe use spacetime() of sfdep to create a space time cube.\n\nGDPPC_st &lt;- spacetime(GDPPC, hunan,\n                 .loc_col = \"County\",\n                 .time_col = \"Year\")\n\nWe can use is_spacetime_cube() of sfedep package to verify if GDPPC_st is indeed a space time cube object.\n\nis_spacetime_cube(GDPPC_st)\n\n[1] TRUE\n\n\nThe TRUE return confirms that GDPPC_st object is indeed an space time cube."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html#computing-gi",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html#computing-gi",
    "title": "In-Class Exercise 2C: Emerging Hot Spot Analysis",
    "section": "6 Computing Gi*",
    "text": "6 Computing Gi*"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html#mann-kendall-test",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html#mann-kendall-test",
    "title": "In-Class Exercise 2C: Emerging Hot Spot Analysis",
    "section": "7 Mann-Kendall Test",
    "text": "7 Mann-Kendall Test"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html#arrange-to-show-significant-emerging-hotcold-spots",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html#arrange-to-show-significant-emerging-hotcold-spots",
    "title": "In-Class Exercise 2C: Emerging Hot Spot Analysis",
    "section": "8 Arrange to show significant emerging hot/cold spots",
    "text": "8 Arrange to show significant emerging hot/cold spots"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html#performing-emerging-hotspot-analysis",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html#performing-emerging-hotspot-analysis",
    "title": "In-Class Exercise 2C: Emerging Hot Spot Analysis",
    "section": "9 Performing Emerging Hotspot Analysis",
    "text": "9 Performing Emerging Hotspot Analysis"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html#section",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2c.html#section",
    "title": "In-Class Exercise 2C: Emerging Hot Spot Analysis",
    "section": "10 ",
    "text": "10"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#computing-local-gi-statistics",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2b.html#computing-local-gi-statistics",
    "title": "In-Class Exercise 2B: Global and Local Spatial Autocorrelations",
    "section": "9 Computing local Gi* Statistics",
    "text": "9 Computing local Gi* Statistics\nFirst, we will compute an inverse distance weight matrix.\n\nwm_idw &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry), \n         wt = st_inverse_distance(nb, geometry, \n                                  scale = 1,\n                                  alpha = 1),\n         .before=1)\n\nWe will then use local_gstar_perm() of sfdep package to compute local Gi* statistics using the following code chunk.\n\nHCSA &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(GDPPC, nb, wt, nsim=99),\n         .before = 1) %&gt;% \n  unnest(local_Gi)\n\nLet us take a look at the output.\n\nHCSA\n\nSimple feature collection with 88 features and 16 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 17\n   gi_star   e_gi    var_gi p_value   p_sim p_folded_sim skewness kurtosis nb   \n     &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;nb&gt; \n 1  0.0416 0.0114   6.41e-6  0.0493 9.61e-1         0.7      0.35    0.875 &lt;int&gt;\n 2 -0.333  0.0106   3.84e-6 -0.0941 9.25e-1         1        0.5     0.661 &lt;int&gt;\n 3  0.281  0.0126   7.51e-6 -0.151  8.80e-1         0.9      0.45    0.640 &lt;int&gt;\n 4  0.411  0.0118   9.22e-6  0.264  7.92e-1         0.6      0.3     0.853 &lt;int&gt;\n 5  0.387  0.0115   9.56e-6  0.339  7.34e-1         0.62     0.31    1.07  &lt;int&gt;\n 6 -0.368  0.0118   5.91e-6 -0.583  5.60e-1         0.72     0.36    0.594 &lt;int&gt;\n 7  3.56   0.0151   7.31e-6  2.61   9.01e-3         0.06     0.03    1.09  &lt;int&gt;\n 8  2.52   0.0136   6.14e-6  1.49   1.35e-1         0.2      0.1     1.12  &lt;int&gt;\n 9  4.56   0.0144   5.84e-6  3.53   4.17e-4         0.04     0.02    1.23  &lt;int&gt;\n10  1.16   0.0104   3.70e-6  1.82   6.86e-2         0.12     0.06    0.416 &lt;int&gt;\n# ℹ 78 more rows\n# ℹ 8 more variables: wt &lt;list&gt;, NAME_2 &lt;chr&gt;, ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;,\n#   ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;int&gt;, geometry &lt;POLYGON [°]&gt;\n\n\nFrom the above results, we see that the following columns are generated due to local_gstar_perm() :\n\ngi_star: the observed statistic\ne_gi: the permutation sample mean\nvar_gi: the permutation sample variance\np_value: the p-value using sample mean and standard deviation\np_folded_sim: p-value based on the implementation of Pysal which always assumes a two-sided test taking the minimum possible p-value\nskewness: sample skewness\nkurtosis: sample kurtosis\n\n\n9.1 Visualing Gi*\nWe use the following code chunk to visualise the Gi* computed.\n\ntmap_mode(\"plot\")\n\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\n\n\n\nVisualising p-value of HCSA\nWe use the following code chunk to visualise the p-values of HCSA computed.\n\ntmap_mode(\"plot\")\n\ntm_shape(HCSA) +\n  tm_fill(\"p_folded_sim\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\n\n\n\nFor effective comparison, we plot both maps next to each other.\n\ntmap_mode(\"plot\")\nmap1 &lt;- tm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\n\n\n\n\n\n9.2 Visualising Hot Spot and Cold Spot Areas\nNow, we are ready to plot the significant (i.e. p-values less than 0.05) hot spot and cold spot areas by using the following code chunk.\n\nHCSA_sig &lt;- HCSA  %&gt;%\n  filter(p_folded_sim &lt; 0.05)\n\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.4)"
  }
]